
@article{petersch_real_2005,
	title = {Real time computation and temporal coherence of opacity transfer functions for direct volume rendering of ultrasound data},
	volume = {29},
	issn = {0895-6111},
	doi = {10.1016/j.compmedimag.2004.09.013},
	abstract = {Opacity transfer function {(OTF)} generation for direct volume rendering of medical image data is an intensely discussed subject. Several automatic methods exist for {CT} and {MRI} data, which are not apt for ultrasound data, mainly due to its low signal-to-noise ratio. Furthermore, ultrasound {(US)} imaging is able to produce time-varying {3D} datasets in real time thus opening the door to {4D} visualization. However, {OTF} design for {4D} datasets has not been exhaustively discussed until now. We present an efficient solution to generate an optimized {OTF} for a given {3DUS} dataset in real time. Our method results in excellent visualization which we demonstrate using {3D} fetus datasets. Finally, we discuss the applicability of our method to {4DUS} visualization.},
	number = {1},
	journal = {Computerized medical imaging and graphics: the official journal of the Computerized Medical Imaging Society},
	author = {Petersch, Bernhard and Hadwiger, Markus and Hauser, Helwig and Hönigmann, Dieter},
	month = jan,
	year = {2005},
	note = {{PMID:} 15710541},
	keywords = {Austria, Humans, Magnetic Resonance Imaging, Tomography, X-Ray Computed},
	pages = {53--63}
}

@inproceedings{balabanian_temporal_2008,
	title = {Temporal Styles for Time-Varying Volume Data},
	location = {Atlanta, {USA}},
	url = {http://www.cc.gatech.edu/research/reports/GT-IC-08-05},
	abstract = {This paper introduces interaction mechanisms for conveying temporal characteristics of time-varying volume data based on temporal styles. We demonstrate the flexibility of the new concept through different temporal style transfer function types and we define a set of temporal compositors as operators on them. The data is rendered by a multi-volume {GPU} raycaster that does not require any grid alignment over the individual time-steps of our data nor a rectilinear grid structure. The paper presents the applicability of the new concept on different data sets from partial to full voxel alignment with rectilinear and curvilinear grid layout.},
	booktitle = {Proceedings of {3DPVT'08} - the Fourth International Symposium on {3D} Data Processing, Visualization and Transmission},
	author = {Balabanian, Jean-Paul and Viola, Ivan and M{\"o}ller, Torsten and Gr{\"o}ller, Eduard},
	editor = {Gumhold, Stephan and Kosecka, Jana and Staadt, Oliver},
	month = jun,
	year = {2008},
	pages = {81-89},
	file = {Balabanian2008_3DPVT.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\UMEITD39\Balabanian2008_3DPVT.pdf:application/pdf}
}

@article{wang_importance-driven_2008,
	title = {Importance-Driven Time-Varying Data Visualization},
	volume = {14},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2008.140},
	abstract = {The ability to identify and present the most essential aspects of time-varying data is critically important in many areas of science and engineering. This paper introduces an importance-driven approach to time-varying volume data visualization for enhancing that ability. By conducting a block-wise analysis of the data in the joint feature-temporal space, we derive an importance curve for each data block based on the formulation of conditional entropy from information theory. Each curve characterizes the local temporal behavior of the respective block, and clustering the importance curves of all the volume blocks effectively classifies the underlying data. Based on different temporal trends exhibited by importance curves and their clustering results, we suggest several interesting and effective visualization techniques to reveal the important aspects of time-varying data.},
	number = {6},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Wang, Chaoli and Yu, Hongfeng and Ma, Kwan-Liu},
	month = dec,
	year = {2008},
	keywords = {block-wise analysis, conditional entropy, data visualisation, entropy, feature-temporal space, importance-driven time-varying volume data visualization, Information Theory, pattern classification, pattern clustering},
	pages = {1547 --1554},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\7DH5SWKH\cookiedetectresponse.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\JVHT7PDI\Wang et al. - 2008 - Importance-Driven Time-Varying Data Visualization.pdf:application/pdf}
}

@article{tikhonova_exploratory_2010,
	title = {An Exploratory Technique for Coherent Visualization of Time-varying Volume Data},
	volume = {29},
	copyright = {© 2010 The Author(s) Journal compilation © 2010 The Eurographics Association and Blackwell Publishing Ltd.},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2009.01690.x/abstract},
	doi = {10.1111/j.1467-8659.2009.01690.x},
	abstract = {The selection of an appropriate global transfer function is essential for visualizing time-varying simulation data. This is especially challenging when the global data range is not known in advance, as is often the case in remote and in-situ visualization settings. Since the data range may vary dramatically as the simulation progresses, volume rendering using local transfer functions may not be coherent for all time steps. We present an exploratory technique that enables coherent classification of time-varying volume data. Unlike previous approaches, which require pre-processing of all time steps, our approach lets the user explore the transfer function space without accessing the original {3D} data. This is useful for interactive visualization, and absolutely essential for in-situ visualization, where the entire simulation data range is not known in advance. Our approach generates a compact representation of each time step at rendering time in the form of ray attenuation functions, which are used for subsequent operations on the opacity and color mappings. The presented approach offers interactive exploration of time-varying simulation data that alleviates the cost associated with reloading and caching large data sets.},
	language = {en},
	number = {3},
	urldate = {2012-10-23},
	journal = {Computer Graphics Forum},
	author = {Tikhonova, A. and Correa, C. D. and Ma, K.-L.},
	year = {2010},
	keywords = {and texture, I.3.7 {[Computer} Graphics]: Three-Dimensional Graphics and {Realism—Color}, shading, shadowing},
	pages = {783-792},
	file = {Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\7PB9UU5V\Tikhonova et al. - 2010 - An Exploratory Technique for Coherent Visualizatio.pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\AUWQBDT3\abstract.html:text/html}
}

@mastersthesis{valverde-real-2010,
	title = {Real Time Rendering of Animated Volumetric Data},
	school = {University of Dublin, Trinity College},
	author = {Valverde, Luis},
	year = {2010}
}

@inproceedings{mensmann_gpu-supported_2010,
	title = {A {GPU-Supported} Lossless Compression Scheme for Rendering Time-Varying Volume Data},
	url = {http://viscg.uni-muenster.de/publications/2010/MRH10a},
	booktitle = {{IEEE/EG} International Symposium on Volume Graphics},
	publisher = {Eurographics Association},
	author = {Mensmann, Jörg and Ropinski, Timo and Hinrichs, Klaus H.},
	editor = {Westermann, Rüdiger and Kindlmann, Gordon},
	year = {2010},
	keywords = {voreen},
	pages = {109-116},
	file = {vg10-compression.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\BAQTWXUF\vg10-compression.pdf:application/pdf}
}

@article{wang_application-driven_2009,
	title = {Application-Driven Compression for Visualizing Large-Scale Time-Varying Volume Data},
	volume = {{PP}},
	issn = {0272-1716},
	doi = {10.1109/MCG.2009.104},
	abstract = {In many areas of science and engineering, the desires to study a problem at the highest possible resolution have led to an explosive growth of data. It is imperative to reduce the data to a manageable scale for analysis and visualization. For high-precision floating-point data, compressing the data solely based on values can only achieve a limited saving. Further reduction is possible with the fact that usually only a smaller subset of the data is of interest in analysis. In this paper, we present an application-driven approach to compressing large-scale time-varying volume data. Our method identifies a reference feature to partition the data into space-time blocks, which are compressed with various precisions depending on their association to the feature. Runtime decompression is performed with bit-wise texture packing and deferred filtering. We show that our method achieves high compression rates and interactive rendering while preserving fine details surrounding regions of interest. Such an application-driven approach points us to a promising direction for coping with the large data problems facing computational scientists.},
	number = {99},
	journal = {{IEEE} Computer Graphics and Applications},
	author = {Wang, C and Yu, H and Ma, K},
	year = {2009},
	pages = {1},
	file = {cga10-adc.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\AGQWPF3P\cga10-adc.pdf:application/pdf;IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\I3QE39SZ\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\MPMKKTAX\Wang et al. - 2009 - Application-Driven Compression for Visualizing Lar.pdf:application/pdf}
}

@phdthesis{garcia_parallel_2006,
	address = {Columbus, {OH}, {USA}},
	title = {Parallel time varying volume rendering on tile displays},
	abstract = {Volume rendering is a process with high computation demands. Time-Varying Volume Data {(TVVD)} increases the challenge not only for computing but also for loading and storing of the data in real time. Scientific fields are generating data at a much faster rate than processing power; thus parallel solutions are necessary for rendering such large datasets. Furthermore, tile displays provide more pixels to present the features of the phenomena under study with finer detail. However, current object-space partitioning schemes for parallel rendering can make load imbalance across processors very severe. This work provides an alternative based on wavelet theory. The size reduction of the data allows data migration and makes image-space partitioning schemes possible for commodity processors deployed in {PC-clusters.}},
	school = {Ohio State University},
	author = {Garcia, Antonio},
	year = {2006},
	note = {{AAI3197874}},
	file = {Garcia Antonio.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\72A53DRR\Garcia Antonio.pdf:application/pdf}
}

@incollection{serlie_computed_2003,
	series = {Lecture Notes in Computer Science},
	title = {Computed Cleansing for Virtual Colonoscopy Using a Three-Material Transition Model},
	copyright = {©2003 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-20464-0, 978-3-540-39903-2},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-39903-2_22},
	abstract = {Virtual colonoscopy is a non-invasive technique for the detection of polyps. Currently, a clean colon is required; as without cleansing the colonic wall cannot be segmented. Enhanced bowel preparation schemes opacify intraluminal remains to enable colon segmentation. Computed cleansing (as opposed to physical cleansing of the bowels) allows removal of tagged intraluminal remains. This paper describes a model that allows proper classification of transitions between three materials: gas, tissue and tagged intraluminal remains. The computed cleansing effectively detects and removes the remains from the data. Inspection of the ‘clean’ wall is possible using common surface visualization techniques.},
	number = {2879},
	urldate = {2012-11-20},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI} 2003},
	publisher = {Springer Berlin Heidelberg},
	author = {Serlie, Iwo and Truyen, Roel and Florie, Jasper and Post, Frits and Vliet, Lucas van and Vos, Frans},
	editor = {Ellis, Randy E. and Peters, Terry M.},
	month = jan,
	year = {2003},
	keywords = {Artificial Intelligence (incl. Robotics), cleansing, colonography, colonoscopy, Computer Graphics, Health Informatics, Image Processing and Computer Vision, Imaging / Radiology, Pattern Recognition, virtual endoscopy, volume segmentation},
	pages = {175--183},
	file = {Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\U7R3EGEX\Serlie et al. - 2003 - Computed Cleansing for Virtual Colonoscopy Using a.pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\EQQVAEV9\978-3-540-39903-2_22.html:text/html}
}

@article{rezk-salama_opacity_2006,
	title = {Opacity Peeling for Direct Volume Rendering},
	volume = {25},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2006.00979.x/abstract},
	doi = {10.1111/j.1467-8659.2006.00979.x},
	abstract = {The most important technique to visualize {3D} scalar data, as they arise e.g. in medicine from tomographic measurement, is direct volume rendering. A transfer function maps the scalar values to optical properties which are used to solve the integral of light transport in participating media. Many medical data sets, especially {MRI} data, however, are difficult to visualize due to different tissue types being represented by the same scalar value. The main problem is that interesting structures will be occluded by less important structures because they share the same range of data values. Occlusion, however, is a view-dependent problem and cannot be solved easily by transfer function design. This paper proposes a new method to display different entities inside the volume data in a single rendering pass. The proposed opacity peeling technique reveals structures in the data set that cannot be visualized directly by one-or multi-dimensional transfer functions without explicit segmentation. We also demonstrate real-time implementations using texture mapping and multiple render {targets.Categories} and Subject Descriptors (according to {ACM} {CCS):} I.3.7 {[Computer} Graphics]: Three-Dimensional Graphics and Realism},
	language = {en},
	number = {3},
	urldate = {2012-11-20},
	journal = {Computer Graphics Forum},
	author = {Rezk-Salama, Christof and Kolb, Andreas},
	year = {2006},
	pages = {597-606},
	file = {Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\TQQXJMAD\Rezk-Salama and Kolb - 2006 - Opacity Peeling for Direct Volume Rendering.pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\XFUU898M\abstract.html:text/html}
}

@phdthesis{neophytou_generalized_2006,
	address = {Stony Brook, {NY}, {USA}},
	title = {A generalized framework for interactive volumetric point-based rendering},
	abstract = {Volume Visualization is the process of displaying volumetric data represented as sample points on a regular or irregular {3D} grid. The data is currently produced by medical scanners such as {MRI}, {CT}, etc, and by numerical methods such as scientific simulations. Techniques that have been proposed for this purpose over the years include direct volume-rendering which seeks to capture a visual impression of the complete {3D} dataset by accounting for the emission and light absorption effects of all the data elements. This technique is effective when rendering volumes of space-filling gasses or volumes composed of many micro-surfaces, such as tissue in medical datasets. We have focused our efforts on Point-Based Volume rendering and specifically on the image-aligned post-shaded splatting algorithm which was proposed as a remedy to the drawbacks of existing algorithms with special focus on image quality. In the course of this dissertation, we will follow the evolution of this algorithm through several stages of maturity. Our contributions to this algorithm include the ability to render efficient grid topologies with significant storage and rendering time gains for both {3D} as well as time-varying datasets. We have also proposed a post-convolved volume rendering technique to accelerate magnified viewing. The framework has been ported to a hardware-accelerated implementation that has the ability to interactively slice point based volumes and was optimized to take full advantage of the splatting algorithm's inherent advantages for empty-space skipping and early splat elimination. Finally, we have generalized our framework for the interactive rendering of irregular datasets consisting of ellipsoidal kernels of arbitrary size and orientation. Our suggested algorithm outperforms existing hardware approaches by about an order of magnitude in terms of throughput. Different modeling approaches have been explored for encoding the data using either {RBF} (Radial Basis Functions) or {EBF} (Elliptical Basis Functions), and new methods are proposed for ongoing/future work. The final goal is a truly general point-based hardware-accelerated framework for the interactive visualization of both regular and irregular volumetric data in high-fidelity.},
	school = {State University of New York at Stony Brook},
	author = {Neophytou, Neophytos},
	year = {2006},
	note = {{AAI3258861}},
	file = {10.1.1.87.8944.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\HSDPER48\10.1.1.87.8944.pdf:application/pdf}
}










@inproceedings{kindlmann_semi-automatic_1998,
	title = {Semi-automatic generation of transfer functions for direct volume rendering},
	doi = {10.1109/SVV.1998.729588},
	abstract = {Although direct volume rendering is a powerful tool for visualizing complex structures within volume data, the size and complexity of the parameter space controlling the rendering process makes generating an informative rendering challenging. In particular, the specification of the transfer function-the mapping from data values to renderable optical properties-is frequently a time consuming and unintuitive task. Ideally, the data being visualized should itself suggest an appropriate transfer function that brings out the features of interest without obscuring them with elements of little importance. We demonstrate that this is possible for a large class of scalar volume data, namely that where the regions of interest are the boundaries between different materials. A transfer function which makes boundaries readily visible can be generated from the relationship between three quantities: the data value and its first and second directional derivatives along the gradient direction. A data structure we term the histogram volume captures the relationship between these quantities throughout the volume in a position independent, computationally efficient fashion. We describe the theoretical importance of the quantities measured by the histogram volume, the implementation issues in its calculation, and a method for semiautomatic transfer function generation through its analysis. We conclude with results of the method on both idealized synthetic data as well as real world datasets.},
	booktitle = {{IEEE} Symposium on Volume Visualization, 1998},
	author = {Kindlmann, G. and Durkin, {J.W.}},
	year = {1998},
	keywords = {complex structure visualization, Computer Graphics, data structure, data structures, data values, data visualisation, data visualization, Direct volume rendering, directional derivatives, gradient direction, histogram volume, Histograms, idealized synthetic data, informative rendering, parameter space, Power generation, Process control, real world datasets, renderable optical properties, rendering (computer graphics), rendering process, scalar volume data, semi automatic generation, semiautomatic transfer function generation, Size control, transfer function, transfer functions, unintuitive task, Volume measurement},
	pages = {79--86},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\KCAR6R7J\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\Z4775FAJ\Kindlmann and Durkin - 1998 - Semi-automatic generation of transfer functions fo.pdf:application/pdf}
}

@article{bruckner_isosurface_2010,
	title = {Isosurface Similarity Maps},
	volume = {29},
	copyright = {© 2010 The Author(s) Journal compilation © 2010 The Eurographics Association and Blackwell Publishing Ltd.},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2009.01689.x/abstract},
	doi = {10.1111/j.1467-8659.2009.01689.x},
	abstract = {In this paper, we introduce the concept of isosurface similarity maps for the visualization of volume data. Iso-surface similarity maps present structural information of a volume data set by depicting similarities between individual isosurfaces quantified by a robust information-theoretic measure. Unlike conventional histograms, they are not based on the frequency of isovalues and/or derivatives and therefore provide complementary information. We demonstrate that this new representation can be used to guide transfer function design and visualization parameter specification. Furthermore, we use isosurface similarity to develop an automatic parameter-free method for identifying representative isovalues. Using real-world data sets, we show that isosurface similarity maps can be a useful addition to conventional classification techniques.},
	language = {en},
	number = {3},
	urldate = {2012-11-15},
	journal = {Computer Graphics Forum},
	author = {Bruckner, Stefan and M{\"o}ller, Torsten},
	year = {2010},
	keywords = {[Computer, Algorithms, {Generation—Display}, Graphics]:, I.3.3, {Picture/Image}},
	pages = {773-782},
	file = {Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\MPXWB8WA\Bruckner and Möller - 2010 - Isosurface Similarity Maps.pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\8GH9SPTQ\abstract.html:text/html}
}

@article{lorensen_marching_1987,
	title = {Marching cubes: A high resolution {3D} surface construction algorithm},
	volume = {21},
	issn = {0097-8930},
	shorttitle = {Marching cubes},
	url = {http://doi.acm.org/10.1145/37402.37422},
	doi = {10.1145/37402.37422},
	abstract = {We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from {3D} medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the {3D} medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original {3D} data. Results from computed tomography ({CT)}, magnetic resonance ({MR)}, and single-photon emission computed tomography ({SPECT)} illustrate the quality and functionality of marching cubes. We also discuss improvements that decrease processing time and add solid modeling capabilities.},
	number = {4},
	urldate = {2013-05-16},
	journal = {{SIGGRAPH} Computer Graphics},
	author = {Lorensen, William E. and Cline, Harvey E.},
	month = aug,
	year = {1987},
	pages = {163-169},
	file = {ACM Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\T2NQCW78\Lorensen and Cline - 1987 - Marching cubes A high resolution 3D surface const.pdf:application/pdf}
}

@inproceedings{bajaj_contour_1997,
	title = {The contour spectrum},
	doi = {10.1109/VISUAL.1997.663875},
	abstract = {The authors introduce the contour spectrum, a user interface component that improves qualitative user interaction and provides real-time exact quantification in the visualization of isocontours. The contour spectrum is a signature consisting of a variety of scalar data and contour attributes, computed over the range of scalar values {ω∈R.} They explore the use of surface, area, volume, and gradient integral of the contour that are shown to be univariate B-spline functions of the scalar value ω for multi-dimensional unstructured triangular grids. These quantitative properties are calculated in real-time and presented to the user as a collection of signature graphs (plots of functions of ω) to assist in selecting relevant isovalues ω 0 for informative visualization. For time-varying data, these quantitative properties can also be computed over time, and displayed using a {2D} interface, giving the user an overview of the time-varying function, and allowing interaction in both isovalue and time step. The effectiveness of the current system and potential extensions are discussed.},
	booktitle = {Visualization '97., Proceedings},
	author = {Bajaj, {C.L.} and Bremer, P.-T. and Schikore, {D.R.}},
	year = {1997},
	keywords = {{2D} interface, area, Computer displays, Computer interfaces, contour attributes, contour spectrum, data acquisition, data visualisation, data visualization, gradient integral, Image analysis, informative visualization, isocontour visualization, isovalue selection, Knowledge based systems, multi-dimensional unstructured triangular grids, Postal services, qualitative user interaction, real-time exact quantification, scalar data, signature graphs, Spline, surface, time step, time-varying data, transfer functions, univariate B-spline functions, user interface component, user interfaces, Volume},
	pages = {167--173},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\CN2S2H2X\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\NUWPK37M\Bajaj et al. - 1997 - The contour spectrum.pdf:application/pdf}
}

@article{levoy_display_1988,
	title = {Display of surfaces from volume data},
	volume = {8},
	issn = {0272-1716},
	doi = {10.1109/38.511},
	abstract = {The application of volume-rendering techniques to the display of surfaces from sampled scalar functions of three spatial dimensions is discussed. It is not necessary to fit geometric primitives to the sampled data; images are formed by directly shading each sample and projecting it onto the picture plane. Surface-shading calculations are performed at every voxel with local gradient vectors serving as surface normals. In a separate step, surface classification operators are applied to compute a partial opacity of every voxel. Operators that detect isovalue contour surfaces and region boundary surfaces are examined. The technique is simple and fast, yet displays surfaces exhibiting smooth silhouettes and few other aliasing artifacts. The use of selective blurring and supersampling to further improve image quality is described. Examples from molecular graphics and medical imaging are given.{\textless}{\textgreater}},
	number = {3},
	journal = {{IEEE} Computer Graphics and Applications},
	author = {Levoy, M.},
	year = {1988},
	keywords = {Application software, Biomedical imaging, Computed tomography, Computer Graphics, data visualization, Detectors, Displays, isovalue contour surfaces, medical imaging, molecular graphics, picture plane, region boundary surfaces, rendering (computer graphics), smooth silhouettes, surface classification, surface fitting, Surface treatment, Volume Data, volume-rendering},
	pages = {29--37},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\5JJN2BCW\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\QIWVZ394\Levoy - 1988 - Display of surfaces from volume data.pdf:application/pdf}
}

@inproceedings{kniss_interactive_2001,
	address = {Washington, {DC}, {USA}},
	series = {{VIS} '01},
	title = {Interactive volume rendering using multi-dimensional transfer functions and direct manipulation widgets},
	isbn = {0-7803-7200-X},
	url = {http://dl.acm.org/citation.cfm?id=601671.601711},
	abstract = {Most direct volume renderings produced today employ one-dimensional transfer functions, which assign color and opacity to the volume based solely on the single scalar quantity which comprises the dataset. Though they have not received widespread attention, multi-dimensional transfer functions are a very effective way to extract specific material boundaries and convey subtle surface properties. However, identifying good transfer functions is difficult enough in one dimension, let alone two or three dimensions. This paper demonstrates an important class of three-dimensional transfer functions for scalar data (based on data value, gradient magnitude, and a second directional derivative), and describes a set of direct manipulation widgets which make specifying such transfer functions intuitive and convenient. We also describe how to use modern graphics hardware to interactively render with multi-dimensional transfer functions. The transfer functions, widgets, and hardware combine to form a powerful system for interactive volume exploration.},
	urldate = {2013-05-07},
	booktitle = {Proceedings of the conference on Visualization '01},
	publisher = {{IEEE} Computer Society},
	author = {Kniss, Joe and Kindlmann, Gordon and Hansen, Charles},
	year = {2001},
	keywords = {direct manipulation widgets, Direct volume rendering, graphics hardware, Multi-Dimensional Transfer Functions, Volume Visualization},
	pages = {255-262},
	file = {ACM Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\NJ6XH437\Kniss et al. - 2001 - Interactive volume rendering using multi-dimension.pdf:application/pdf}
}

@article{pfister_transfer_2001,
	title = {The transfer function bake-off},
	volume = {21},
	issn = {0272-1716},
	doi = {10.1109/38.920623},
	abstract = {Direct volume rendering is a key technology for visualizing large {3D} data sets from scientific or medical applications. Transfer functions are particularly important to the quality of direct volume-rendered images. A transfer function assigns optical properties, such as color and opacity, to original values of the data set being visualized. Unfortunately, finding good transfer functions proves difficult. It is one of the major problems in volume visualization. The article examines four of the currently most promising approaches to transfer function design. The four approaches are: trial and error, with minimum computer aid; data-centric, with no underlying assumed model; data-centric, using an underlying data model; and image-centric, using organized sampling},
	number = {3},
	journal = {{IEEE} Computer Graphics and Applications},
	author = {Pfister, H. and Lorensen, B. and Bajaj, C. and Kindlmann, G. and Schroeder, W. and Avila, {L.S.} and Raghu, {K.M.} and Machiraju, R. and Lee, Jinho},
	year = {2001},
	keywords = {Color, Computer errors, data visualisation, data visualization, data-centric, Direct volume rendering, direct volume-rendered images, Heart, Image generation, image-centric, Isosurfaces, Knee, large {3D} data set visualization, Magnetic Resonance Imaging, opacity, optical properties, organized sampling, rendering (computer graphics), Teeth, transfer function, transfer functions, trial and error, underlying data model, Volume Visualization},
	pages = {16--22},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\4JF8848P\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\RZ6HNR3G\Pfister et al. - 2001 - The transfer function bake-off.pdf:application/pdf}
}

@article{kniss_multidimensional_2002,
	title = {Multidimensional Transfer Functions for Interactive Volume Rendering},
	volume = {8},
	issn = {1077-2626},
	url = {http://dx.doi.org/10.1109/TVCG.2002.1021579},
	doi = {10.1109/TVCG.2002.1021579},
	abstract = {Most direct volume renderings produced today employ one-dimensional transfer functions which assign color and opacity to the volume based solely on the single scalar quantity which comprises the data set. Though they have not received widespread attention, multidimensional transfer functions are a very effective way to extract materials and their boundaries for both scalar and multivariate data. However, identifying good transfer functions is difficult enough in one dimension, let alone two or three dimensions. This paper demonstrates an important class of three-dimensional transfer functions for scalar data, and describes the application of multidimensional transfer functions to multivariate data. We present a set of direct manipulation widgets that make specifying such transfer functions intuitive and convenient. We also describe how to use modern graphics hardware to both interactively render with multidimensional transfer functions and to provide interactive shadows for volumes. The transfer functions, widgets, and hardware combine to form a powerful system for interactive volume exploration.},
	number = {3},
	urldate = {2013-05-01},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Kniss, Joe and Kindlmann, Gordon and Hansen, Charles},
	month = jul,
	year = {2002},
	keywords = {direct manipulation widgets, Direct volume rendering, graphics hardware., multidimensional transfer functions, Volume Visualization},
	pages = {270-285},
	file = {kniss_tvcg02-small.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\9UNIT82H\kniss_tvcg02-small.pdf:application/pdf}
}

@inproceedings{jankun-kelly_study_2001,
	address = {Aire-la-Ville, Switzerland, Switzerland},
	series = {{VG'01}},
	title = {A study of transfer function generation for time-varying volume data},
	isbn = {3-211-83737-X},
	url = {http://dx.doi.org/10.2312/VG/VG01/051-066},
	doi = {10.2312/VG/VG01/051-066},
	abstract = {The proper usage and creation of transfer functions for time-varying data sets is an often ignored problem in volume visualization. Although methods and guidelines exist for time-invariant data, little formal study for the timevarying case has been performed. This paper examines this problem, and reports the study that we have conducted to determine how the dynamic behavior of time-varying data may be captured by a single or small set of transfer functions. The criteria which dictate when more than one transfer function is needed were also investigated. Four data sets with different temporal characteristics were used for our study. Results obtained using two different classes of methods are discussed, along with lessons learned. These methods, including a new multiresolution opacity map approach, can be used for semi-automatic generation of transfer functions to explore large-scale time-varying data sets.},
	urldate = {2012-11-06},
	booktitle = {Proceedings of the 2001 Eurographics conference on Volume Graphics},
	publisher = {Eurographics Association},
	author = {Jankun-Kelly, T. J. and Ma, Kwan-Liu},
	year = {2001},
	pages = {51-66},
	file = {10.1.1.64.8722.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\37SIAVEV\10.1.1.64.8722.pdf:application/pdf}
}

@article{woodring_semi-automatic_2009,
	title = {Semi-Automatic Time-Series Transfer Functions via Temporal Clustering and Sequencing},
	volume = {28},
	copyright = {© 2009 The Author(s) Journal compilation © 2009 The Eurographics Association and Blackwell Publishing Ltd.},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2009.01472.x/abstract},
	doi = {10.1111/j.1467-8659.2009.01472.x},
	abstract = {When creating transfer functions for time-varying data, it is not clear what range of values to use for classification, as data value ranges and distributions change over time. In order to generate time-varying transfer functions, we search the data for classes that have similar behavior over time, assuming that data points that behave similarly belong to the same feature. We utilize a method we call temporal clustering and sequencing to find dynamic features in value space and create a corresponding transfer function. First, clustering finds groups of data points that have the same value space activity over time. Then, sequencing derives a progression of clusters over time, creating chains that follow value distribution changes. Finally, the cluster sequences are used to create transfer functions, as sequences describe the value range distributions over time in a data set.},
	language = {en},
	number = {3},
	urldate = {2012-11-07},
	journal = {Computer Graphics Forum},
	author = {Woodring, Jonathan and Shen, Han-Wei},
	year = {2009},
	keywords = {[I.3.7]:, Applications, Computer, Graphics},
	pages = {791-798},
	file = {Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\J2BICZDM\Woodring and Shen - 2009 - Semi-Automatic Time-Series Transfer Functions via .pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\ZM4UWMH9\abstract.html:text/html}
}

@article{nguyen_clustering-based_2012,
	title = {A clustering-based system to automate transfer function design for medical image visualization},
	volume = {28},
	issn = {0178-2789, 1432-2315},
	url = {http://link.springer.com/article/10.1007/s00371-011-0634-3},
	doi = {10.1007/s00371-011-0634-3},
	abstract = {Finding good transfer functions for rendering medical volumes is difficult, non-intuitive, and time-consuming. We introduce a clustering-based framework for the automatic generation of transfer functions for volumetric data. The system first applies mean shift clustering to oversegment the volume boundaries according to their low-high ({LH)} values and their spatial coordinates, and then uses hierarchical clustering to group similar voxels. A transfer function is then automatically generated for each cluster such that the number of occlusions is reduced. The framework also allows for semi-automatic operation, where the user can vary the hierarchical clustering results or the transfer functions generated. The system improves the efficiency and effectiveness of visualizing medical images and is suitable for medical imaging applications.},
	language = {en},
	number = {2},
	urldate = {2012-11-15},
	journal = {The Visual Computer},
	author = {Nguyen, Binh P. and Tay, Wei-Liang and Chui, Chee-Kong and Ong, Sim-Heng},
	month = feb,
	year = {2012},
	keywords = {Artificial Intelligence (incl. Robotics), Clustering, Computer Graphics, Computer Science, general, Image Processing and Computer Vision, {LH} histogram, Transfer function design, volume rendering},
	pages = {181--191},
	file = {Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\FKFK3BTD\Nguyen et al. - 2012 - A clustering-based system to automate transfer fun.pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\N34J54PI\s00371-011-0634-3.html:text/html}
}

@inproceedings{brambilla_illustrative_2012,
	title = {Illustrative Flow Visualization: State of the Art, Trends and Challenges},
	location = {Cagliari, Italy},
	url = {http://diglib.eg.org/EG/DL/conf/EG2012/stars/075-094.pdf},
	doi = {10.2312/conf/EG2012/stars/075-094},
	abstract = {Flow visualization is a well established branch of scientific visualization and it currently represents an invaluable resource to many fields, like automotive design, meteorology and medical imaging. Thanks to the capabilities of modern hardware, flow datasets are increasing in size and complexity, and traditional flow visualization techniques need to be updated and improved in order to deal with the upcoming challenges. A fairly recent trend to enhance the expressiveness of scientific visualization is to produce depictions of physical phenomena taking inspiration from traditional handcrafted illustrations: this approach is known as illustrative visualization, and it is getting a foothold in flow visualization as well. In this state of the art report we give an overview of the existing illustrative techniques for flow visualization, we highlight which problems have been solved and which issues still need further investigation, and, finally, we provide remarks and insights on the current trends in illustrative flow visualization.},
	booktitle = {{EuroGraphics} 2012 State of the Art Reports ({STARs)}},
	author = {Brambilla, Andrea and Carnecky, Robert and Peikert, Ronald and Viola, Ivan and Hauser, Helwig},
	year = {2012},
	pages = {75-94},
	file = {Brambilla12Illustrative.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\K8Q6HABQ\Brambilla12Illustrative.pdf:application/pdf;Brambilla12Illustrative.pptx:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\6724H32P\Brambilla12Illustrative.pptx:application/vnd.openxmlformats-officedocument.presentationml.presentation}
}

@article{viola_importance-driven_2005,
	title = {Importance-Driven Feature Enhancement in Volume Visualization},
	volume = {11},
	issn = {1077-2626},
	url = {http://dx.doi.org/10.1109/TVCG.2005.62},
	doi = {10.1109/TVCG.2005.62},
	abstract = {This paper presents importance-driven feature enhancement as a technique for the automatic generation of cut-away and ghosted views out of volumetric data. The presented focus+context approach removes or suppresses less important parts of a scene to reveal more important underlying information. However, less important parts are fully visible in those regions, where important visual information is not lost, i.e., more relevant features are not occluded. Features within the volumetric data are first classified according to a new dimension, denoted as object importance. This property determines which structures should be readily discernible and which structures are less important. Next, for each feature, various representations (levels of sparseness) from a dense to a sparse depiction are defined. Levels of sparseness define a spectrum of optical properties or rendering styles. The resulting image is generated by ray-casting and combining the intersected features proportional to their importance (importance compositing). The paper includes an extended discussion on several possible schemes for levels of sparseness specification. Furthermore, different approaches to importance compositing are treated.},
	number = {4},
	urldate = {2013-05-12},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Viola, Ivan and Kanitsar, Armin and Gr{\"o}ller, M. Eduard},
	month = jul,
	year = {2005},
	keywords = {Algorithms, Biomedical imaging, biomedical optical imaging, Computer Graphics, Computer Simulation, data visualisation, Data visualization, feature extraction, {Focus+Context} Techniques, focus-context approach, Focusing, hidden feature removal, illustrative techniques., image enhancement, Image Interpretation, Computer-Assisted, Imaging, Three-Dimensional, importance-driven feature enhancement, Index Terms- View-dependent visualization, Layout, Lesions, level-of-detail techniques, Liver neoplasms, Medical diagnostic imaging, Models, Biological, Numerical Analysis, Computer-Assisted, Online Systems, Pattern Recognition, Automated, ray tracing, ray-casting, rendering (computer graphics), shape, sparseness specification, User-Computer Interface, visual databases, volume rendering, Volume Visualization},
	pages = {408-418},
	file = {01432686.pdf:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\TXVS4V7B\\01432686.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\REKRXQ25\\articleDetails.html:text/html}
}

@inproceedings{stompel_visualization_2002,
	address = {Washington, {DC}, {USA}},
	series = {{PG} '02},
	title = {Visualization of Multidimensional, Multivariate Volume Data Using Hardware-Accelerated Non-Photorealistic Rendering Techniques},
	isbn = {0-7695-1784-6},
	url = {http://dl.acm.org/citation.cfm?id=826030.826635},
	abstract = {This paper presents a set of feature enhancement techniques coupled with hardware-accelerated non-photorealistic rendering for generating more perceptually effective visualizations of multidimensional, multivariate volume data, such as those obtained from typical computational fluid dynamics simulations. For time-invariant data, one or more variables are used to either highlight important features in another variable, or add contextural information to the visualization. For time-varying data, rendering of each time step also takes into account the values at neighboring time steps to reinforce the perception of the changingfeatures in the data over time. With hardware-accelerated rendering, interactive visualization becomes possible leading to increased explorability and comprehension of the data.},
	urldate = {2013-05-12},
	booktitle = {Proceedings of the 10th Pacific Conference on Computer Graphics and Applications},
	publisher = {{IEEE} Computer Society},
	author = {Stompel, Aleksander and Lum, Eric B. and Ma, Kwan-Liu},
	year = {2002},
	keywords = {animation, hardware-accelerated rendering, multidimensional data, multivariate data, non-photorealistic rendering, scientific visualization, streamlines, stroke based rendering, vector field, Visual Perception, volume rendering},
	pages = {394},
	file = {FeatureEnhancedVisualizationofMultidimensionalMultivariateVolumeDataUsingNonphotorealisticRenderingTechniques.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\NNHBN7P3\FeatureEnhancedVisualizationofMultidimensionalMultivariateVolumeDataUsingNonphotorealisticRenderingTechniques.pdf:application/pdf}
}

@article{maciejewski_structuring_2009,
	title = {Structuring Feature Space: A Non-Parametric Method for Volumetric Transfer Function Generation},
	volume = {15},
	issn = {1077-2626},
	shorttitle = {Structuring Feature Space},
	doi = {10.1109/TVCG.2009.185},
	abstract = {The use of multi-dimensional transfer functions for direct volume rendering has been shown to be an effective means of extracting materials and their boundaries for both scalar and multivariate data. The most common multi-dimensional transfer function consists of a two-dimensional ({2D)} histogram with axes representing a subset of the feature space (e.g., value vs. value gradient magnitude), with each entry in the {2D} histogram being the number of voxels at a given feature space pair. Users then assign color and opacity to the voxel distributions within the given feature space through the use of interactive widgets (e.g., box, circular, triangular selection). Unfortunately, such tools lead users through a trial-and-error approach as they assess which data values within the feature space map to a given area of interest within the volumetric space. In this work, we propose the addition of non-parametric clustering within the transfer function feature space in order to extract patterns and guide transfer function generation. We apply a non-parametric kernel density estimation to group voxels of similar features within the {2D} histogram. These groups are then binned and colored based on their estimated density, and the user may interactively grow and shrink the binned regions to explore feature boundaries and extract regions of interest. We also extend this scheme to temporal volumetric data in which time steps of {2D} histograms are composited into a histogram volume. A three-dimensional ({3D)} density estimation is then applied, and users can explore regions within the feature space across time without adjusting the transfer function at each time step. Our work enables users to effectively explore the structures found within a feature space of the volume and provide a context in which the user can understand how these structures relate to their volumetric data. We provide tools for enhanced exploration and manipulation of the transfer function, and we show that the initial t ransfer function generation serves as a reasonable base for volumetric rendering, reducing the trial-and-error overhead typically found in transfer function design.},
	number = {6},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Maciejewski, R. and Woo, Insoo and Chen, Wei and Ebert, {D.S.}},
	year = {2009},
	keywords = {Algorithms, Cluster Analysis, colour graphics, Computer Graphics, data mining, Diagnostic Imaging, Direct volume rendering, feature extraction, Histograms, Humans, Image Processing, Computer-Assisted, Kernel, kernel density estimation, Multi-Dimensional Transfer Functions, nonparametric clustering, rendering (computer graphics), Shape, Statistics, Nonparametric, temporal volume rendering, three-dimensional density estimation, Transfer function design, transfer function feature space, transfer functions, two-dimensional histogram, volume rendering, volumetric transfer function generation},
	pages = {1473--1480},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\45J3J883\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\NZ5KPR4U\Maciejewski et al. - 2009 - Structuring Feature Space A Non-Parametric Method.pdf:application/pdf}
}

@inproceedings{park_multi-dimensional_2004,
	title = {Multi-dimensional transfer functions for interactive {3D} flow visualization},
	doi = {10.1109/PCCGA.2004.1348348},
	abstract = {Transfer functions are a standard technique used in volume rendering to assign color and opacity to a volume of a scalar field. Multidimensional transfer functions ({MDTFs)} have proven to be an effective way to extract specific features with subtle properties. As {3D} texture-based methods gain widespread popularity for the visualization of steady and unsteady flow field data, there is a need to define and apply similar {MDTFs} to interactive {3D} flow visualization. We exploit flow field properties such as velocity, gradient, curl, helicity, and divergence using vector calculus methods to define an {MDTF} that can be used to extract and track features in a flow field. We show how the defined {MDTF} can be applied to interactive {3D} flow visualization by combining them with state-of-the-art texture-based flow visualization of steady and unsteady fields. We demonstrate that {MDTFs} can be used to help alleviate the problem of occlusion, which is one of the main inherent drawbacks of {3D} texture-based flow visualization techniques. In our implementation, we make use of current graphics hardware to obtain interactive frame rates.},
	booktitle = {12th Pacific Conference on Computer Graphics and Applications, 2004. {PG} 2004. Proceedings},
	author = {Park, {S.W.} and Budge, B. and Linsen, L. and Hamann, B. and Joy, {K.I.}},
	month = oct,
	year = {2004},
	keywords = {data visualisation, digital simulation, feature extraction, feature tracking, flow visualisation, hidden feature removal, image texture, interactive {3D} flow visualization, interactive systems, multidimensional transfer functions, rendering (computer graphics), texture-based flow visualization, transfer functions, vector calculus, volume rendering},
	pages = {177 -- 185},
	file = {01348348.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\EI5APGPU\01348348.pdf:application/pdf;IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\TII5GVKZ\abs_all.html:text/html}
}

@article{wang_automating_2012,
	title = {Automating Transfer Function Design with Valley Cell-Based Clustering of {2D} Density Plots},
	volume = {31},
	copyright = {© 2012 The Author(s) Computer Graphics Forum © 2012 The Eurographics Association and Blackwell Publishing Ltd.},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2012.03122.x/abstract},
	doi = {10.1111/j.1467-8659.2012.03122.x},
	abstract = {Two-dimensional transfer functions are an effective and well-accepted tool in volume classification. The design of them mostly depends on the user's experience and thus remains a challenge. Therefore, we present an approach in this paper to automate the transfer function design based on {2D} density plots. By exploiting their smoothness, we adopted the Morse theory to automatically decompose the feature space into a set of valley cells. We design a simplification process based on cell separability to eliminate cells which are mainly caused by noise in the original volume data. Boundary persistence is first introduced to measure the separability between adjacent cells and to suitably merge them. Afterward, a reasonable classification result is achieved where each cell represents a potential feature in the volume data. This classification procedure is automatic and facilitates an arbitrary number and shape of features in the feature space. The opacity of each feature is determined by its persistence and size. To further incorporate the user's prior knowledge, a hierarchical feature representation is created by successive merging of the cells. With this representation, the user is allowed to merge or split features of interest and set opacity and color freely. Experiments on various volumetric data sets demonstrate the effectiveness and usefulness of our approach in transfer function generation.},
	language = {en},
	number = {3pt4},
	urldate = {2013-04-30},
	journal = {Computer Graphics Forum},
	author = {Wang, Yunhai and Zhang, Jian and Lehmann, Dirk J. and Theisel, Holger and Chi, Xuebin},
	year = {2012},
	keywords = {[Computer, and, curve, generation, {Generation—Line}, Graphics]:, I.3.3, {Picture/Image}},
	pages = {1295-1304},
	file = {Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\WCB3V9HR\Wang et al. - 2012 - Automating Transfer Function Design with Valley Ce.pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\V6WVW7PW\abstract.html:text/html}
}

@inproceedings{svakhine_illustration_2005,
	title = {Illustration and photography inspired visualization of flows and volumes},
	doi = {10.1109/VISUAL.2005.1532858},
	abstract = {Understanding and analyzing complex volumetrically varying data is a difficult problem. Many computational visualization techniques have had only limited success in succinctly portraying the structure of three-dimensional turbulent flow. Motivated by both the extensive history and success of illustration and photographic flow visualization techniques, we have developed a new interactive volume rendering and visualization system for flows and volumes that simulates and enhances traditional illustration, experimental advection, and photographic flow visualization techniques. Our system uses a combination of varying focal and contextual illustrative styles, new advanced two-dimensional transfer functions, enhanced Schlieren and shadowgraphy shaders, and novel oriented structure enhancement techniques to allow interactive visualization, exploration, and comparative analysis of scalar, vector, and time-varying volume datasets. Both traditional illustration techniques and photographic flow visualization techniques effectively reduce visual clutter by using compact oriented structure information to convey three-dimensional structures. Therefore, a key to the effectiveness of our system is using one-dimensional (Schlieren and shadowgraphy) and two-dimensional (silhouette) oriented structural information to reduce visual clutter, while still providing enough three-dimensional structural information for the user's visual system to understand complex three-dimensional flow data. By combining these oriented feature visualization techniques with flexible transfer function controls, we can visualize scalar and vector data, allow comparative visualization of flow properties in a succinct, informative manner, and provide continuity for visualizing time-varying datasets.},
	booktitle = {{IEEE} Visualization, 2005. {VIS} 05},
	author = {Svakhine, {N.A.} and Jang, Yun and Ebert, D. and Gaither, K.},
	month = oct,
	year = {2005},
	keywords = {Color, Computer Graphics, contextual illustrative styles, data visualisation, data visualization, Electric shock, flow visualisation, interactive systems, Interactive Volume Rendering, photographic flow visualization techniques, photography, rendering (computer graphics), schlieren systems, shadowgraphy shaders, Space vehicles, Stress, structure enhancement techniques, Temperature, three-dimensional turbulent flow, time-varying volume datasets, transfer functions, turbulence, two-dimensional transfer functions, visual clutter, Visual System},
	pages = {687--694},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\VEFJ4TW7\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\8WSWHD43\Svakhine et al. - Illustration and photography inspired visualizatio.pdf:application/pdf}
}

@article{joshi_case_2009,
	title = {Case Study on Visualizing Hurricanes Using Illustration-Inspired Techniques},
	volume = {15},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2008.105},
	abstract = {The devastating power of hurricanes was evident during the 2005 hurricane season, the most active season on record. This has prompted increased efforts by researchers to understand the physical processes that underlie the genesis, intensification, and tracks of hurricanes. This research aims at facilitating an improved understanding into the structure of hurricanes with the aid of visualization techniques. Our approach was developed by a mixed team of visualization and domain experts. To better understand these systems, and to explore their representation in {NWP} models, we use a variety of illustration-inspired techniques to visualize their structure and time evolution. Illustration-inspired techniques aid in the identification of the amount of vertical wind shear in a hurricane, which can help meteorologists predict dissipation. Illustration-style visualization, in combination with standard visualization techniques, helped explore the vortex rollup phenomena and the mesovortices contained within. We evaluated the effectiveness of our visualization with the help of six hurricane experts. The expert evaluation showed that the illustration-inspired techniques were preferred over existing tools. Visualization of the evolution of structural features is a prelude to a deeper visual analysis of the underlying dynamics.},
	number = {5},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Joshi, A. and Caban, J. and Rheingans, P. and Sparling, L.},
	month = oct,
	year = {2009},
	keywords = {data visualisation, geophysics computing, hurricanes, illustration-inspired visualization, illustration-style visualization, mesovortice, meteorology, {NWP} model, storms, visual analysis, vortex rollup phenomena},
	pages = {709 --718},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\TFEPHQTN\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\ZZ327BHR\Joshi et al. - 2009 - Case Study on Visualizing Hurricanes Using Illustr.pdf:application/pdf}
}

@article{joshi_evaluation_2008,
	title = {Evaluation of illustration-inspired techniques for time-varying data visualization},
	volume = {27},
	copyright = {© 2008 The Author(s) Journal compilation © 2008 The Eurographics Association and Blackwell Publishing Ltd.},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2008.01235.x/abstract},
	doi = {10.1111/j.1467-8659.2008.01235.x},
	abstract = {Illustration-inspired techniques have provided alternative ways to visualize time-varying data. Techniques such as speedlines, flow ribbons, strobe silhouettes and opacity-based techniques provide temporal context to the current timestep being visualized. We evaluated the effectiveness of these illustrative techniques by conducting a user study. We compared the ability of subjects to visually track features using snapshots, snapshots augmented by illustration techniques, animations, and animations augmented by illustration techniques. User accuracy, time required to perform a task, and user confidence were used as measures to evaluate the techniques. The results indicate that the use of illustration-inspired techniques provides a significant improvement in user accuracy and the time required to complete the task. Subjects performed significantly better on each metric when using augmented animations as compared to augmented snapshots.},
	language = {en},
	number = {3},
	urldate = {2013-05-08},
	journal = {Computer Graphics Forum},
	author = {Joshi, Alark and Rheingans, Penny},
	year = {2008},
	keywords = {[Human, factors]:, H.1.2},
	pages = {999-1006},
	file = {Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\ZA5NM26G\Joshi and Rheingans - 2008 - Evaluation of illustration-inspired techniques for.pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\ZKSGD5UU\abstract.html:text/html}
}

@inproceedings{joshi_illustration-inspired_2005,
	title = {Illustration-inspired techniques for visualizing time-varying data},
	doi = {10.1109/VISUAL.2005.1532857},
	abstract = {Traditionally, time-varying data has been visualized using snapshots of the individual time steps or an animation of the snapshots shown in a sequential manner. For larger datasets with many time-varying features, animation can be limited in its use, as an observer can only track a limited number of features over the last few frames. Visually inspecting each snapshot is not practical either for a large number of time-steps. We propose new techniques inspired from the illustration literature to convey change over time more effectively in a time-varying dataset. Speedlines are used extensively by cartoonists to convey motion, speed, or change over different panels. Flow ribbons are another technique used by cartoonists to depict motion in a single frame. Strobe silhouettes are used to depict previous positions of an object to convey the previous positions of the object to the user. These illustration-inspired techniques can be used in conjunction with animation to convey change over time.},
	booktitle = {{IEEE} Visualization, 2005. {VIS} 05},
	author = {Joshi, A. and Rheingans, P.},
	month = oct,
	year = {2005},
	keywords = {Algorithm design and analysis, animation, Birds, computer animation, data analysis, data mining, data visualisation, data visualization, feature extraction, flow ribbons, Humans, illustration-inspired techniques, motion estimation, rendering (computer graphics), strobe silhouettes, time-varying data visualization, Ultrasonic imaging, weather forecasting},
	pages = {679 -- 686},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\3SHN97IQ\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\TFVW9N94\Joshi and Rheingans - 2005 - Illustration-inspired techniques for visualizing t.pdf:application/pdf}
}

@article{benard_state_art_2011,
	title = {State-of-the-Art Report on Temporal Coherence for Stylized Animations},
	volume = {30},
	copyright = {© 2011 The Authors Computer Graphics Forum © 2011 The Eurographics Association and Blackwell Publishing Ltd.},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2011.02075.x/abstract},
	doi = {10.1111/j.1467-8659.2011.02075.x},
	abstract = {Non-photorealistic rendering ({NPR)} algorithms allow the creation of images in a variety of styles, ranging from line drawing and pen-and-ink to oil painting and watercolour. These algorithms provide greater flexibility, control and automation over traditional drawing and painting. Despite significant progress over the past 15 years, the application of {NPR} to the generation of stylized animations remains an active area of research. The main challenge of computer-generated stylized animations is to reproduce the look of traditional drawings and paintings while minimizing distracting flickering and sliding artefacts present in hand-drawn animations. These goals are inherently conflicting and any attempt to address the temporal coherence of stylized animations is a trade-off. This state-of-the-art report is motivated by the growing number of methods proposed in recent years and the need for a comprehensive analysis of the trade-offs they propose. We formalize the problem of temporal coherence in terms of goals and compare existing methods accordingly. We propose an analysis for both line and region stylization methods and discuss initial steps towards their perceptual evaluation. The goal of our report is to help uninformed readers to choose the method that best suits their needs, as well as motivate further research to address the limitations of existing methods.},
	language = {en},
	number = {8},
	urldate = {2013-04-29},
	journal = {Computer Graphics Forum},
	author = {Bénard, Pierre and Bousseau, Adrien and Thollot, Joëlle},
	year = {2011},
	keywords = {I.3.3 [Computer Graphics], {Picture/Image} {Generation—I.3.7} [Computer Graphics], Three-Dimensional Graphics and Realism},
	pages = {2367-2386},
	file = {Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\666XNA97\Bénard et al. - 2011 - State-of-the-Art Report on Temporal Coherence for .pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\IDD627RE\abstract;jsessionid=DCBB6E3CBAB6FCBD2BD56884CACD7CFC.html:text/html}
}

@inproceedings{annen_vector_2008,
	address = {Toronto, Ont., Canada, Canada},
	series = {{GI} '08},
	title = {Vector field contours},
	isbn = {978-1-56881-423-0},
	url = {http://dl.acm.org/citation.cfm?id=1375714.1375731},
	abstract = {We describe an approach to define contours of {3D} vector fields and employ them as an interactive flow visualization tool. Although contours are well-defined and commonly used for surfaces and {3D} scalar fields, they have no straightforward extension in vector fields. Our approach is to extract and visualize specific stream lines which show the most similar behavior to contours on surfaces. This way, the vector field contours are a particular set of isolated stream line segments that depend on the view direction and few additional parameters. We present an analysis of the usefulness of vector field contours by demonstrating their application to linear vector fields. In order to achieve interactive visualization, we develop an efficient {GPU-based} implementation for real-time extraction and rendering of vector field contours. We show the potential of our approach by applying it to a number of example data sets.},
	urldate = {2013-05-09},
	booktitle = {Proceedings of graphics interface 2008},
	publisher = {Canadian Information Processing Society},
	author = {Annen, T. and Theisel, H. and Rössl, C. and Ziegler, G. and Seidel, H.-P.},
	year = {2008},
	pages = {97-105},
	file = {ACM Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\92CH92FI\Annen et al. - 2008 - Vector field contours.pdf:application/pdf}
}

@article{chen_illustrative_2011,
	title = {An Illustrative Visualization Framework for {3D} Vector Fields},
	volume = {30},
	copyright = {2011 The Author(s) Computer Graphics Forum © 2011 The Eurographics Association and Blackwell Publishing Ltd.},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2011.02064.x/abstract},
	doi = {10.1111/j.1467-8659.2011.02064.x},
	abstract = {Most {3D} vector field visualization techniques suffer from the problem of visual clutter, and it remains a challenging task to effectively convey both directional and structural information of {3D} vector fields. In this paper, we present a novel visualization framework that combines the advantages of clustering methods and illustrative rendering techniques to generate a concise and informative depiction of complex flow structures. Given a {3D} vector field, we first generate a number of streamlines covering the important regions based on an entropy measurement. Then we decompose the streamlines into different groups based on a categorization of vector information, wherein the streamline pattern in each group is ensured to be coherent or nearly coherent. For each group, we select a set of representative streamlines and render them in an illustrative fashion to enhance depth cues and succinctly show local flow characteristics. The results demonstrate that our approach can generate a visualization that is relatively free of visual clutter while facilitating perception of salient information of complex vector fields.},
	language = {en},
	number = {7},
	urldate = {2013-05-16},
	journal = {Computer Graphics Forum},
	author = {Chen, Cheng-Kai and Yan, Shi and Yu, Hongfeng and Max, Nelson and Ma, Kwan-Liu},
	year = {2011},
	keywords = {[Computer, and, curve, generation, Graphics]:, I.3.3, {—Line}, {Picture/Image}},
	pages = {1941-1951},
	file = {Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\939VXFFW\abstract.html:text/html}
}

@article{ma_coherent_2013,
	title = {Coherent view-dependent streamline selection for importance-driven flow visualization},
	url = {http://dx.doi.org/10.1117/12.2001887},
	doi = {10.1117/12.2001887},
	abstract = {Streamline visualization can be formulated as the problem of streamline placement or streamline selection. In this 
paper, we present an importance-driven approach to view-dependent streamline selection that guarantees coherent 
streamline update when the view changes gradually. Given a large number of randomly or uniformly seeded 
and traced streamlines and sample viewpoints, our approach evaluates, for each streamline, the view-dependent 
importance by considering the amount of information shared by the {3D} streamline and its {2D} projection as well as 
how stereoscopic the streamline’s shape is reflected under each viewpoint. We achieve coherent view-dependent 
streamline selection following a two-pass solution that considers i) the relationships between local viewpoints 
and the global streamline set selected in a view-independent manner and ii) the continuity between adjacent 
viewpoints. We demonstrate the effectiveness of our approach with several synthesized and simulated flow fields 
and compare our view-dependent streamline selection algorithm with a naïve algorithm that selects streamlines 
solely based on the information at the current viewpoint.},
	urldate = {2013-05-14},
	journal = {Proc. {SPIE} 8654, Visualization and Data Analysis},
	author = {Ma, Jun and Wang, Chaoli and Shene, Ching-Kuang},
	month = feb,
	year = {2013},
	pages = {865407--865407},
	file = {vda13-vds.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\KCNR8G4E\vda13-vds.pdf:application/pdf}
}

@inproceedings{kuhn_clustering-based_2011,
	title = {A Clustering-based Visualization Technique to Emphasize Meaningful Regions of Vector Fields},
	booktitle = {Proc. of Vision, Modeling, and Visualization ({VMV} 2011)},
	publisher = {Eurographics Assosciation},
	author = {Kuhn, A. and Lehmann, D. J. and Gaststeiger, R. and Neugebauer, Matthias and Preim, B. and Theisel, H.},
	year = {2011},
	pages = {191-198},
	file = {Kuhn_2011_VMV.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\TPQ37S7P\Kuhn_2011_VMV.pdf:application/pdf}
}

@inproceedings{mattausch_strategies_2003,
	address = {New York, {NY}, {USA}},
	series = {{SCCG} '03},
	title = {Strategies for interactive exploration of {3D} flow using evenly-spaced illuminated streamlines},
	isbn = {1-58113-861-X},
	url = {http://doi.acm.org/10.1145/984952.984987},
	doi = {10.1145/984952.984987},
	abstract = {This paper presents several strategies to interactively explore {3D} flow. Based on a fast illuminated streamlines algorithm, standard graphics hardware is sufficient to gain interactive rendering rates. Our approach does not require the user to have any prior knowledge of flow features. After the streamlines are computed in a short preprocessing time, the user can interactively change appearance and density of the streamlines to further explore the flow. Most important flow features like velocity or pressure not only can be mapped to all available streamline appearance properties like streamline width, material, opacity, but also to streamline density. To improve spatial perception of the {3D} flow we apply techniques based on animation, depth cueing, and halos along a streamline if it is crossed by another streamline in the foreground. Finally, we make intense use of focus+context methods like magic volumes, region of interest driven streamline placing, and spotlights to solve the occlusion problem.},
	urldate = {2013-05-13},
	booktitle = {Proceedings of the 19th spring conference on Computer graphics},
	publisher = {{ACM}},
	author = {Mattausch, Oliver and Theu{\ss}l, Thomas and Hauser, Helwig and Gr{\"o}ller, Eduard},
	year = {2003},
	keywords = {{3D} flow visualization, focus-context visualization, illuminated streamlines, Interactive exploration},
	pages = {213-222},
	file = {ACM Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\TWQNURM4\\Mattausch et al. - 2003 - Strategies for interactive exploration of 3D flow .pdf:application/pdf}
}

@inproceedings{zockler_interactive_1996,
	title = {Interactive visualization of {3D-vector} fields using illuminated stream lines},
	doi = {10.1109/VISUAL.1996.567777},
	abstract = {A new technique for interactive vector field visualization using large numbers of properly illuminated stream lines is presented. Taking into account ambient, diffuse, and specular reflection terms as well as transparency, we employ a realistic shading model which significantly increases quality and realism of the resulting images. While many graphics workstations offer hardware support for illuminating surface primitives, usually no means for an accurate shading of line primitives are provided. However, we show that proper illumination of lines can be implemented by exploiting the texture mapping capabilities of modern graphics hardware. In this way high rendering performance with interactive frame rates can be achieved. We apply the technique to render large numbers of integral curves in a vector field. The impression of the resulting images can be further improved by making the curves partially transparent. We also describe methods for controlling the distribution of stream lines in space. These methods enable us to use illuminated stream lines within an interactive visualization environment.},
	booktitle = {Visualization '96. Proceedings.},
	author = {Zockler, M. and Stalling, D. and Hege, H.-C.},
	month = oct,
	year = {1996},
	keywords = {{3D} vector fields, accurate shading, Computer Graphics, data visualisation, graphics workstations, Hardware, high rendering performance, illuminated stream lines, Image generation, integral curves, interactive frame rates, interactive vector field visualization, interactive visualization environment, Layout, lighting, line primitives, modern graphics hardware, Optical reflection, partially transparent curves, realistic shading model, rendering (computer graphics), specular reflection terms, Streaming media, texture mapping capabilities, transparency, vector field, visualization, Workstations},
	pages = {107-113},
	file = {IEEE Xplore Abstract Record:C:\Users\JoeShengzhou\AppData\Roaming\Zotero\Zotero\Profiles\0m7eflhb.default\zotero\storage\5GWZUUZK\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\JoeShengzhou\AppData\Roaming\Zotero\Zotero\Profiles\0m7eflhb.default\zotero\storage\2QQT93CD\Zockler et al. - 1996 - Interactive visualization of 3D-vector fields usin.pdf:application/pdf}
}

@inproceedings{arens_survey_2010,
	address = {Aire-la-Ville, Switzerland, Switzerland},
	series = {{VG'10}},
	title = {A survey of transfer functions suitable for volume rendering},
	isbn = {978-3-905674-23-1},
	url = {http://dx.doi.org/10.2312/VG/VG10/077-083},
	doi = {10.2312/VG/VG10/077-083},
	abstract = {There are many transfer functions ({TF)} that emphasize or hide special features of volume data. Their potential to cleverly generate a color and opacity value for direct volume rendering is primarily determined by the used metrics besides the input data value. Despite this variety of {TFs}, for the most part simple one dimensional data value only based {TFs} are used in practice. This survey will therefore examine the differences in representative {TF} types (defined by their used metrics) to provide a basis for selecting the right {TF} type for the boundary conditions that describe an individual field of application and task. Besides fundamental properties like metrics or memory consumption, we will also give an assessment about user interaction and quality of feature emphasis.},
	urldate = {2013-05-09},
	booktitle = {Proceedings of the 8th {IEEE/EG} international conference on Volume Graphics},
	publisher = {Eurographics Association},
	author = {Arens, S. and Domik, G.},
	year = {2010},
	pages = {77-83},
	file = {A_Survey_of_Transfer_Functions_suitable_for_Volume_Rendering.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\QTTQZXG6\A_Survey_of_Transfer_Functions_suitable_for_Volume_Rendering.pdf:application/pdf}
}

@article{bernardon_transfer-function_2008,
	title = {Transfer-Function Specification for Rendering Disparate Volumes},
	volume = {10},
	issn = {1521-9615},
	doi = {10.1109/MCSE.2008.158},
	abstract = {Being able to create insightful visualizations from both simulated and measured data is important for the visualization community. For scalar volumes, direct volume rendering has proved a useful tool for data exploration. Using a transfer function, we can map scalar values to colors and opacities to identify and enhance important features. Although researchers have developed some automatic techniques for transfer-function specification, the exploration process still requires users to tune the parameters manually until they can produce the desired visualization. Researchers have conducted substantial work to assist users in this specification task by providing interactive widgets. These tools generally assist users by letting them create and manipulate widgets over one or more dimensions of histogram information representing the data. The authors' framework combines elements of existing transfer-function specification techniques and introduces new features to handle the direct volume rendering of a diversity of volumetric data sets.},
	number = {6},
	journal = {Computing in Science Engineering},
	author = {Bernardon, {F.F.} and Ha, {L.K.} and Callahan, {S.P.} and Comba, {J.L.D.} and Silva, {C.T.}},
	year = {2008},
	keywords = {Data Exploration, data mining, data representation, data structures, data visualisation, data visualization, Direct volume rendering, Dynamic range, feature extraction, histogram information, Histograms, interactive widget, Medical simulation, Multidimensional systems, rendering (computer graphics), scientific visualization, table lookup, transfer functions, transfer-function specification, volume rendering, volumetric data set},
	pages = {82--89},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\8V2HTWWA\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\WKT9AMQA\Bernardon et al. - 2008 - Transfer-Function Specification for Rendering Disp.pdf:application/pdf}
}

@article{svakhine_illustration-inspired_2009,
	title = {Illustration-Inspired Depth Enhanced Volumetric Medical Visualization},
	volume = {15},
	issn = {1077-2626},
	doi = {http://doi.ieeecomputersociety.org/10.1109/TVCG.2008.56},
	number = {1},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Svakhine, Nikolai A. and Ebert, David S. and Andrews, William M.},
	year = {2009},
	keywords = {Algorithms, anatomical structure, and texture, Biomedical imaging, biomedical {MRI}, Color, Computer Graphics, computerised tomography, {CT} scanner, data visualisation, data visualization, Eyes, Focusing, graphics processors, illustration-inspired depth enhanced volumetric medical visualization, image enhancement, Image Interpretation, Computer-Assisted, Imaging, Three-Dimensional, interaction techniques, Magnetic Resonance Imaging, Manuals, medical image processing, medical textbook, Medicine, {MRI} scanner, pipeline rendering, Pipelines, rendering (computer graphics), shading, shadowing, spatial relationship, Subtraction Technique, surgery, surgery manual, Tomography, X-Ray Computed, transfer functions, Visualization systems and software, Visualization techniques and methodologies, volume rendering, Volume Visualization, Volumetric, volumetric dataset},
	pages = {77--86},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\X8MBR94A\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\SH95V2DT\Svakhine et al. - 2009 - Illustration-Inspired Depth Enhanced Volumetric Me.pdf:application/pdf}
}

@article{post_state_2003,
	title = {The State of the Art in Flow Visualisation: Feature Extraction and Tracking},
	volume = {22},
	issn = {1467-8659},
	shorttitle = {The State of the Art in Flow Visualisation},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2003.00723.x/abstract},
	doi = {10.1111/j.1467-8659.2003.00723.x},
	abstract = {Flow visualisation is an attractive topic in data visualisation, offering great challenges for research. Very large data sets must be processed, consisting of multivariate data at large numbers of grid points, often arranged in many time steps. Recently, the steadily increasing performance of computers again has become a driving force for new advances in flow visualisation, especially in techniques based on texturing, feature extraction, vector field clustering, and topology {extraction.In} this article we present the state of the art in feature-based flow visualisation techniques. We will present numerous feature extraction techniques, categorised according to the type of feature. Next, feature tracking and event detection algorithms are discussed, for studying the evolution of features in time-dependent data sets. Finally, various visualisation techniques are {demonstrated.ACM} {CSS:} I.3.8 Computer Graphics—applications},
	language = {en},
	number = {4},
	urldate = {2013-03-22},
	journal = {Computer Graphics Forum},
	author = {Post, Frits H. and Vrolijk, Benjamin and Hauser, Helwig and Laramee, Robert S. and Doleisch, Helmut},
	year = {2003},
	keywords = {feature-based flow visualisation, flow visualisation, Visualisation},
	pages = {775-792},
	file = {Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\FS332BW9\Post et al. - 2003 - The State of the Art in Flow Visualisation Featur.pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\P7RI8VIK\abstract.html:text/html}
}

@inproceedings{tzeng_intelligent_2005,
	address = {Washington, {DC}, {USA}},
	series = {{SC} '05},
	title = {Intelligent Feature Extraction and Tracking for Visualizing Large-Scale {4D} Flow Simulations},
	isbn = {1-59593-061-2},
	url = {http://dx.doi.org/10.1109/SC.2005.37},
	doi = {10.1109/SC.2005.37},
	abstract = {Terascale simulations produce data that is vast in spatial, temporal, and variable domains, creating a formidable challenge for subsequent analysis. Feature extraction as a data reduction method offers a viable solution to this large data problem. This paper presents a new approach to the problem of extracting and visualizing {4D} features within large volume data. Conventional methods requires either an analytical description of the feature of interest or tedious manual intervention throughout the feature extraction and tracking process. We show that it is possible for a visualization system to "learn" to extract and track features in complex {4D} flow field according to their "visual" properties, location, shape, and size. The basic approach is to employ machine learning in the process of visualization. Such an intelligent system approach is powerful because it allows us to extract and track an feature of interest in a high-dimensional space without explicitly specifying the relations between those dimensions, resulting in a greatly simplified and intuitive visualization interface.},
	urldate = {2012-11-07},
	booktitle = {Proceedings of the 2005 {ACM/IEEE} conference on Supercomputing},
	publisher = {{IEEE} Computer Society},
	author = {Tzeng, Fan-Yin and Ma, Kwan-Liu},
	year = {2005},
	keywords = {Analytical models, Computational modeling, Computer Simulation, data mining, data visualization, feature extraction, Large-scale systems, Learning systems, Machine Learning, transfer functions},
	pages = {6},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\GHXTKBZ3\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\X5X94ZEN\Tzeng and Ma - 2005 - Intelligent Feature Extraction and Tracking for Vi.pdf:application/pdf}
}

@article{caban_texture-based_2007,
	title = {Texture-based feature tracking for effective time-varying data visualization},
	volume = {13},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2007.70599},
	abstract = {Analyzing, visualizing, and illustrating changes within time-varying volumetric data is challenging due to the dynamic changes occurring between timesteps. The changes and variations in computational fluid dynamic volumes and atmospheric {3D} datasets do not follow any particular transformation. Features within the data move at different speeds and directions making the tracking and visualization of these features a difficult task. We introduce a texture-based feature tracking technique to overcome some of the current limitations found in the illustration and visualization of dynamic changes within time-varying volumetric data. Our texture-based technique tracks various features individually and then uses the tracked objects to better visualize structural changes. We show the effectiveness of our texture-based tracking technique with both synthetic and real world time-varying data. Furthermore, we highlight the specific visualization, annotation, registration, and feature isolation benefits of our technique. For instance, we show how our texture-based tracking can lead to insightful visualizations of time-varying data. Such visualizations, more than traditional visualization techniques, can assist domain scientists to explore and understand dynamic changes.},
	number = {6},
	journal = {{IEEE} transactions on visualization and computer graphics},
	author = {Caban, Jesus and Joshi, Alark and Rheingans, Penny},
	month = dec,
	year = {2007},
	note = {{PMID:} 17968099},
	pages = {1472--1479},
	file = {tvcg07.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\EIF6CFCC\tvcg07.pdf:application/pdf}
}

@inproceedings{woodring_high_2003,
	title = {High dimensional direct rendering of time-varying volumetric data},
	doi = {10.1109/VISUAL.2003.1250402},
	abstract = {We present an alternative method for viewing time-varying volumetric data. We consider such data as a four-dimensional data field, rather than considering space and time as separate entities. If we treat the data in this manner, we can apply high dimensional slicing and projection techniques to generate an image hyperplane. The user is provided with an intuitive user interface to specify arbitrary hyperplanes in {4D}, which can be displayed with standard volume rendering techniques. From the volume specification, we are able to extract arbitrary hyperslices, combine slices together into a hyperprojection volume, or apply a {4D} raycasting method to generate the same results. In combination with appropriate integration operators and transfer functions, we are able to extract and present different space-time features to the user.},
	booktitle = {{IEEE} Visualization, 2003. {VIS} 2003},
	author = {Woodring, J. and Wang, Chaoli and Shen, Han-Wei},
	month = oct,
	year = {2003},
	keywords = {{4D} raycasting, data visualisation, four-dimensional data field, high dimensional direct rendering, high dimensional projection, high dimensional slicing, hyperplanes, hyperprojection, hyperprojection volume, hyperslice, image classification, image hyperplane, integration operator, ray tracing, raycasting, rendering (computer graphics), solid modelling, space-time feature, time-varying data, time-varying systems, time-varying volumetric data, transfer function, user interface, volume rendering, volume specification},
	pages = {417 --424},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\UMKQ22XF\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\VVJMH9P3\Woodring et al. - 2003 - High dimensional direct rendering of time-varying .pdf:application/pdf}
}

@inproceedings{widanagamaachchi_interactive_2012,
	title = {Interactive exploration of large-scale time-varying data using dynamic tracking graphs},
	doi = {10.1109/LDAV.2012.6378962},
	abstract = {Exploring and analyzing the temporal evolution of features in large-scale time-varying datasets is a common problem in many areas of science and engineering. One natural representation of such data is tracking graphs, i.e., constrained graph layouts that use one spatial dimension to indicate time and show the “tracks” of each feature as it evolves, merges or disappears. However, for practical data sets creating the corresponding optimal graph layouts that minimize the number of intersections can take hours to compute with existing techniques. Furthermore, the resulting graphs are often unmanageably large and complex even with an ideal layout. Finally, due to the cost of the layout, changing the feature definition, e.g. by changing an iso-value, or analyzing properly adjusted sub-graphs is infeasible. To address these challenges, this paper presents a new framework that couples hierarchical feature definitions with progressive graph layout algorithms to provide an interactive exploration of dynamically constructed tracking graphs. Our system enables users to change feature definitions on-the-fly and filter features using arbitrary attributes while providing an interactive view of the resulting tracking graphs. Furthermore, the graph display is integrated into a linked view system that provides a traditional {3D} view of the current set of features and allows a cross-linked selection to enable a fully flexible spatio-temporal exploration of data. We demonstrate the utility of our approach with several large-scale scientific simulations from combustion science.},
	booktitle = {2012 {IEEE} Symposium on Large Data Analysis and Visualization ({LDAV)}},
	author = {Widanagamaachchi, W. and Christensen, C. and Bremer, P.-T. and Pascucci, V.},
	year = {2012},
	keywords = {Computer Graphics, constrained graph layouts, Correlation, data visualization, dynamic tracking graphs, feature definition, Feature Detection and Tracking, feature extraction, graph theory, Interactive exploration, interactive systems, large-scale time-varying data, Layout, Measurement, Parallel coordinates, spatial dimension, spatio temporal exploration, temporal evolution, time-varying data, Topology-based Techniques, Vegetation, visualization, Visualization in Physical Sciences and Engineering},
	pages = {9--17},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\E32RB8D4\articleDetails.html:text/html}
}

@article{ma_machine_2007,
	title = {Machine Learning to Boost the Next Generation of Visualization Technology},
	volume = {27},
	issn = {0272-1716},
	doi = {10.1109/MCG.2007.129},
	abstract = {Visualization has become an indispensable tool in many areas of science and engineering. In particular, the advances made in the field of visualization over the past 20 years have turned visualization from a presentation tool to a discovery tool. Machine learning has received great success in both data mining and computer graphics; surprisingly, the study of systematic ways to employ machine learning in making visualization is meager. Like human learning, we can make a computer program learn from previous input data to optimize its performance on processing new data. In the context of visualization, the use of machine learning can potentially free us from manually sifting through all the data. This paper describes intelligent visualization designs for three different applications: (1) volume classification and visualization, (2) {4D} flow feature extraction and tracking, (3) network scan characterization.},
	number = {5},
	journal = {{IEEE} Computer Graphics and Applications},
	author = {Ma, Kwan-Liu},
	year = {2007},
	keywords = {{4D} flow feature extraction, {4D} flow feature tracking, Biological neural networks, Computer Graphics, data mining, data visualisation, data visualization, feature extraction, information visualization, Intelligent systems, intelligent visualization designs, interface design, learning (artificial intelligence), Machine Learning, network scan characterization, painting, Paints, rendering (computer graphics), scientific visualization, transfer functions, user interfaces, Volume classification, volume rendering, Volume Visualization},
	pages = {6--9},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\FJVBS36B\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\4Z76HTGQ\Ma - 2007 - Machine Learning to Boost the Next Generation of V.pdf:application/pdf}
}

@inproceedings{lee_visualizing_2009,
	title = {Visualizing time-varying features with {TAC-based} distance fields},
	doi = {10.1109/PACIFICVIS.2009.4906831},
	abstract = {To analyze time-varying data sets, tracking features over time is often necessary to better understand the dynamic nature of the underlying physical process. Tracking {3D} time-varying features, however, is non-trivial when the boundaries of the features cannot be easily defined. In this paper, we propose a new framework to visualize time-varying features and their motion without explicit feature segmentation and tracking. In our framework, a time-varying feature is described by a time series or time activity curve ({TAC).} To compute the distance, or similarity, between a voxel's time series and the feature, we use the dynamic time warping ({DTW)} distance metric. The purpose of {DTW} is to compare the shape similarity between two time series with an optimal warping of time so that the phase shift of the feature in time can be accounted for. After applying {DTW} to compare each voxel's time series with the feature, a time-invariant distance field can be computed. The amount of time warping required for each voxel to match the feature provides an estimate of the time when the feature is most likely to occur. Based on the {TAC-based} distance field, several visualization methods can be derived to highlight the position and motion of the feature. We present several case studies to demonstrate and compare the effectiveness of our framework.},
	booktitle = {Visualization Symposium, 2009. {PacificVis} '09. {IEEE} Pacific},
	author = {Lee, Teng-Yok and Shen, Han-Wei},
	month = apr,
	year = {2009},
	keywords = {animation, data analysis, data mining, data visualisation, data visualization, distance metric, dynamic time warping, earthquakes, feature extraction, feature tracking, I.3.3 [Computing Methodologies]: {COMPUTER} {GRAPHICS—Picture/Image} Generation, I.3.7 [Computing Methodologies]: {COMPUTER} {GRAPHICS—Three-Dimensional} Graphics and Realism, Shape, shape similarity, Space exploration, Spatiotemporal phenomena, {TAC-based} distance field, time activity curve, time series, time-invariant distance field, time-varying data set, time-varying feature visualization, Tracking},
	pages = {1 --8},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\ZNR33S6I\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\TU6XIUKT\Lee and Shen - 2009 - Visualizing time-varying features with TAC-based d.pdf:application/pdf}
}

@article{gu_transgraph_2011,
	title = {{TransGraph:} Hierarchical Exploration of Transition Relationships in Time-Varying Volumetric Data},
	volume = {17},
	issn = {1077-2626},
	shorttitle = {{TransGraph}},
	doi = {10.1109/TVCG.2011.246},
	abstract = {A fundamental challenge for time-varying volume data analysis and visualization is the lack of capability to observe and track data change or evolution in an occlusion-free, controllable, and adaptive fashion. In this paper, we propose to organize a timevarying data set into a hierarchy of states. By deriving transition probabilities among states, we construct a global map that captures the essential transition relationships in the time-varying data. We introduce the {TransGraph}, a graph-based representation to visualize hierarchical state transition relationships. The {TransGraph} not only provides a visual mapping that abstracts data evolution over time in different levels of detail, but also serves as a navigation tool that guides data exploration and tracking. The user interacts with the {TransGraph} and makes connection to the volumetric data through brushing and linking. A set of intuitive queries is provided to enable knowledge extraction from time-varying data. We test our approach with time-varying data sets of different characteristics and the results show that the {TransGraph} can effectively augment our ability in understanding time-varying data.},
	number = {12},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Gu, Yi and Wang, Chaoli},
	month = dec,
	year = {2011},
	keywords = {data analysis, data mining, data structures, data visualisation, data visualization, graph based representation, graph theory, hierarchical state transition relationships, knowledge extraction, navigation tool, occlusion free, probability, time-varying volumetric data analysis, {TransGraph}, transition probability, visual mapping},
	pages = {2015 --2024},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\CM6KWK4T\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\PVXTJTK2\Gu and Wang - 2011 - TransGraph Hierarchical Exploration of Transition.pdf:application/pdf}
}

@article{woodring_multiscale_2009,
	title = {Multiscale Time Activity Data Exploration via Temporal Clustering Visualization Spreadsheet},
	volume = {15},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2008.69},
	abstract = {Time-varying data is usually explored by animation or arrays of static images. Neither is particularly effective for classifying data by different temporal activities. Important temporal trends can be missed due to the lack of ability to find them with current visualization methods. In this paper, we propose a method to explore data at different temporal resolutions to discover and highlight data based upon time-varying trends. Using the wavelet transform along the time axis, we transform data points into multi-scale time series curve sets. The time curves are clustered so that data of similar activity are grouped together, at different temporal resolutions. The data are displayed to the user in a global time view spreadsheet where she is able to select temporal clusters of data points, and filter and brush data across temporal scales. With our method, a user can interact with data based on time activities and create expressive visualizations.},
	number = {1},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Woodring, J. and Shen, Han-Wei},
	month = feb,
	year = {2009},
	keywords = {Algorithms, animation, Brushes, Cluster Analysis, computer animation, Computer Graphics, Computer Simulation, data visualisation, data visualization, Filter bank, Frequency, Histograms, Information Storage and Retrieval, information visualization, Models, Theoretical, multiscale time activity data exploration, multiscale time series curve sets, Multivariate visualization, pattern clustering, Software, Temperature, temporal clustering visualization spreadsheet, transfer functions, User-Computer Interface, Visualization systems and software, Visualization techniques and methodologies, Wavelet coefficients, wavelet transform, wavelet transforms},
	pages = {123 --137},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\P9A2PEKN\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\2NTVR4FT\Woodring 和 Shen - 2009 - Multiscale Time Activity Data Exploration via Temp.pdf:application/pdf}
}

@inproceedings{wang_information_2008,
	title = {Information and Knowledge assisted analysis and Visualization of large-scale data},
	doi = {10.1109/ULTRAVIS.2008.5154057},
	abstract = {The ever-increasing sizes of data produced from a variety of scientific studies post a formidable challenge for the subsequent data analysis and visualization tasks. While steady advances in graphics hardware enable faster rendering, achieving interactive visualization of large data must also rely on effective data filtering and organization. In many cases, the best interactivity can only be obtained by taking into account the intrinsic properties of the data and domain knowledge to better reduce and organize the data for visualization. As a result, in recent years, we have seen increasing research and development efforts into the area of information and knowledge assisted visualization ({IKV).} In this paper, we survey research in {IKV} of scientific data and also identify a few directions for further work in this emerging area.},
	booktitle = {Workshop on Ultrascale Visualization, 2008. {UltraVis} 2008},
	author = {Wang, Chaoli and Ma, Kwan-Liu},
	year = {2008},
	keywords = {Computer Graphics, data analysis, data filtering, data mining, data visualisation, data visualization, Focusing, Hardware, Information analysis, information and knowledge assisted visualization, interactive systems, large-scale data visualization, Large-scale systems, Petascale computing, rendering (computer graphics)},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\V8N7HPNE\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\KWRRPDXP\Wang and Ma - 2008 - Information and Knowledge assisted analysis and Vi.pdf:application/pdf}
}

@inproceedings{ozer_group_2012,
	title = {Group dynamics in scientific visualization},
	doi = {10.1109/LDAV.2012.6378982},
	abstract = {The ability to visually extract and track features is appealing to scientists in many simulations including flow fields. However, as the resolution of the simulation becomes higher, the number of features to track increases and so does the cost in large-scale simulations. Since many of these features act in groups, it seems more cost-effective to follow groups of features rather than individual ones. Very little work has been done for tracking groups of features. In this paper, we present the first full group tracking framework in which we track groups (clusters) of features in time-varying {3D} fluid flow simulations. Our framework uses a clustering algorithm to group interacting features. We demonstrate the use of our framework on data output from a {3D} simulation of wall bounded turbulent flow.},
	booktitle = {2012 {IEEE} Symposium on Large Data Analysis and Visualization ({LDAV)}},
	author = {Ozer, S. and Wei, Jishang and Silver, D. and Ma, Kwan-Liu and Martin, P.},
	year = {2012},
	keywords = {boundary layer turbulence, Clustering, clustering algorithm, Clustering algorithms, data visualisation, data visualization, feature extraction, feature tracking, flow fields, flow simulation, group dynamics, group tracking, group tracking framework, grouping, image color analysis, mechanical engineering computing, packet identification, pattern clustering, Radar tracking, scientific visualization, Shape, time-varying {3D} fluid flow simulations, Tracking, wall bounded turbulent flow},
	pages = {97--104},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\ZG2CFIWV\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\3FIJG258\Ozer et al. - 2012 - Group dynamics in scientific visualization.pdf:application/pdf}
}

@article{lee_visualization_2009,
	title = {Visualization and Exploration of Temporal Trend Relationships in Multivariate Time-Varying Data},
	volume = {15},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2009.200},
	abstract = {We present a new algorithm to explore and visualize multivariate time-varying data sets. We identify important trend relationships among the variables based on how the values of the variables change over time and how those changes are related to each other in different spatial regions and time intervals. The trend relationships can be used to describe the correlation and causal effects among the different variables. To identify the temporal trends from a local region, we design a new algorithm called {SUBDTW} to estimate when a trend appears and vanishes in a given time series. Based on the beginning and ending times of the trends, their temporal relationships can be modeled as a state machine representing the trend sequence. Since a scientific data set usually contains millions of data points, we propose an algorithm to extract important trend relationships in linear time complexity. We design novel user interfaces to explore the trend relationships, to visualize their temporal characteristics, and to display their spatial distributions. We use several scientific data sets to test our algorithm and demonstrate its utilities.},
	number = {6},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Lee, Teng-Yok and Shen, Han-Wei},
	month = dec,
	year = {2009},
	keywords = {Algorithm design and analysis, Clustering algorithms, computational complexity, Data Exploration, data mining, data visualisation, data visualization, Displays, hurricanes, linear time complexity, multivariate time-varying data, spatial distributions, {SUBDTW}, Temperature, temporal trend relationships, Testing, trend sequence, trend sequence clustering, user interfaces, Wind},
	pages = {1359 --1366},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\UZZ2X962\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\2IDUVVHC\Lee 和 Shen - 2009 - Visualization and Exploration of Temporal Trend Re.pdf:application/pdf}
}

@inproceedings{muelder_interactive_2009,
	title = {Interactive feature extraction and tracking by utilizing region coherency},
	doi = {10.1109/PACIFICVIS.2009.4906833},
	abstract = {The ability to extract and follow time-varying flow features in volume data generated from large-scale numerical simulations enables scientists to effectively see and validate modeled phenomena and processes. Extracted features often take much less storage space and computing resources to visualize. Most feature extraction and tracking methods first identify features of interest in each time step independently, then correspond these features in consecutive time steps of the data. Since these methods handle each time step separately, they do not use the coherency of the feature along the time dimension in the extraction process. In this paper, we present a prediction-correction method that uses a prediction step to make the best guess of the feature region in the subsequent time step, followed by growing and shrinking the border of the predicted region to coherently extract the actual feature of interest. This method makes use of the temporal-space coherency of the data to accelerate the extraction process while implicitly solving the tedious correspondence problem that previous methods focus on. Our method is low cost with very little storage overhead, and thus facilitates interactive or runtime extraction and visualization, unlike previous methods which were largely suited for batch-mode processing due to high computational cost.},
	booktitle = {Visualization Symposium, 2009. {PacificVis} '09. {IEEE} Pacific},
	author = {Muelder, C. and Ma, Kwan-Liu},
	year = {2009},
	keywords = {Acceleration, Application software, batch-mode processing, Computational modeling, Computer Graphics, computing resources, Costs, data mining, data visualisation, data visualization, feature extraction, feature tracking, I.4.6 [Computer Graphics]: {Segmentation—Region} growing, partitioning, I.4.7 [Computer Graphics]: Feature {Measurement—Feature} representation, interactive feature extraction, large-scale numerical simulations, Large-scale systems, Numerical simulation, prediction-correction method, storage management, storage overhead, storage space, temporal-space coherency, time-varying flow features, utilizing region coherency},
	pages = {17--24},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\D8HMWDFG\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\SKUM9TG9\Muelder and Ma - 2009 - Interactive feature extraction and tracking by uti.pdf:application/pdf}
}

@book{pylyshyn_seeing_2003,
	title = {Seeing and Visualizing: It's Not what You Think},
	isbn = {0262162172},
	shorttitle = {Seeing and Visualizing},
	abstract = {Winner in the category of Psychology in the 2003 {Professional/Scholarly} Publishing Annual Awards Competition presented by the Association of American Publishers, {Inc.In} Seeing and Visualizing, Zenon Pylyshyn argues that seeing is different from thinking and that to see is not, as it may seem intuitively, to create an inner replica of the world. Pylyshyn examines how we see and how we visualize and why the scientific account does not align with the way these processes seem to us "from the inside." In doing so, he addresses issues in vision science, cognitive psychology, philosophy of mind, and cognitive {neuroscience.First}, Pylyshyn argues that there is a core stage of vision independent from the influence of our prior beliefs and examines how vision can be intelligent and yet essentially knowledge-free. He then proposes that a mechanism within the vision module, called a visual index (or {FINST)}, provides a direct preconceptual connection between parts of visual representations and things in the world, and he presents various experiments that illustrate the operation of this mechanism. He argues that such a deictic reference mechanism is needed to account for many properties of vision, including how mental images attain their apparent spatial character without themselves being laid out in space in our {brains.The} final section of the book examines the "picture theory" of mental imagery, including recent neuroscience evidence, and asks whether any current evidence speaks to the issue of the format of mental images. This analysis of mental imagery brings together many of the themes raised throughout the book and provides a framework for considering such issues as the distinction between the form and the content of representations, the role of vision in thought, and the relation between behavioral, neuroscientific, and phenomenological evidence regarding mental representations.},
	language = {en},
	publisher = {{MIT} Press},
	author = {Pylyshyn, Z. W.},
	year = {2003},
	keywords = {Medical / Neuroscience, Philosophy / Mind \& Body, Psychology / Cognitive Psychology, Psychology / Neuropsychology},
	file = {bookall.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\BKW4PAEX\bookall.pdf:application/pdf;Review of Zenon Pylyshyn’s Seeing and Visualizing: It’s Not What You Think:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\BK7GVHMN\2599.pdf:application/pdf}
}

@article{rheingans_volume_2001,
	title = {Volume illustration: nonphotorealistic rendering of volume models},
	volume = {7},
	issn = {1077-2626},
	shorttitle = {Volume illustration},
	doi = {10.1109/2945.942693},
	abstract = {Accurately and automatically conveying the structure of a volume model is a problem which has not been fully solved by existing volume rendering approaches. Physics-based volume rendering approaches create images which may match the appearance of translucent materials in nature but may not embody important structural details. Transfer function approaches allow flexible design of the volume appearance but generally require substantial hand-tuning for each new data set in order to be effective. We introduce the volume illustration approach, combining the familiarity of a physics-based illumination model with the ability to enhance important features using non-photorealistic rendering techniques. Since the features to be enhanced are defined on the basis of local volume characteristics rather than volume sample values, the application of volume illustration techniques requires less manual tuning than the design of a good transfer function. Volume illustration provides a flexible unified framework for enhancing the structural perception of volume models through the amplification of features and the addition of illumination effects},
	number = {3},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Rheingans, P. and Ebert, D.},
	year = {2001},
	keywords = {Art, data visualization, feature amplification, flexible design, image enhancement, important feature enhancement, Isosurfaces, lighting, lighting models, local volume characteristics, manual tuning, Manuals, nonphotorealistic rendering, Optical attenuators, optical transfer function, physics-based illumination model, physics-based volume rendering, rendering (computer graphics), shading, Solid modeling, solid modelling, structural details, structural perception, transfer functions, translucent materials, visualization, volume appearance, Volume illustration, volume model structure, X-rays},
	pages = {253--264},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\8WCFHNN5\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\VREI3X7X\Rheingans and Ebert - 2001 - Volume illustration nonphotorealistic rendering o.pdf:application/pdf}
}

@inproceedings{woodring_chronovolumes_2003,
	address = {New York, {NY}, {USA}},
	series = {{VG} '03},
	title = {Chronovolumes: a direct rendering technique for visualizing time-varying data},
	isbn = {1-58113-745-1},
	shorttitle = {Chronovolumes},
	url = {http://doi.acm.org/10.1145/827051.827054},
	doi = {10.1145/827051.827054},
	abstract = {We present a new method for displaying time varying volumetric data. The core of the algorithm is an integration through time producing a single view volume that captures the essence of multiple time steps in a sequence. The resulting view volume then can be viewed with traditional raycasting techniques. With different time integration functions, we can generate several kinds of resulting chronovolumes, which illustrate differing types of time varying features to the user. By utilizing graphics hardware and texture memory, the integration through time can be sped up, allowing the user interactive control over the temporal transfer function and exploration of the data.},
	urldate = {2013-05-17},
	booktitle = {Proceedings of the 2003 {Eurographics/IEEE} {TVCG} Workshop on Volume graphics},
	publisher = {{ACM}},
	author = {Woodring, Jonathan and Shen, Han-Wei},
	year = {2003},
	pages = {27-34},
	file = {ACM Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\G5HNWE6B\Woodring and Shen - 2003 - Chronovolumes a direct rendering technique for vi.pdf:application/pdf}
}

@article{wang_efficient_2011,
	title = {Efficient opacity specification based on feature visibilities in direct volume rendering},
	volume = {30},
	copyright = {2011 The Author(s) Computer Graphics Forum © 2011 The Eurographics Association and Blackwell Publishing Ltd.},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2011.02045.x/abstract},
	doi = {10.1111/j.1467-8659.2011.02045.x},
	abstract = {Due to {3D} occlusion, the specification of proper opacities in direct volume rendering is a time-consuming and unintuitive process. The visibility histograms introduced by Correa and Ma reflect the effect of occlusion by measuring the influence of each sample in the histogram to the rendered image. However, the visibility is defined on individual samples, while volume exploration focuses on conveying the spatial relationships between features. Moreover, the high computational cost and large memory requirement limits its application in multi-dimensional transfer function {design.In} this paper, we extend visibility histograms to feature visibility, which measures the contribution of each feature in the rendered image. Compared to visibility histograms, it has two distinctive advantages for opacity specification. First, the user can directly specify the visibilities for features and the opacities are automatically generated using an optimization algorithm. Second, its calculation requires only one rendering pass with no additional memory requirement. This feature visibility based opacity specification is fast and compatible with all types of transfer function design. Furthermore, we introduce a two-step volume exploration scheme, in which an automatic optimization is first performed to provide a clear illustration of the spatial relationship and then the user adjusts the visibilities directly to achieve the desired feature enhancement. The effectiveness of this scheme is demonstrated by experimental results on several volumetric datasets.},
	language = {en},
	number = {7},
	urldate = {2013-04-30},
	journal = {Computer Graphics Forum},
	author = {Wang, Yunhai and Zhang, Jian and Chen, Wei and Zhang, Huai and Chi, Xuebin},
	year = {2011},
	keywords = {[Computer, and, curve, generation, {Generation—Line}, Graphics]:, I.3.3, {Picture/Image}},
	pages = {2117-2126},
	file = {Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\JA8ET95D\Wang et al. - 2011 - Efficient opacity specification based on feature v.pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\WM8KJPXQ\abstract.html:text/html}
}

@article{correa_visibility_2011,
	title = {Visibility Histograms and Visibility-Driven Transfer Functions},
	volume = {17},
	issn = {1077-2626},
	url = {http://dx.doi.org/10.1109/TVCG.2010.35},
	doi = {10.1109/TVCG.2010.35},
	abstract = {Direct volume rendering is an important tool for visualizing complex data sets. However, in the process of generating {2D} images from {3D} data, information is lost in the form of attenuation and occlusion. The lack of a feedback mechanism to quantify the loss of information in the rendering process makes the design of good transfer functions a difficult and time consuming task. In this paper, we present the general notion of visibility histograms, which are multidimensional graphical representations of the distribution of visibility in a volume-rendered image. In this paper, we explore the {1D} and {2D} transfer functions that result from intensity values and gradient magnitude. With the help of these histograms, users can manage a complex set of transfer function parameters that maximize the visibility of the intervals of interest and provide high quality images of volume data. We present a semiautomated method for generating transfer functions, which progressively explores the transfer function space toward the goal of maximizing visibility of important structures. Our methodology can be easily deployed in most visualization systems and can be used together with traditional {1D} and {2D} opacity transfer functions based on scalar values, as well as with other more sophisticated rendering algorithms.},
	number = {2},
	urldate = {2013-05-02},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Correa, Carlos D. and Ma, Kwan-Liu},
	year = {2011},
	keywords = {Attenuation, complex data set visualisation, data visualization, Direct volume rendering, Feedback, feedback mechanism, Histograms, histograms., Image generation, multidimensional graphical representations, Multidimensional systems, Process design, Quality management, rendering (computer graphics), transfer functions, view-point dependent rendering, visibility, visibility driven transfer functions, visibility histograms, volume rendered image, volume rendering},
	pages = {192-204},
	file = {IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\J7JUS8N4\Correa and Ma - 2011 - Visibility Histograms and Visibility-Driven Transf.pdf:application/pdf}
}

@inproceedings{correa_visibility-driven_2009,
	title = {Visibility-driven transfer functions},
	doi = {10.1109/PACIFICVIS.2009.4906854},
	abstract = {Direct volume rendering is an important tool for visualizing complex data sets. However, in the process of generating {2D} images from {3D} data, information is lost in the form of attenuation and occlusion. The lack of a feedback mechanism to quantify the loss of information in the rendering process makes the design of good transfer functions a difficult and time consuming task. In this paper, we present the notion of visibility-driven transfer functions, which are transfer functions that provide a good visibility of features of interest from a given viewpoint. To achieve this, we introduce visibility histograms. These histograms provide graphical cues that intuitively inform the user about the contribution of particular scalar values to the final image. By carefully manipulating the parameters of the opacity transfer function, users can now maximize the visibility of the intervals of interest in a volume data set. Based on this observation, we also propose a semi-automated method for generating transfer functions, which progressively improves a transfer function defined by the user, according to a certain importance metric. Now the user does not have to deal with the tedious task of making small changes to the transfer function parameters, but now he/she can rely on the system to perform these searches automatically. Our methodology can be easily deployed in most visualization systems and can be used together with traditional {1D} opacity transfer functions based on scalar values, as well as with multidimensional transfer functions and other more sophisticated rendering algorithms.},
	booktitle = {Visualization Symposium, 2009. {PacificVis} '09. {IEEE} Pacific},
	author = {Correa, C. and Ma, Kwan-Liu},
	year = {2009},
	keywords = {{1D} opacity transfer functions, Attenuation, complex data set visualization, Computer Graphics, data visualisation, Data visualization, Direct volume rendering, Feedback, Histograms, Image generation, Multidimensional systems, Process design, rendering (computer graphics), transfer functions, visibility-driven transfer functions, volume rendering},
	pages = {177--184},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\5V4BE2EB\\abs_all.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\M7FEIITC\\Correa and Ma - 2009 - Visibility-driven transfer functions.pdf:application/pdf}
}

@article{ruiz_automatic_2011,
	title = {Automatic Transfer Functions Based on Informational Divergence},
	volume = {17},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2011.173},
	abstract = {In this paper we present a framework to define transfer functions from a target distribution provided by the user. A target distribution can reflect the data importance, or highly relevant data value interval, or spatial segmentation. Our approach is based on a communication channel between a set of viewpoints and a set of bins of a volume data set, and it supports {1D} as well as {2D} transfer functions including the gradient information. The transfer functions are obtained by minimizing the informational divergence or Kullback-Leibler distance between the visibility distribution captured by the viewpoints and a target distribution selected by the user. The use of the derivative of the informational divergence allows for a fast optimization process. Different target distributions for {1D} and {2D} transfer functions are analyzed together with importance-driven and view-based techniques.},
	number = {12},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Ruiz, M. and Bardera, A. and Boada, I. and Viola, I. and Feixas, M. and Sbert, M.},
	year = {2011},
	keywords = {{1D} transfer functions, {2D} transfer functions, automatic transfer functions, communication channel, data value interval, data visualization, Information analysis, Information Theory, informational divergence, Kullback-Leibler distance, Kullback-Leibler distance., Mutual information, optical transfer function, optimisation, optimization process, Probability distribution, rendering (computer graphics), spatial segmentation, target distribution, transfer function, transfer functions, visibility, visibility distribution},
	pages = {1932--1941},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\7G35HKWI\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\6Q62QI2M\Ruiz et al. - 2011 - Automatic Transfer Functions Based on Informationa.pdf:application/pdf}
}

@article{bramon_information_2013,
	title = {Information Theory-Based Automatic Multimodal Transfer Function Design},
	volume = {17},
	issn = {2168-2194},
	doi = {10.1109/JBHI.2013.2263227},
	abstract = {In this paper, we present a new framework for multimodal volume visualization that combines several information-theoretic strategies to define both colors and opacities of the multimodal transfer function. To the best of our knowledge, this is the first fully automatic scheme to visualize multimodal data. To define the fused color, we set an information channel between two registered input datasets, and afterward, we compute the informativeness associated with the respective intensity bins. This informativeness is used to weight the color contribution from both initial 1-D transfer functions. To obtain the opacity, we apply an optimization process that minimizes the informational divergence between the visibility distribution captured by a set of viewpoints and a target distribution proposed by the user. This distribution is defined either from the dataset features, from manually set importances, or from both. Other problems related to the multimodal visualization, such as the computation of the fused gradient and the histogram binning, have also been solved using new information-theoretic strategies. The quality and performance of our approach are evaluated on different datasets.},
	number = {4},
	journal = {{IEEE} Journal of Biomedical and Health Informatics},
	author = {Bramon, R. and Ruiz, M. and Bardera, A. and Boada, I. and Feixas, M. and Sbert, M.},
	year = {2013},
	keywords = {Information Theory, {Kullback-Leibler} distance, multimodal fusion, multimodal visualization, Transfer function design},
	pages = {870--880},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\KN5IQJG5\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\VF48UATT\Bramon et al. - 2013 - Information Theory-Based Automatic Multimodal Tran.pdf:application/pdf}
}

@inproceedings{bordoloi_view_2005,
	title = {View selection for volume rendering},
	doi = {10.1109/VISUAL.2005.1532833},
	abstract = {In a visualization of a three-dimensional dataset, the insights gained are dependent on what is occluded and what is not. Suggestion of interesting viewpoints can improve both the speed and efficiency of data understanding. This paper presents a view selection method designed for volume rendering. It can be used to find informative views for a given scene, or to find a minimal set of representative views which capture the entire scene. It becomes particularly useful when the visualization process is non-interactive - for example, when visualizing large datasets or time-varying sequences. We introduce a viewpoint "goodness" measure based on the formulation of entropy from information theory. The measure takes into account the transfer function, the data distribution and the visibility of the voxels. Combined with viewpoint properties like view-likelihood and view-stability, this technique can be used as a guide, which suggests "interesting" viewpoints for further exploration. Domain knowledge is incorporated into the algorithm via an importance transfer function or volume. This allows users to obtain view selection behaviors tailored to their specific situations. We generate a view space partitioning, and select one representative view for each partition. Together, this set of views encapsulates the "interesting" and distinct views of the data. Viewpoints in this set can be used as starting points for interactive exploration of the data, thus reducing the human effort in visualization. In non-interactive situations, such a set can be used as a representative visualization of the dataset from all directions.},
	booktitle = {{IEEE} Visualization},
	author = {Bordoloi, {U.D.} and Shen, Han-Wei},
	year = {2005},
	keywords = {Cameras, Data Distribution, data visualisation, data visualization, Design methodology, domain knowledge, entropy, entropy formulation, hidden feature removal, Humans, Information Theory, interactive data exploration, Layout, occlusion, Partitioning algorithms, rendering (computer graphics), transfer function, transfer functions, very large databases, view selection method, view space partitioning, volume rendering, voxel visibility},
	pages = {487--494},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\X9PCRU4T\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\DHIBNP53\Bordoloi and Shen - 2005 - View selection for volume rendering.pdf:application/pdf}
}

@article{ruiz_viewpoint_2010,
	title = {Viewpoint information channel for illustrative volume rendering},
	volume = {34},
	issn = {0097-8493},
	shorttitle = {Procedural Methods in Computer Graphics Illustrative Visualization},
	url = {http://www.sciencedirect.com/science/article/pii/S0097849310000439},
	doi = {10.1016/j.cag.2010.01.006},
	abstract = {This paper introduces a volume rendering framework based on the information channel constructed between the volumetric data set and a set of viewpoints. From this channel, the information associated to each voxel can be interpreted as an ambient occlusion value that allows to obtain illustrative volume visualizations. The use of the voxel information combined with the assignation of color to each viewpoint and non-photorealistic effects produces an enhanced visualization of the volume data set. Voxel information is also applied to modulate the transfer function and to select the most informative views.},
	number = {4},
	urldate = {2013-01-22},
	journal = {Computers \& Graphics},
	author = {Ruiz, M. and Boada, I. and Feixas, M. and Sbert, M.},
	month = aug,
	year = {2010},
	keywords = {Ambient occlusion, Illustrative Visualization, Viewpoint selection},
	pages = {351--360},
	file = {ScienceDirect Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\EBEE3XDD\Ruiz et al. - 2010 - Viewpoint information channel for illustrative vol.pdf:application/pdf;ScienceDirect Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\4M4BCII7\Ruiz et al. - 2010 - Viewpoint information channel for illustrative vol.html:text/html}
}

@article{ji_dynamic_2006,
	title = {Dynamic View Selection for Time-Varying Volumes},
	volume = {12},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2006.137},
	abstract = {Animation is an effective way to show how time-varying phenomena evolve over time. A key issue of generating a good animation is to select ideal views through which the user can perceive the maximum amount of information from the time-varying dataset. In this paper, we first propose an improved view selection method for static data. The method measures the quality of a static view by analyzing the opacity, color and curvature distributions of the corresponding volume rendering images from the given view. Our view selection metric prefers an even opacity distribution with a larger projection area, a larger area of salient features' colors with an even distribution among the salient features, and more perceived curvatures. We use this static view selection method and a dynamic programming approach to select time-varying views. The time-varying view selection maximizes the information perceived from the time-varying dataset based on the constraints that the time-varying view should show smooth changes of direction and near-constant speed. We also introduce a method that allows the user to generate a smooth transition between any two views in a given time step, with the perceived information maximized as well. By combining the static and dynamic view selection methods, the users are able to generate a time-varying view that shows the maximum amount of information from a time-varying data set},
	number = {5},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Ji, Guangfeng and Shen, Han-Wei},
	month = oct,
	year = {2006},
	keywords = {animation, computer animation, curvature distributions, data visualisation, data visualization, Diversity reception, dynamic programming, dynamic programming approach, dynamic view selection, Image analysis, image based method, image color analysis, Information entropy, opacity distribution, Optimization methods, optimization., rendering (computer graphics), salient feature colors, smooth transition generation, static view selection, static view selection method, time-varying dataset, time-varying view selection, time-varying volumes, Volume measurement, volume rendering images},
	pages = {1109 --1116},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\39SXVHIZ\cookiedetectresponse.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\CI7ZG68R\Ji and Shen - 2006 - Dynamic View Selection for Time-Varying Volumes.pdf:application/pdf}
}

@inproceedings{takahashi_feature-driven_2005,
	title = {A feature-driven approach to locating optimal viewpoints for volume visualization},
	doi = {10.1109/VISUAL.2005.1532834},
	abstract = {Optimal viewpoint selection is an important task because it considerably influences the amount of information contained in the {2D} projected images of {3D} objects, and thus dominates their first impressions from a psychological point of view. Although several methods have been proposed that calculate the optimal positions of viewpoints especially for {3D} surface meshes, none has been done for solid objects such as volumes. This paper presents a new method of locating such optimal viewpoints when visualizing volumes using direct volume rendering. The major idea behind our method is to decompose an entire volume into a set of feature components, and then find a globally optimal viewpoint by finding a compromise between locally optimal viewpoints for the components. As the feature components, the method employs interval volumes and their combinations that characterize the topological transitions of isosurfaces according to the scalar field. Furthermore, opacity transfer functions are also utilized to assign different weights to the decomposed components so that users can emphasize features of specific interest in the volumes. Several examples of volume datasets together with their optimal positions of viewpoints are exhibited in order to demonstrate that the method can effectively guide naive users to find optimal projections of volumes.},
	booktitle = {{IEEE} Visualization, 2005. {VIS} 05},
	author = {Takahashi, S. and Fujishiro, I. and Takeshima, Y. and Nishita, T.},
	year = {2005},
	keywords = {{3D} surface mesh, Chromium, Computer Graphics, data visualisation, Direct volume rendering, entropy, Hardware, Isosurfaces, level-set graph, mesh generation, optimal viewpoint selection, Psychology, rendering (computer graphics), Solids, surface fitting, transfer function, transfer functions, viewpoint entropy, visualization, Volume Visualization},
	pages = {495--502},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\HZG84WEV\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\63Z8VC5U\Takahashi et al. - 2005 - A feature-driven approach to locating optimal view.pdf:application/pdf}
}

@article{schlegel_visibility-difference_2013,
	title = {Visibility-difference entropy for automatic transfer function generation},
	url = {http://dx.doi.org/10.1117/12.2002971},
	doi = {10.1117/12.2002971},
	abstract = {Direct volume rendering allows for interactive exploration of volumetric data and has become an important tool in many 
visualization domains. But the insight and information that can be obtained are dependent on the transfer function defining 
the transparency of voxels. Constructing good transfer functions is one of the most time consuming and cumbersome tasks 
in volume visualization. We present a novel general purpose method for automatically generating an initial set of best 
transfer function candidates. The generated transfer functions reveal the major structural features within the volume and 
allow for an efficient initial visual analysis, serving as a basis for further interactive exploration in particular of originally 
unknown data. The basic idea is to introduce a metric as a measure of the goodness of a transfer function which indicates the 
information that can be gained from rendered images by interactive visualization. In contrast to prior methods, our approach 
does not require a user feedback-loop, operates exclusively in image space and takes the characteristics of interactive data 
exploration into account. We show how our new transfer function generation method can uncover the major structures of 
an unknown dataset within only a few minutes.},
	urldate = {2013-07-17},
	author = {Schlegel, Philipp and Pajarola, Renato},
	month = feb,
	year = {2013},
	pages = {865406--865406},
	file = {VDE_TF.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\229KG5CU\VDE_TF.pdf:application/pdf}
}

@inproceedings{lee_motion_2009,
	address = {Aire-la-Ville, Switzerland, Switzerland},
	series = {{EGSR'09}},
	title = {Motion based painterly rendering},
	url = {http://dx.doi.org/10.1111/j.1467-8659.2009.01498.x},
	doi = {10.1111/j.1467-8659.2009.01498.x},
	abstract = {Previous painterly rendering techniques normally use image gradients for deciding stroke orientations. Image gradients are good for expressing object shapes, but difficult to express the flow or movements of objects. In real painting, the use of brush strokes corresponding to the actual movement of objects allows viewers to recognize objects' motion better and thus to have an impression of the dynamic. In this paper, we propose a novel painterly rendering algorithm to express dynamic objects based on their motion information. We first extract motion information (magnitude, direction, standard deviation) of a scene from a set of consecutive image sequences from the same view. Then the motion directions are used for determining stroke orientations in the regions with significant motions, and image gradients determine stroke orientations where little motion is observed. Our algorithm is useful for realistically and dynamically representing moving objects. We have applied our algorithm for rendering landscapes. We could segment a scene into dynamic and static regions, and express the actual movement of dynamic objects using motion based strokes.},
	urldate = {2013-07-21},
	booktitle = {Proceedings of the Twentieth Eurographics conference on Rendering},
	publisher = {Eurographics Association},
	author = {Lee, H. and Lee, C. H. and Yoon, K.},
	year = {2009},
	pages = {1207-1215},
	file = {EGSR09_MotbasedPR_low.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\7G83G3EK\EGSR09_MotbasedPR_low.pdf:application/pdf}
}

@inproceedings{hays_image_2004,
	address = {New York, {NY}, {USA}},
	series = {{NPAR} '04},
	title = {Image and video based painterly animation},
	isbn = {1-58113-887-3},
	url = {http://doi.acm.org/10.1145/987657.987676},
	doi = {10.1145/987657.987676},
	abstract = {We present techniques for transforming images and videos into painterly animations depicting different artistic styles. Our techniques rely on image and video analysis to compute appearance and motion properties. We also determine and apply motion information from different (user-specified) sources to static and moving images. These properties that encode spatio-temporal variations are then used to render (or paint) effects of selected styles to generate images and videos with a painted look. Painterly animations are generated using a mesh of brush stroke objects with dynamic spatio-temporal properties. Styles govern the behavior of these brush strokes as well as their rendering to a virtual canvas. We present methods for modifying the properties of these brush strokes according to the input images, videos, or motions. Brush stroke color, length, orientation, opacity, and motion are determined and the brush strokes are regenerated to fill the canvas as the video changes. All brush stroke properties are temporally constrained to guarantee temporally coherent non-photorealistic animations.},
	urldate = {2013-07-21},
	booktitle = {Proceedings of the 3rd international symposium on Non-photorealistic animation and rendering},
	publisher = {{ACM}},
	author = {Hays, James and Essa, Irfan},
	year = {2004},
	pages = {113-120},
	file = {IVBPA_Final.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\EWPBRNHW\IVBPA_Final.pdf:application/pdf}
}

@article{healey_perceptually_2004,
	title = {Perceptually based brush strokes for nonphotorealistic visualization},
	volume = {23},
	issn = {0730-0301},
	url = {http://doi.acm.org/10.1145/966131.966135},
	doi = {10.1145/966131.966135},
	abstract = {An important problem in the area of computer graphics is the visualization of large, complex information spaces. Datasets of this type have grown rapidly in recent years, both in number and in size. Images of the data stored in these collections must support rapid and accurate exploration and analysis. This article presents a method for constructing visualizations that are both effective and aesthetic. Our approach uses techniques from master paintings and human perception to visualize a multidimensional dataset. Individual data elements are drawn with one or more brush strokes that vary their appearance to represent the element's attribute values. The result is a nonphotorealistic visualization of information stored in the dataset. Our research extends existing glyph-based and nonphotorealistic techniques by applying perceptual guidelines to build an effective representation of the underlying data. The nonphotorealistic properties the strokes employ are selected from studies of the history and theory of Impressionist art. We show that these properties are similar to visual features that are detected by the low-level human visual system. This correspondence allows us to manage the strokes to produce perceptually salient visualizations. Psychophysical experiments confirm a strong relationship between the expressive power of our nonphotorealistic properties and previous findings on the use of perceptual color and texture patterns for data display. Results from these studies are used to produce effective nonphotorealistic visualizations. We conclude by applying our techniques to a large, multidimensional weather dataset to demonstrate their viability in a practical, real-world setting.},
	number = {1},
	urldate = {2013-05-17},
	journal = {{ACM} Trans. Graph.},
	author = {Healey, Christopher G. and Tateosian, Laura and Enns, James T. and Remple, Mark},
	month = jan,
	year = {2004},
	keywords = {Abstractionism, Color, Computer Graphics, human vision, Impressionism, nonphotorealistic rendering, perception, psychophysics, scientific visualization, texture},
	pages = {64-96},
	file = {ACM Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\JNZP5UJX\Healey et al. - 2004 - Perceptually based brush strokes for nonphotoreali.pdf:application/pdf}
}

@article{hertzmann_survey_2003,
	title = {A survey of stroke-based rendering},
	volume = {23},
	issn = {0272-1716},
	doi = {10.1109/MCG.2003.1210867},
	abstract = {This tutorial describes several stroke-based rendering ({SBR)} algorithms. {SBR} is an automatic approach to creating nonphotorealistic imagery by placing discrete elements such as paint strokes or stipples.},
	number = {4},
	journal = {{IEEE} Computer Graphics and Applications},
	author = {Hertzmann, A.},
	month = aug,
	year = {2003},
	keywords = {discrete elements, nonphotorealistic imagery, paint strokes, rendering (computer graphics), stipples, stroke-based rendering},
	pages = {70 --81},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\URTHAV92\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\9NN2I7GB\Hertzmann - 2003 - A survey of stroke-based rendering.pdf:application/pdf}
}

@inproceedings{lopez-moreno_stylized_2010,
	address = {New York, {NY}, {USA}},
	series = {{NPAR} '10},
	title = {Stylized depiction of images based on depth perception},
	isbn = {978-1-4503-0125-1},
	url = {http://doi.acm.org/10.1145/1809939.1809952},
	doi = {10.1145/1809939.1809952},
	abstract = {Recent works in image editing are opening up new possibilities to manipulate and enhance input images. Within this context, we leverage well-known characteristics of human perception along with a simple depth approximation algorithm to creatively relight images for the purpose of generating non-photorealistic renditions that would be difficult to achieve with existing methods. Our realtime implementation on graphics hardware allows the user to efficiently explore artistic possibilities for each image. We show results produced with four different styles proving the versatility of our approach, and validate our assumptions and simplifications by means of a user study.},
	urldate = {2013-07-26},
	booktitle = {Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering},
	publisher = {{ACM}},
	author = {Lopez-Moreno, Jorge and Jimenez, Jorge and Hadap, Sunil and Reinhard, Erik and Anjyo, Ken and Gutierrez, Diego},
	year = {2010},
	keywords = {human visual system, image processing, non-photorealistic rendering, relighting},
	pages = {109-118},
	file = {ACM Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\ZEPCSAJI\Lopez-Moreno et al. - 2010 - Stylized depiction of images based on depth percep.pdf:application/pdf}
}

@inproceedings{marks_design_1997,
	address = {New York, {NY}, {USA}},
	series = {{SIGGRAPH} '97},
	title = {Design galleries: a general approach to setting parameters for computer graphics and animation},
	isbn = {0-89791-896-7},
	shorttitle = {Design galleries},
	url = {http://dx.doi.org/10.1145/258734.258887},
	doi = {10.1145/258734.258887},
	urldate = {2013-07-31},
	booktitle = {Proceedings of the 24th annual conference on Computer graphics and interactive techniques},
	publisher = {{ACM} {Press/Addison-Wesley} Publishing Co.},
	author = {Marks, J. and Andalman, B. and Beardsley, P. A. and Freeman, W. and Gibson, S. and Hodgins, J. and Kang, T. and Mirtich, B. and Pfister, H. and Ruml, W. and Ryall, K. and Seims, J. and Shieber, S.},
	year = {1997},
	keywords = {animation, Computer-Aided Design, image rendering, lighting, motion synthesis, Particle systems, physical modeling, visualization, volume rendering},
	pages = {389-400},
	file = {TR97-14.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\JDKKIFG8\TR97-14.pdf:application/pdf}
}

@article{wu_interactive_2007,
	title = {Interactive Transfer Function Design Based on Editing Direct Volume Rendered Images},
	volume = {13},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2007.1051},
	abstract = {Direct volume rendered images ({DVRIs)} have been widely used to reveal structures in volumetric data. However, {DVRIs} generated by many volume visualization techniques can only partially satisfy users' demands. In this paper, we propose a framework for editing {DVRIs}, which can also be used for interactive transfer function ({TF)} design. Our approach allows users to fuse multiple features in distinct {DVRIs} into a comprehensive one, to blend two {DVRIs}, and/or to delete features in a {DVRI.} We further present how these editing operations can generate smooth animations for focus + context visualization. Experimental results on some real volumetric data demonstrate the effectiveness of our method.},
	number = {5},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Wu, Yingcai and Qu, Huamin},
	year = {2007},
	keywords = {Algorithms, animation, animations, Biomedical imaging, computational fluid dynamics, Computer Graphics, context visualization, data visualisation, data visualization, direct volume rendered images, Direct volume rendering, focus + context, Focusing, Fuses, Graphics, image editing, image enhancement, Image Interpretation, Computer-Assisted, Imaging, Three-Dimensional, Information Storage and Retrieval, interactive transfer function, intuitive user interface, morphing, Numerical Analysis, Computer-Assisted, rendering (computer graphics), Signal Processing, Computer-Assisted, Transfer function design, transfer functions, user interfaces, User-Computer Interface, visualization techniques, Word Processing},
	pages = {1027--1040},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\UQ96NDQ5\login.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\7VDF8FWU\Wu and Qu - 2007 - Interactive Transfer Function Design Based on Edit.pdf:application/pdf}
}

@inproceedings{haidacher_information-based_2008,
	address = {Aire-la-Ville, Switzerland, Switzerland},
	series = {{EG} {VCBM'08}},
	title = {Information-based transfer functions for multimodal visualization},
	isbn = {978-3-905674-13-2},
	url = {http://dx.doi.org/10.2312/VCBM/VCBM08/101-108},
	doi = {10.2312/VCBM/VCBM08/101-108},
	abstract = {Transfer functions are an essential part of volume visualization. In multimodal visualization at least two values exist at every sample point. Additionally, other parameters, such as gradient magnitude, are often retrieved for each sample point. To find a good transfer function for this high number of parameters is challenging because of the complexity of this task. In this paper we present a general information-based approach for transfer function design in multimodal visualization which is independent of the used modality types. Based on information theory, the complex multi-dimensional transfer function space is fused to allow utilization of a well-known {2D} transfer function with a single value and gradient magnitude as parameters. Additionally, a quantity is introduced which enables better separation of regions with complementary information. The benefit of the new method in contrast to other techniques is a transfer function space which is easy to understand and which provides a better separation of different tissues. The usability of the new approach is shown on examples of different modalities.},
	urldate = {2013-05-02},
	booktitle = {Proceedings of the First Eurographics conference on Visual Computing for Biomedicine},
	publisher = {Eurographics Association},
	author = {Haidacher, Martin and Bruckner, Stefan and Kanitsar, Armin and Gr{\"o}ller, M. Eduard},
	year = {2008},
	keywords = {Information Theory, Multimodal Visualization, transfer function},
	pages = {101-108},
	file = {haidacher-2008-vcbm-CT-PET.jpg (JPEG Image, 1444 × 1167 pixels):C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\5RM7B9HE\haidacher-2008-vcbm-CT-PET.jpg:image/jpeg;haidacher-2008-vcbm-CT-PET.jpg (JPEG Image, 1444 × 1167 pixels):C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\BKGZBA9A\haidacher-2008-vcbm-CT-PET.jpg:image/jpeg}
}

@article{meyer-spradow_voreen:_2009,
	title = {Voreen: A Rapid-Prototyping Environment for Ray-Casting-Based Volume Visualizations},
	volume = {29},
	issn = {0272-1716},
	shorttitle = {Voreen},
	doi = {10.1109/MCG.2009.130},
	abstract = {By splitting a complex ray-casting process into different tasks performed on different processors, Voreen provides a lot of flexibility because users can intervene at different points during ray casting. Voreen's object-oriented design lets users easily create customized processor classes that cooperate seamlessly with existing classes. A user-friendly {GUI} supports rapid prototyping of visualization ideas. We've implemented several applications based on our library. In the future, we'd like to further extend Voreen's capabilities to make visualization prototyping even easier on all abstraction levels. Thus, we plan to realize a set of dedicated processor skeletons, which are solely configured through shader programs and can thus be modified at runtime.},
	number = {6},
	journal = {{IEEE} Computer Graphics and Applications},
	author = {Meyer-Spradow, J. and Ropinski, T. and Mensmann, J. and Hinrichs, K.},
	year = {2009},
	keywords = {Casting, {GPU-based} ray casting, graphical user interfaces, {GUI}, Libraries, object-oriented design, object-oriented methods, program visualisation, Prototypes, rapid-prototyping environment, ray-casting-based volume visualizations, Runtime, skeleton, software prototyping, visualization, visualization prototyping, volume rendering, Voreen},
	pages = {6--13},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\ZUXEA78N\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\NG8HQGI4\Meyer-Spradow et al. - 2009 - Voreen A Rapid-Prototyping Environment for Ray-Ca.pdf:application/pdf}
}

@article{wang_information_2011,
	title = {Information Theory in Scientific Visualization},
	volume = {13},
	issn = {1099-4300},
	url = {http://www.mdpi.com/1099-4300/13/1/254},
	doi = {10.3390/e13010254},
	number = {12},
	urldate = {2013-07-31},
	journal = {Entropy},
	author = {Wang, Chaoli and Shen, Han-Wei},
	month = jan,
	year = {2011},
	pages = {254--273},
	file = {Entropy | Free Full-Text | Information Theory in Scientific Visualization:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\S9SBUEKJ\254.html:text/html;entropy-13-00254.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\7QNZVSNQ\entropy-13-00254.pdf:application/pdf}
}

@article{chen_information-theoretic_2010,
	title = {An Information-theoretic Framework for Visualization},
	volume = {16},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2010.132},
	abstract = {In this paper, we examine whether or not information theory can be one of the theoretic frameworks for visualization. We formulate concepts and measurements for qualifying visual information. We illustrate these concepts with examples that manifest the intrinsic and implicit use of information theory in many existing visualization techniques. We outline the broad correlation between visualization and the major applications of information theory, while pointing out the difference in emphasis and some technical gaps. Our study provides compelling evidence that information theory can explain a significant number of phenomena or events in visualization, while no example has been found which is fundamentally in conflict with information theory. We also notice that the emphasis of some traditional applications of information theory, such as data compression or data communication, may not always suit visualization, as the former typically focuses on the efficient throughput of a communication channel, whilst the latter focuses on the effectiveness in aiding the perceptual and cognitive process for data understanding and knowledge discovery. These findings suggest that further theoretic developments are necessary for adopting and adapting information theory for visualization.},
	number = {6},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Chen, M. and Jäenicke, H.},
	year = {2010},
	keywords = {communication channel, data communication, data compression, data mining, data visualisation, Information Theory, information-theoretic framework, knowledge discovery, quantitative evaluation, theory of visualization, visual information qualification, visualization techniques},
	pages = {1206--1215},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\FQPBTZJ2\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\VD3DCBN7\Chen and Jäenicke - 2010 - An Information-theoretic Framework for Visualizati.pdf:application/pdf}
}

@inproceedings{roettger_spatialized_2005,
	address = {Aire-la-Ville, Switzerland, Switzerland},
	series = {{EUROVIS'05}},
	title = {Spatialized transfer functions},
	isbn = {3-905673-19-3},
	url = {http://dx.doi.org/10.2312/VisSym/EuroVis05/271-278},
	doi = {10.2312/VisSym/EuroVis05/271-278},
	abstract = {Multi-dimensional transfer functions are an efficient way to visualize features in scalar volume data produced by {CT} or {MRI} scanners. However, the optimal transfer function is difficult to find in general. We present an automatic yet powerful method for the automatic setup of multi-dimensional transfer functions by adding spatial information to the histogram of a volume. Using this information we can easily classify the histogram and derive a transfer function by assigning unique colors to each class of the histogram. Each feature can be selected interactively by pointing and clicking at the corresponding class in the transfer function. In order to render the classified volume with adequate quality we propose an extension of the wellknown pre-integration technique. Furthermore, we demonstrate the flexibility of our approach by giving examples for the imaging of segmented, diffusion-tensor and multi-modal data.},
	urldate = {2013-07-09},
	booktitle = {Proceedings of the Seventh Joint Eurographics / {IEEE} {VGTC} conference on Visualization},
	publisher = {Eurographics Association},
	author = {Roettger, Stefan and Bauer, Michael and Stamminger, Marc},
	year = {2005},
	pages = {271-278},
	file = {EUROVIS05.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\DP3HR2C3\EUROVIS05.pdf:application/pdf;SPATIAL.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\SEDBU2A7\SPATIAL.pdf:application/pdf}
}

@inproceedings{tappenbeck_distance-based_2006,
	title = {Distance-Based Transfer Function Design: Specification Methods and Applications},
	shorttitle = {Distance-Based Transfer Function Design},
	abstract = {We employ distances as a second dimension for transfer function (hereafter {TF)}  specification. Distances refer to selected reference shapes. When distance-based {TFs}  are applied to medical volume data and anatomic structures as reference shapes, they  can support diagnostic procedures and therapy planning. As an example, distance-based  {TFs} may be used to explore the neighborhood of a tumor which is essential to assess  whether a surgical removal is feasible. In this paper, we discuss methods to specify  2d distance-based {TFs}, the use of predefined but adjustable templates to reduce the  interaction effort and an efficient implementation of these {TFs.}},
	booktitle = {{SimVis}},
	author = {Tappenbeck, Andreas and Preim, Bernhard and Dicken, Volker},
	year = {2006},
	pages = {259--274},
	file = {Citeseer - Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\QIFNNC98\Tappenbeck et al. - 2006 - Distance-Based Transfer Function Design Specifica.pdf:application/pdf;Citeseer - Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\IQBJ59V6\summary.html:text/html}
}

@article{correa_size-based_2008,
	title = {Size-based Transfer Functions: A New Volume Exploration Technique},
	volume = {14},
	issn = {1077-2626},
	shorttitle = {Size-based Transfer Functions},
	doi = {10.1109/TVCG.2008.162},
	abstract = {The visualization of complex {3D} images remains a challenge, a fact that is magnified by the difficulty to classify or segment volume data. In this paper, we introduce size-based transfer functions, which map the local scale of features to color and opacity. Features in a data set with similar or identical scalar values can be classified based on their relative size. We achieve this with the use of scale fields, which are {3D} fields that represent the relative size of the local feature at each voxel. We present a mechanism for obtaining these scale fields at interactive rates, through a continuous scale-space analysis and a set of detection filters. Through a number of examples, we show that size-based transfer functions can improve classification and enhance volume rendering techniques, such as maximum intensity projection. The ability to classify objects based on local size at interactive rates proves to be a powerful method for complex data exploration.},
	number = {6},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Correa, C. and Ma, Kwan-Liu},
	month = dec,
	year = {2008},
	keywords = {{3D} fields, Algorithms, complex {3D} images, complex data exploration, data visualisation, detection filters, Diagnostic Imaging, {GPU} Techniques, image classification, image enhancement, Image Interpretation, Computer-Assisted, image representation, image segmentation, Imaging, Three-Dimensional, Index Terms\&\#8212, interactive rates, Interactive Visualization, maximum intensity projection, opacity, Pattern Recognition, Automated, rendering (computer graphics), Reproducibility of Results, Scale Space, Sensitivity and Specificity, size-based transfer functions, transfer functions, volume exploration technique, volume rendering},
	pages = {1380 --1387},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\BVEHDVKE\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\QAAQT4ER\Correa and Ma - 2008 - Size-based Transfer Functions A New Volume Explor.pdf:application/pdf}
}

@article{caban_texture-based_2008,
	title = {Texture-based Transfer Functions for Direct Volume Rendering},
	volume = {14},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2008.169},
	abstract = {Visualization of volumetric data faces the difficult task of finding effective parameters for the transfer functions. Those parameters can determine the effectiveness and accuracy of the visualization. Frequently, volumetric data includes multiple structures and features that need to be differentiated. However, if those features have the same intensity and gradient values, existing transfer functions are limited at effectively illustrating those similar features with different rendering properties. We introduce texture-based transfer functions for direct volume rendering. In our approach, the voxelpsilas resulting opacity and color are based on local textural properties rather than individual intensity values. For example, if the intensity values of the vessels are similar to those on the boundary of the lungs, our texture-based transfer function will analyze the textural properties in those regions and color them differently even though they have the same intensity values in the volume. The use of texture-based transfer functions has several benefits. First, structures and features with the same intensity and gradient values can be automatically visualized with different rendering properties. Second, segmentation or prior knowledge of the specific features within the volume is not required for classifying these features differently. Third, textural metrics can be combined and/or maximized to capture and better differentiate similar structures. We demonstrate our texture-based transfer function for direct volume rendering with synthetic and real-world medical data to show the strength of our technique.},
	number = {6},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Caban, {J.J.} and Rheingans, P.},
	month = dec,
	year = {2008},
	keywords = {data variability, data visualisation, Direct volume rendering, feature classification, feature extraction, gradient methods, gradient value, image classification, image colour analysis, image texture, Index Terms\&\#8212, medical imaging, rendering (computer graphics), statistical analysis, texture-based transfer function, transfer functions, visualization, volume rendering, volumetric data face visualization},
	pages = {1364 --1371},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\KRAHM5PT\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\VMESB38F\Caban and Rheingans - 2008 - Texture-based Transfer Functions for Direct Volume.pdf:application/pdf}
}

@article{drebin_volume_1988,
	title = {Volume rendering},
	volume = {22},
	issn = {0097-8930},
	url = {http://doi.acm.org/10.1145/378456.378484},
	doi = {10.1145/378456.378484},
	abstract = {A technique for rendering images of volumes containing mixtures of materials is presented. The shading model allows both the interior of a material and the boundary between materials to be colored. Image projection is performed by simulating the absorption of light along the ray path to the eye. The algorithms used are designed to avoid artifacts caused by aliasing and quantization and can be efficiently implemented on an image computer. Images from a variety of applications are shown.},
	number = {4},
	urldate = {2013-04-14},
	journal = {{SIGGRAPH} Comput. Graph.},
	author = {Drebin, Robert A. and Carpenter, Loren and Hanrahan, Pat},
	month = jun,
	year = {1988},
	keywords = {computer tomography, image processing, magnetic resonance imaging ({MRI)}, medical imaging, non-destructive evaluation ({NDE)}, scientific visualization},
	pages = {65-74},
	file = {ACM Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\QIQPXZBX\Drebin et al. - 1988 - Volume rendering.pdf:application/pdf}
}

@article{sereda_visualization_2006,
	title = {Visualization of boundaries in volumetric data sets using {LH} histograms},
	volume = {12},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2006.39},
	abstract = {A crucial step in volume rendering is the design of transfer functions that highlights those aspects of the volume data that are of interest to the user. For many applications, boundaries carry most of the relevant information. Reliable detection of boundaries is often hampered by limitations of the imaging process, such as blurring and noise. We present a method to identify the materials that form the boundaries. These materials are then used in a new domain that facilitates interactive and semiautomatic design of appropriate transfer functions. We also show how the obtained boundary information can be used in region-growing-based segmentation.},
	number = {2},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Sereda, P. and Bartroli, {A.V.} and Serlie, {I.W.O.} and Gerritsen, {F.A.}},
	month = apr,
	year = {2006},
	keywords = {Algorithms, boundary detection, Computed tomography, Computer Graphics, Computer Simulation, Data Interpretation, Statistical, data visualisation, data visualization, Direct volume rendering, Histograms, image enhancement, Image Interpretation, Computer-Assisted, image reconstruction, image segmentation, Imaging, Three-Dimensional, Information Storage and Retrieval, interactive design, {LH} histogram, Medical diagnostic imaging, Models, Statistical, Multidimensional systems, multidimensional transfer functions, Numerical Analysis, Computer-Assisted, Optical imaging, region growing., rendering (computer graphics), semiautomatic design, Shape, Signal Processing, Computer-Assisted, transfer function, transfer functions, User-Computer Interface, volume rendering, Volume Visualization},
	pages = {208 --218},
	file = {01580455.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\BQ3DKI6G\01580455.pdf:application/pdf;IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\PKPHVGRS\abs_all.html:text/html}
}

@book{durand_perceptual_2002,
	address = {New York},
	series = {{ACM} {SIGGRAPH} 2002 Course Notes},
	title = {Perceptual and Artistic Principles for Effective Computer Depiction},
	volume = {13},
	url = {http://graphics.lcs.mit.edu/ fredo/SIG02_ArtScience/},
	editor = {Durand, Frédo},
	year = {2002}
}

@inproceedings{sbert_information_2011,
	address = {New York, {NY}, {USA}},
	series = {{SA} '11},
	title = {Information theory in computer graphics and visualization},
	isbn = {978-1-4503-1135-9},
	url = {http://doi.acm.org/10.1145/2077434.2077443},
	doi = {10.1145/2077434.2077443},
	abstract = {We present a half-day course to review several information theory applications for computer graphics and visualization. Information theory tools, widely used in scientific fields such as engineering, physics, genetics and neuroscience, are also emerging as useful transversal tools in computer graphics and related fields. We introduce the basic concepts of information theory and how they map into application areas. Application areas in computer graphics include viewpoint selection, mesh saliency, scene exploration, ambient occlusion, geometry simplification, radiosity, adaptive ray-tracing and shape descriptors. Application areas in visualization are view selection for volume data, flow visualization, ambient occlusion, time-varying volume visualization, transfer function definition, time-varying volume visualization, iso-surface similarity maps and quality metrics. The applications fall broadly into two categories: the mapping of the problem to an information channel - as in viewpoint applications - and the direct use of measures such as entropy, Kullback-Leibler distance, Jensen-Shannon divergence, and f-divergences. These would be used to evaluate, for instance, the homogeneity of a set of samples being used as metrics. We will also discuss the potential applications of the information bottleneck method that allows us to progressively extract or merge information in a hierarchical structure.},
	urldate = {2013-05-02},
	booktitle = {{SIGGRAPH} Asia 2011 Courses},
	publisher = {{ACM}},
	author = {Sbert, Mateu and Feixas, Miquel and Viola, Ivan and Rigau, Jaume and Chover, Miguel},
	year = {2011},
	pages = {10:1-10:58}
}

@article{pessoa_finding_1998,
	title = {Finding out about filling-in: a guide to perceptual completion for visual science and the philosophy of perception},
	volume = {21},
	issn = {0140-{525X}},
	shorttitle = {Finding out about filling-in},
	abstract = {In visual science the term filling-in is used in different ways, which often leads to confusion. This target article presents a taxonomy of perceptual completion phenomena to organize and clarify theoretical and empirical discussion. Examples of boundary completion (illusory contours) and featural completion (color, brightness, motion, texture, and depth) are examined, and single-cell studies relevant to filling-in are reviewed and assessed. Filling-in issues must be understood in relation to theoretical issues about neural-perceptual isomorphism and linking propositions. Six main conclusions are drawn: (1) visual filling-in comprises a multitude of different perceptual completion phenomena; (2) certain forms of visual completion seem to involve spatially propagating neural activity (neural filling-in) and so, contrary to Dennett's (1991; 1992) recent discussion of filling-in, cannot be described as results of the brain's "ignoring an absence" or "jumping to a conclusion"; (3) in certain cases perceptual completion seems to have measurable effects that depend on neural signals representing a presence rather than ignoring an absence; (4) neural filling-in does not imply either "analytic isomorphism" or {"Cartesian} materialism," and thus the notion of the bridge locus--a particular neural stage that forms the immediate substrate of perceptual experience--is problematic and should be abandoned; (5) to reject the representational conception of vision in favor of an "enactive" or "animate" conception reduces the importance of filling-in as a theoretical category in the explanation of vision; and (6) the evaluation of perceptual content should not be determined by "subpersonal" considerations about internal processing, but rather by considerations about the task of vision at the level of the animal or person interacting with the world.},
	language = {eng},
	number = {6},
	journal = {The Behavioral and brain sciences},
	author = {Pessoa, L and Thompson, E and Noë, A},
	month = dec,
	year = {1998},
	note = {{PMID:} 10191878},
	keywords = {Humans, Optical Illusions, psychophysics, Time Factors, Vision, Ocular, Visual Cortex, Visual Perception},
	pages = {723--748; discussion 748-802},
	file = {175.pdf__Predict+Inf+Homunc.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\SC7X4Z6Z\175.pdf__Predict+Inf+Homunc.pdf:application/pdf}
}

@article{serlie_classifying_2007,
	title = {Classifying {CT} Image Data Into Material Fractions by a Scale and Rotation Invariant Edge Model},
	volume = {16},
	issn = {1057-7149},
	doi = {10.1109/TIP.2007.909407},
	abstract = {A fully automated method is presented to classify 3-D {CT} data into material fractions. An analytical scale-invariant description relating the data value to derivatives around Gaussian blurred step edges - arch model - is applied to uniquely combine robustness to noise, global signal fluctuations, anisotropic scale, noncubic voxels, and ease of use via a straightforward segmentation of 3-D {CT} images through material fractions. Projection of noisy data value and derivatives onto the arch yields a robust alternative to the standard computed Gaussian derivatives. This results in a superior precision of the method. The arch-model parameters are derived from a small, but over-determined, set of measurements (data values and derivatives) along a path following the gradient uphill and downhill starting at an edge voxel. The model is first used to identify the expected values of the two pure materials (named and ) and thereby classify the boundary. Second, the model is used to approximate the underlying noise-free material fractions for each noisy measurement. An iso-surface of constant material fraction accurately delineates the material boundary in the presence of noise and global signal fluctuations. This approach enables straightforward segmentation of 3-D {CT} images into objects of interest for computer-aided diagnosis and offers an easy tool for the design of otherwise complicated transfer functions in high-quality visualizations. The method is applied to segment a tooth volume for visualization and digital cleansing for virtual colonoscopy.},
	number = {12},
	journal = {{IEEE} Transactions on Image Processing},
	author = {Serlie, I. W O and Vos, {F.M.} and Truyen, R. and Post, {F.H.} and van Vliet, {L.J.}},
	year = {2007},
	keywords = {Algorithms, Anisotropic Gaussian point spread function ({PSF)}, Anisotropic magnetoresistance, Artificial Intelligence, Computed tomography, computer-aided diagnosis, computerised tomography, {CT} image data classification, edge detection, Fluctuations, Gaussian blurred step edges, Gaussian noise, Gaussian processes, Image analysis, image classification, image segmentation, Imaging, Three-Dimensional, material fractions, medical image processing, Noise measurement, Noise robustness, noisy data, object segmentation, partial volume effect ({PVE)}, Pattern Recognition, Automated, Radiographic Image Enhancement, Radiographic Image Interpretation, Computer-Assisted, Reproducibility of Results, Rotation, rotation invariant edge model, Sensitivity and Specificity, Signal analysis, Tomography, X-Ray Computed, transfer function for visualization, virtual colonoscopy, visualization, voxel classification},
	pages = {2891--2904},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\9TDVPAE3\articleDetails.html:text/html;IEEETIP2007_Serlie.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\67EWGBZZ\IEEETIP2007_Serlie.pdf:application/pdf}
}

@article{bruckner_style_2007,
	title = {Style Transfer Functions for Illustrative Volume Rendering},
	volume = {26},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2007.01095.x/abstract},
	doi = {10.1111/j.1467-8659.2007.01095.x},
	abstract = {Illustrative volume visualization frequently employs non-photorealistic rendering techniques to enhance important features or to suppress unwanted details. However, it is difficult to integrate multiple non-photorealistic rendering approaches into a single framework due to great differences in the individual methods and their parameters. In this paper, we present the concept of style transfer functions. Our approach enables flexible data-driven illumination which goes beyond using the transfer function to just assign colors and opacities. An image-based lighting model uses sphere maps to represent non-photorealistic rendering styles. Style transfer functions allow us to combine a multitude of different shading styles in a single rendering. We extend this concept with a technique for curvature-controlled style contours and an illustrative transparency model. Our implementation of the presented methods allows interactive generation of high-quality volumetric illustrations.},
	language = {en},
	number = {3},
	urldate = {2012-11-14},
	journal = {Computer Graphics Forum},
	author = {Bruckner, S. and Gr{\"o}ller, M. E.},
	year = {2007},
	keywords = {I.3.3 [Computer Graphics]: {Picture/Image} Generation, I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism, illustrative visualization, Transfer functions, volume rendering},
	pages = {715-724},
	file = {Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\T7SSNVZB\Bruckner and Gröller - 2007 - Style Transfer Functions for Illustrative Volume R.pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\XZ54J765\full.html:text/html}
}

@inproceedings{tateosian_engaging_2007,
	address = {New York, {NY}, {USA}},
	series = {{NPAR} '07},
	title = {Engaging viewers through nonphotorealistic visualizations},
	isbn = {978-1-59593-624-0},
	url = {http://doi.acm.org/10.1145/1274871.1274886},
	doi = {10.1145/1274871.1274886},
	abstract = {Research in human visual cognition suggests that beautiful images can engage the visual system, encouraging it to linger in certain locations in an image and absorb subtle details. By developing aesthetically pleasing visualizations of data, we aim to engage viewers and promote prolonged inspection, which can lead to new discoveries within the data. We present three new visualization techniques that apply painterly rendering styles to vary interpretational complexity ({IC)}, indication and detail ({ID)}, and visual complexity ({VC)}, image properties that are important to aesthetics. Knowledge of human visual perception and psychophysical models of aesthetics provide the theoretical basis for our designs. Computational geometry and nonphotorealistic algorithms are used to preprocess the data and render the visualizations. We demonstrate the techniques with visualizations of real weather and supernova data.},
	urldate = {2013-04-29},
	booktitle = {Proceedings of the 5th international symposium on Non-photorealistic animation and rendering},
	publisher = {{ACM}},
	author = {Tateosian, Laura G. and Healey, Christopher G. and Enns, James T.},
	year = {2007},
	keywords = {aesthetics, mesh simplification, nonphotorealistic rendering, {NPR} applications, visualization, voronoi diagrams},
	pages = {93-102},
	file = {ACM Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\URDB9TXZ\Tateosian et al. - 2007 - Engaging viewers through nonphotorealistic visuali.pdf:application/pdf}
}

@article{ebert_designing_2002,
	title = {Designing effective transfer functions for volume rendering from photographic volumes},
	volume = {8},
	issn = {1077-2626},
	doi = {10.1109/2945.998670},
	abstract = {Photographic volumes present a unique, interesting challenge for volume rendering. In photographic volumes, the voxel color is pre-determined, making color selection through transfer functions unnecessary. However, photographic data does not contain a clear mapping from the multi-valued color values to a scalar density or opacity, making projection and compositing much more difficult than with traditional volumes. Moreover, because of the nonlinear nature of color spaces, there is no meaningful norm for the multi-valued voxels. Thus, the individual color channels of photographic data must be treated as incomparable data tuples rather than as vector values. Traditional differential geometric tools, such as intensity gradients, density and Laplacians, are distorted by the nonlinear non-orthonormal color spaces that are the domain of the voxel values. We have developed different techniques for managing these issues while directly rendering volumes from photographic data. We present and justify the normalization of color values by mapping {RGB} values to the {CIE} L*u*v* color space. We explore and compare different opacity transfer functions that map three-channel color values to opacity. We apply these many-to-one mappings to the original {RGB} values as well as to the voxels after conversion to L*u*v* space. Direct rendering using transfer functions allows us to explore photographic volumes without having to commit to an a-priori segmentation that might mask fine variations of interest. We empirically compare the combined effects of each of the two color spaces with our opacity transfer functions using source data from the Visible Human project},
	number = {2},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Ebert, {D.S.} and Morris, {C.J.} and Rheingans, P. and Yoo, {T.S.}},
	year = {2002},
	keywords = {{CIE} L*u*v* color space, color channels, colour graphics, colour photography, compositing, differential geometry, distortion, fine variations, image colour analysis, incomparable data tuples, intensity gradients, Laplacians, many-to-one mappings, multi-valued color values, nonlinear nonorthonormal color space, normalization, opacity, optical transfer function, photographic volumes, projection, rendering (computer graphics), {RGB} values, scalar density, Transfer function design, transfer functions, Visible Human project, volume rendering, voxel color},
	pages = {183--197},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\TSCJCAGE\articleDetails.html:text/html}
}

@article{hauser_two-level_2001,
	title = {Two-level volume rendering},
	volume = {7},
	issn = {1077-2626},
	doi = {10.1109/2945.942692},
	abstract = {Presents a two-level approach for volume rendering, which allows for selectively using different rendering techniques for different subsets of a {3D} data set. Different structures within the data set are rendered locally on an object-by-object basis by either direct volume rendering ({DVR)}, maximum-intensity projection ({MIP)}, surface rendering, value integration (X-ray-like images) or non-photorealistic rendering ({NPR).} All the results of subsequent object renderings are combined globally in a merging step (usually compositing in our case). This allows us to selectively choose the most suitable technique for depicting each object within the data while keeping the amount of information contained in the image at a reasonable level. This is especially useful when inner structures should be visualized together with semi-transparent outer parts, similar to the focus+context approach known from information visualization. We also present an implementation of our approach which allows us to explore volumetric data using two-level rendering at interactive frame rates},
	number = {3},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Hauser, H. and Mroz, L. and Italo Bischi, G. and Gr{\"o}ller, E.},
	month = sep,
	year = {2001},
	keywords = {2-level volume rendering, {3D} data subsets, Biomedical equipment, Biomedical imaging, compositing, Computer Graphics, Context, data visualisation, data visualization, Direct volume rendering, dynamical systems, focus, Focusing, Humans, information visualization, inner structure visualization, interactive frame rates, maximum-intensity projection, medical applications, Medical services, merging, nonphotorealistic rendering, object depiction techniques, object-by-object local rendering, rendering (computer graphics), semi-transparent outer parts, solid modelling, surface rendering, value integration, volumetric data, X-ray imaging, X-ray-like images},
	pages = {242--252},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\32SNWCER\abs_all.html:text/html}
}

@article{corcoran_perceptual_2010,
	title = {Perceptual enhancement of two-level volume rendering},
	volume = {34},
	issn = {0097-8493},
	shorttitle = {Procedural Methods in Computer Graphics Illustrative Visualization},
	url = {http://www.sciencedirect.com/science/article/pii/S0097849310000531},
	doi = {10.1016/j.cag.2010.03.014},
	abstract = {We present a system for interactive visualisation of {3D} volumetric medical datasets combined with perceptual evaluation of how such visualisations can affect a user's interpretation of scenes and attention. Enhancements to traditional volume renderings are provided through a two-level volume rendering strategy which employs fast {GPU-based} direct volume rendering ({DVR)} coupled with an additional layer of perceptual cues derived from various techniques from the non-photorealistic rendering ({NPR)} literature. The two-level approach allows us to successfully separate the most relevant data from peripheral extraneous detail enabling the user to more effectively understand the visual information. Peripheral details are abstracted but sufficiently retained in order to provide spatial reference. We perform a number of perceptual user experiments which test how this approach affects a user's attention and ability to determine the shape of an object. Results indicate that our approach can provide a significant improvement in user perception of shape in complex visualisations, especially when a user has little or no prior knowledge of the data. Our approach would prove extremely useful in technical, medical or scientific visualisations to improve understanding of detailed volumetric datasets.},
	number = {4},
	urldate = {2013-07-08},
	journal = {Computers \& Graphics},
	author = {Corcoran, Andrew and Redmond, Niall and Dingliana, John},
	month = aug,
	year = {2010},
	keywords = {non-photorealistic rendering, Visualisation, volume rendering},
	pages = {388--397},
	file = {ScienceDirect Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\H5FE6DDG\Corcoran et al. - 2010 - Perceptual enhancement of two-level volume renderi.pdf:application/pdf;ScienceDirect Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\CDXFVBJ4\S0097849310000531.html:text/html}
}

@inproceedings{interrante_strategies_1997,
	address = {Los Alamitos, {CA}, {USA}},
	series = {{VIS} '97},
	title = {Strategies for effectively visualizing {3D} flow with volume {LIC}},
	isbn = {1-58113-011-2},
	url = {http://dl.acm.org/citation.cfm?id=266989.267112},
	urldate = {2013-09-10},
	booktitle = {Proceedings of the 8th conference on Visualization '97},
	publisher = {{IEEE} Computer Society Press},
	author = {Interrante, Victoria and Grosch, Chester},
	year = {1997},
	pages = {421-ff.},
	file = {interran.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\9IZBRUW4\interran.pdf:application/pdf}
}

@article{liu_texture-based_2005,
	title = {A Texture-Based Hardware-Independent Technique for Time-Varying Volume Flow Visualization},
	volume = {8},
	issn = {1343-8875},
	url = {http://dx.doi.org/10.1007/BF03181501},
	doi = {10.1007/BF03181501},
	abstract = {Existing texture-based {3D} flow visualization techniques, e.g., volume Line Integral Convolution ({LIC)}, are either limited to steady flows or dependent on special-purpose graphics cards. In this paper we present a texture-based hardware-independent technique for time-varying volume flow visualization. It is based on our Accelerated Unsteady Flow {LIC} ({AUFLIC)} algorithm (Liu and Moorhead, 2005), which uses a flow-driven seeding strategy and a dynamic seeding controller to reuse pathlines in the value scattering process to achieve fast time-dependent flow visualization with high temporal-spatial coherence. We extend {AUFLIC} to {3D} scenarios for accelerated generation of volume flow textures. To address occlusion, lack of depth cuing, and poor perception of flow directions within a dense volume, we employ magnitude-based transfer functions and cutting planes in volume rendering to clearly show the flow structure and the flow evolution.},
	number = {3},
	urldate = {2013-09-14},
	journal = {J. Vis.},
	author = {Liu, Zhanping and {Moorhead,II}, Robert J.},
	month = aug,
	year = {2005},
	keywords = {{LIC}, texture-based flow visualization, {UFLIC}, unsteady {3D} flow, volume rendering},
	pages = {235-244},
	file = {VAUFLIC.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\SB4XS66N\VAUFLIC.pdf:application/pdf}
}

@inproceedings{urnessy_techniques_2004,
	address = {Aire-la-Ville, Switzerland, Switzerland},
	series = {{VISSYM'04}},
	title = {Techniques for visualizing multi-valued flow data},
	isbn = {3-905673-07-X},
	url = {http://dx.doi.org/10.2312/VisSym/VisSym04/165-172},
	doi = {10.2312/VisSym/VisSym04/165-172},
	abstract = {In this paper we discuss several techniques to display multiple scalar distributions within an image depicting a {2D} flow field. We first address how internal contrast and mean luminance can effectively be used to represent a scalar distribution in addition to an underlying flow field. Secondly, we expand upon a current technique to more effectively use luminance ramps over dense streamlines to represent direction of flow. Lastly, we present a new method, based on embossing, to encode the out-of-plane component of a {3D} vector field defined over a {2D} domain. Throughout this paper, we limit our focus to the visualization of steady flows.},
	urldate = {2013-09-14},
	booktitle = {Proceedings of the Sixth Joint Eurographics - {IEEE} {TCVG} conference on Visualization},
	publisher = {Eurographics Association},
	author = {Urnessy, Timothy and Interrante, Victoria and Longmire, Ellen and Marusic, Ivan and Ganapathisubramani, Bharathram},
	year = {2004},
	pages = {165-172},
	file = {vissym04.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\NUP6NMG9\vissym04.pdf:application/pdf}
}

@inproceedings{kaufman_volume_1997,
	title = {Volume Visualization: Principles and Advances},
	shorttitle = {Volume Visualization},
	abstract = {This paper is a survey ofvolume visualization. It includes an introduction to volumetric data; surface rendering techniques for volume data; volume rendering techniques, including image-order,objectorder, and domain techniques; optimization methods for volume rendering; special-purpose volume rendering hardware; global illumination of volumetric data, including volumetric ray tracing and volumetric radiosity; irregular grid rendering; and volume graphics, with several volume modeling techniques, such as voxelization, texture mapping, amorphous phenomena, block operations, constructive solid modeling, and volume sculpting.},
	booktitle = {{ACM} {SIGGRAPH} Course Notes},
	author = {Kaufman, Arie E.},
	year = {1997},
	pages = {23--35},
	file = {Citeseer - Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\43IDCDFC\Kaufman - 2003 - Volume Visualization Principles and Advances.pdf:application/pdf;Citeseer - Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\UHJ4CJVV\summary.html:text/html}
}

@inproceedings{haeberli_paint_1990,
	address = {New York, {NY}, {USA}},
	series = {{SIGGRAPH} '90},
	title = {Paint by numbers: abstract image representations},
	isbn = {0-89791-344-2},
	shorttitle = {Paint by numbers},
	url = {http://doi.acm.org/10.1145/97879.97902},
	doi = {10.1145/97879.97902},
	abstract = {Computer graphics research has concentrated on creating photo-realistic images of synthetic objects. These images communicate surface shading and curvature, as well as the depth relationships of objects in a scene. These renderings are traditionally represented by a rectangular array of pixels that tile the image {plane.As} an alternative to photo-realism, it is possible to create abstract images using an ordered collection of brush strokes. These abstract images filter and refine visual information before it is presented to the viewer. By controlling the color, shape, size, and orientation of individual brush strokes, impressionistic paintings of computer generated or photographic images can easily be created.},
	urldate = {2013-10-14},
	booktitle = {Proceedings of the 17th annual conference on Computer graphics and interactive techniques},
	publisher = {{ACM}},
	author = {Haeberli, Paul},
	year = {1990},
	pages = {207-214},
	file = {download.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\JDEK58AV\download.pdf:application/pdf}
}

@article{tory_human_2004,
	title = {Human factors in visualization research},
	volume = {10},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2004.1260759},
	abstract = {Visualization can provide valuable assistance for data analysis and decision making tasks. However, how people perceive and interact with a visualization tool can strongly influence their understanding of the data as well as the system's usefulness. Human factors therefore contribute significantly to the visualization process and should play an important role in the design and evaluation of visualization tools. Several research initiatives have begun to explore human factors in visualization, particularly in perception-based design. Nonetheless, visualization work involving human factors is in its infancy, and many potentially promising areas have yet to be explored. Therefore, we aim to 1) review known methodology for doing human factors research, with specific emphasis on visualization, 2) review current human factors research in visualization to provide a basis for future investigation, and 3) identify promising areas for future research.},
	number = {1},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Tory, M. and M{\"o}ller, T.},
	year = {2004},
	keywords = {Algorithms, Biomedical imaging, cognition, cognitive support, Computer Graphics, data analysis, data visualisation, data visualization, decision making, decision making task, Fluid flow, Geographic Information Systems, Human Engineering, human factors, Image Interpretation, Computer-Assisted, Imaging, Three-Dimensional, Information Storage and Retrieval, Medical simulation, Online Systems, Pattern Recognition, Automated, perception, research, Research initiatives, Signal Processing, Computer-Assisted, Terminology, User-Computer Interface, Visual Perception, visualization},
	pages = {72--84},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\BMR52CM5\articleDetails.html:text/html;tvcg04.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\HKW6AX8T\tvcg04.pdf:application/pdf}
}

@inproceedings{schumann_assessing_1996,
	address = {New York, {NY}, {USA}},
	series = {{CHI} '96},
	title = {Assessing the effect of non-photorealistic rendered images in {CAD}},
	isbn = {0-89791-777-4},
	url = {http://doi.acm.org/10.1145/238386.238398},
	doi = {10.1145/238386.238398},
	urldate = {2013-11-03},
	booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	publisher = {{ACM}},
	author = {Schumann, Jutta and Strothotte, Thomas and Laser, Stefan and Raab, Andreas},
	year = {1996},
	keywords = {architectural presentation, {CAD}, non-photorealistic rendering, preliminary drafts, sketches},
	pages = {35-41}
}

@article{shannon_mathematical_1948,
	title = {A Mathematical Theory of Communication},
	volume = {27},
	url = {http://cm.bell-labs.com/cm/ms/what/shannonday/shannon1948.pdf},
	number = {3},
	journal = {The Bell System Technical Journal},
	author = {Shannon, Claude E.},
	month = oct,
	year = {1948},
	keywords = {communication, entropy, information, shannon, toread},
	pages = {379--423},
	file = {shannon1948.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\SSBZHFXA\shannon1948.pdf:application/pdf}
}

@misc{website:Roettger_volume_2013,
      author = {Roettger, Stefan},
      title = {The Volume Library},
      month = {January},
      year = {2006},
      url = {http://lgdv.cs.fau.de/External/vollib/},
      howpublished = "\url{http://lgdv.cs.fau.de/External/vollib/}",
      note = {Accessed: 2013-01-20},
      doi = {}
}

@misc{website:Ma_repository_2013,
      author = {Ma, Kwan-Liu},
      title = {Time-Varying Data Repository},
      month = {October},
      year = {2003},
      url = {http://www.cs.ucdavis.edu/~ma/ITR/},
      howpublished = "\url{http://www.cs.ucdavis.edu/~ma/ITR/}",
      note = {Accessed: 2013-02-10},
      doi = {}
}


@misc{website:Voreen_datasets_2013,
	author = {Pra{\ss}ni, J{\"o}rg-Stefan},
	title = {Voreen Data Sets},
	month = {December},
	year = {2013},
	url = {http://www.uni-muenster.de/Voreen/download/workspaces_and_data_sets.html},
	howpublished = "\url{http://www.uni-muenster.de/Voreen/download/workspaces_and_data_sets.html}",
	note = {Accessed: 2013-12-20},
	doi = {}
}

@phdthesis{redmond_influencing_2010,
	address = {Ireland},
	type = {{PhD} Thesis},
	title = {Influencing User Perception Using Real-time Adaptive Abstraction},
	language = {en},
	school = {Trinity College Dublin},
	author = {Redmond, Niall},
	month = sep,
	year = {2010},
	file = {Influencing User Perception Using Real-Time Adaptive Abstraction:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\27QQNT93\redmond2011.pdf:application/pdf}
}

@article{isenberg_systematic_2013,
	title = {A Systematic Review on the Practice of Evaluating Visualization},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.126},
	abstract = {We present an assessment of the state and historic development of evaluation practices as reported in papers published at the {IEEE} Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the {IEEE} Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90\% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the {IEEE} Visualization conference was much more pronounced than in the {IEEE} Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in {IEEE} Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.},
	number = {12},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Isenberg, Tobias and Isenberg, Petra and Chen, Jian and Sedlmair, Michael and M{\"o}ller, Torsten},
	year = {2013},
	keywords = {data visualization, encoding, evaluation, History, information visualization, Mathematical model, scientific visualization, systematic review, Systematics, validation, visualization},
	pages = {2818--2827},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\CGP6DAII\articleDetails.html:text/html;Isenberg_2013_SRP.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\6JMU8FGR\Isenberg_2013_SRP.pdf:application/pdf}
}

@article{lam_empirical_2012,
	title = {Empirical Studies in Information Visualization: Seven Scenarios},
	volume = {18},
	issn = {1077-2626},
	shorttitle = {Empirical Studies in Information Visualization},
	doi = {10.1109/TVCG.2011.279},
	abstract = {We take a new, scenario-based look at evaluation in information visualization. Our seven scenarios, evaluating visual data analysis and reasoning, evaluating user performance, evaluating user experience, evaluating environments and work practices, evaluating communication through visualization, evaluating visualization algorithms, and evaluating collaborative data analysis were derived through an extensive literature review of over 800 visualization publications. These scenarios distinguish different study goals and types of research questions and are illustrated through example studies. Through this broad survey and the distillation of these scenarios, we make two contributions. One, we encapsulate the current practices in the information visualization research community and, two, we provide a different approach to reaching decisions about what might be the most effective evaluation of a given information visualization. Scenarios can be used to choose appropriate research questions and goals and the provided examples can be consulted for guidance on how to design one's own study.},
	number = {9},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Lam, H. and Bertini, E. and Isenberg, P. and Plaisant, C. and Carpendale, S.},
	year = {2012},
	keywords = {data analysis, data visualisation, data visualization, Electronic mail, empirical studies, encoding, evaluating collaborative data analysis, evaluating communication, evaluating environments, evaluating user experience, evaluating visualization algorithms, evaluation., information visualization, seven scenarios, Systematics, Taxonomy, user performance evaluation, visual data analysis, visual data reasoning, visualization, visualization publications},
	pages = {1520--1536},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\3IUS28QT\login.html:text/html;tvcg2011-seven-scenarios.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\U46X2DVB\tvcg2011-seven-scenarios.pdf:application/pdf}
}

@techreport{chen_what_2013,
	type = {{arXiv} e-print},
	title = {What is Visualization Really for?},
	url = {http://arxiv.org/abs/1305.5670},
	abstract = {Whenever a visualization researcher is asked about the purpose of visualization, the phrase "gaining insight" by and large pops out instinctively. However, it is not absolutely factual that all uses of visualization are for gaining a deep understanding, unless the term insight is broadened to encompass all types of thought. Even when insight is the focus of a visualization task, it is rather difficult to know what insight is gained, how much, or how accurate. In this paper, we propose that "saving time" in accomplishing a user's task is the most fundamental objective. By giving emphasis to saving time, we can establish a concrete metric, alleviate unnecessary contention caused by different interpretations of insight, and stimulate new research efforts in some aspects of visualization, such as empirical studies, design optimisation and theories of visualization.},
	number = {1305.5670},
	urldate = {2013-11-06},
	author = {Chen, Min and Floridi, Luciano and Borgo, Rita},
	month = may,
	year = {2013},
	keywords = {Computer Science - Human-Computer Interaction},
	file = {1305.5670 PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\VSAKTRKT\Chen et al. - 2013 - What is Visualization Really for.pdf:application/pdf;arXiv.org Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\MK5VRHKT\1305.html:text/html}
}

@inproceedings{anderson_evaluating_2012,
	address = {New York, {NY}, {USA}},
	series = {{BELIV} '12},
	title = {Evaluating visualization using cognitive measures},
	isbn = {978-1-4503-1791-7},
	url = {http://doi.acm.org/10.1145/2442576.2442581},
	doi = {10.1145/2442576.2442581},
	abstract = {In this position paper, we discuss the problems and advantages of using physiological measurements to to estimate cognitive load in order to evaluate scientific visualization methods. We will present various techniques and technologies designed to measure cognitive load and how they may be leveraged in the context of user evaluation studies for scientific visualization. We also discuss the challenges of experiments designed to use these physiological measurements.},
	urldate = {2013-11-06},
	booktitle = {Proceedings of the 2012 {BELIV} Workshop: Beyond Time and Errors - Novel Evaluation Methods for Visualization},
	publisher = {{ACM}},
	author = {Anderson, Erik W.},
	year = {2012},
	keywords = {evaluation, human-computer interfaces, scientific visualization},
	pages = {5:1-5:4},
	file = {paper05.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\DURHC8P4\paper05.pdf:application/pdf}
}

@article{christopher_thoughts_2003,
	title = {Thoughts on User Studies: Why, How, and When},
	volume = {23},
	shorttitle = {Thoughts on User Studies},
	abstract = {This article describes our experiences with user studies. We offer some examples of our own studies, talk about the pitfalls and problems we encountered, and show how the results were applied to produce successful visualizations. Although our main goal is to encourage the use of studies in visualization, we recognize that other disciplines also offer important insights into visualization design, for example, the areas of visual design or the visual arts. We conclude by discussing when knowledge from these areas might be preferable to a traditional user study},
	number = {4},
	journal = {{IEEE} Computer Graphics and Applications},
	author = {Christopher, Robert Kosara and Healey, Christopher G. and Interrante, Victoria and Laidlaw, David H. and Ware, Colin},
	year = {2003},
	pages = {20--25},
	file = {Citeseer - Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\XSM8W3TG\Christopher et al. - 2003 - Thoughts on User Studies Why, How, and When.pdf:application/pdf;Citeseer - Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\3SN4D95S\summary.html:text/html}
}

@inproceedings{laidlaw_quantitative_2001,
	title = {Quantitative comparative evaluation of {2D} vector field visualization methods},
	doi = {10.1109/VISUAL.2001.964505},
	abstract = {Presents results from a user study that compared six visualization methods for {2D} vector data. Two methods used different distributions of short arrows, two used different distributions of integral curves, one used wedges located to suggest flow lines, and the final one was line-integral convolution ({LIC).} We defined three simple but representative tasks for users to perform using visualizations from each method: (1) locating all critical points in an image, (2) identifying critical point types, and (3) advecting a particle. The results show different strengths and weaknesses for each method. We found that users performed better with methods that: (1) showed the sign of vectors within the vector field, (2) visually represented integral curves, and (3) visually represented the locations of critical points. These results provide quantitative support for some of the anecdotal evidence concerning visualization methods. The tasks and testing framework also provide a basis for comparing other visualization methods, for creating more effective methods and for defining additional tasks to further understand tradeoffs among methods. They may also be useful for evaluating {2D} vectors on {2D} surfaces embedded in {3D} and for defining analogous tasks for {3D} visualization methods.},
	booktitle = {Visualization, 2001. {VIS} '01. Proceedings},
	author = {Laidlaw, {D.H.} and Kirby, {R.M.} and Davidson, {J.S.} and Miller, {T.S.} and da Silva, M. and Warren, {W.H.} and Tarr, M.},
	year = {2001},
	keywords = {{2D} surfaces, {2D} vector field visualization methods, Application software, Chromium, computational fluid dynamics, Computer applications, Computer Graphics, Computer Science, Convolution, critical point location, critical point types, critical points, data visualisation, data visualization, flow lines, flow visualisation, Fluid dynamics, graphical user interfaces, human factors, iconic textures, image texture, image-guided streamlines, integral curve distributions, jittered grid icons, line-integral convolution, mathematics, particle advection, quantitative comparative evaluation, scientific visualization, short arrow distributions, Streaming media, Testing, testing framework, tradeoffs, user performance study, vector sign, vectors, Visual Representation, wedges},
	pages = {143--150},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\CH3WTUPT\login.html:text/html}
}

@inproceedings{lombaert_spatio-temporal_2010,
	title = {Spatio-temporal segmentation of the heart in {4D} {MRI} images using graph cuts with motion cues},
	doi = {10.1109/ISBI.2010.5490303},
	abstract = {With the increasing availability of {4D} cardiac imaging technologies, the need for efficient spatio-temporal segmentation algorithms for the heart is growing. We propose a new method for heart segmentation in {4D} data sets. We efficiently use the established graph cut method for the segmentation of the heart by simultaneously exploiting motion and region cues. We construct a {4D} graph designed to find a moving object with a uniform intensity from a static background. This method has useful applications ranging from qualitative tasks such as direct visualization of the heart by removing its surrounding structures, to quantitative tasks such as measurements and analysis of the total heart volume. The method has been tested on cardiac {MRI} sequences with successful results.},
	booktitle = {2010 {IEEE} International Symposium on Biomedical Imaging: From Nano to Macro},
	author = {Lombaert, H. and Cheriet, F.},
	year = {2010},
	keywords = {4-D cardiac imaging, 4-D {MRI} image, biomedical {MRI}, cardiology, diseases, Echocardiography, graph cut method, Heart, Image motion analysis, image segmentation, image sequences, Magnetic analysis, Magnetic Resonance Imaging, medical image processing, Motion cues, motion picture, Motion pictures, Spatiotemporal phenomena, spatiotemporal segmentation, static background, Testing, total heart volume, uniform intensity, visualization, Volume measurement},
	pages = {492--495},
	file = {IEEE Xplore Abstract Record:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\M8IKEUSN\login.html:text/html;IEEE Xplore Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\E4IEJ67G\Lombaert and Cheriet - 2010 - Spatio-temporal segmentation of the heart in 4D MR.pdf:application/pdf}
}

@article{boykov_graph_2006,
	title = {Graph Cuts and Efficient N-D Image Segmentation},
	volume = {70},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/article/10.1007/s11263-006-7934-5},
	doi = {10.1007/s11263-006-7934-5},
	abstract = {Combinatorial graph cut algorithms have been successfully applied to a wide range of problems in vision and graphics. This paper focusses on possibly the simplest application of graph-cuts: segmentation of objects in image data. Despite its simplicity, this application epitomizes the best features of combinatorial graph cuts methods in vision: global optima, practical efficiency, numerical robustness, ability to fuse a wide range of visual cues and constraints, unrestricted topological properties of segments, and applicability to N-D problems. Graph cuts based approaches to object extraction have also been shown to have interesting connections with earlier segmentation methods such as snakes, geodesic active contours, and level-sets. The segmentation energies optimized by graph cuts combine boundary regularization with region-based properties in the same fashion as Mumford-Shah style functionals. We present motivation and detailed technical description of the basic combinatorial optimization framework for image segmentation via s/t graph cuts. After the general concept of using binary graph cut algorithms for object segmentation was first proposed and tested in Boykov and Jolly (2001), this idea was widely studied in computer vision and graphics communities. We provide links to a large number of known extensions based on iterative parameter re-estimation and learning, multi-scale or hierarchical approaches, narrow bands, and other techniques for demanding photo, video, and medical applications.},
	language = {en},
	number = {2},
	urldate = {2013-11-16},
	journal = {International Journal of Computer Vision},
	author = {Boykov, Yuri and Funka-Lea, Gareth},
	month = nov,
	year = {2006},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Imaging, Graphics and Computer Vision, image processing, Pattern Recognition},
	pages = {109--131},
	file = {ijcv06.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\AU8CDC7Q\ijcv06.pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\7J4HJKT3\10.html:text/html}
}

@article{burns_line_2005,
	title = {Line Drawings from Volume Data},
	volume = {24},
	issn = {0730-0301},
	url = {http://doi.acm.org/10.1145/1073204.1073222},
	doi = {10.1145/1073204.1073222},
	abstract = {Renderings of volumetric data have become an important data analysis tool for applications ranging from medicine to scientific simulation. We propose a volumetric drawing system that directly extracts sparse linear features, such as silhouettes and suggestive contours, using a temporally coherent seed-and-traverse framework. In contrast to previous methods based on isosurfaces or nonrefractive transparency, producing these drawings requires examining an asymptotically smaller subset of the data, leading to efficiency on large data sets. In addition, the resulting imagery is often more comprehensible than standard rendering styles, since it focuses attention on important features in the data. We test our algorithms on datasets up to 5123, demonstrating interactive extraction and rendering of line drawings in a variety of drawing styles.},
	number = {3},
	urldate = {2013-11-17},
	journal = {{ACM} Trans. Graph.},
	author = {Burns, Michael and Klawe, Janek and Rusinkiewicz, Szymon and Finkelstein, Adam and {DeCarlo}, Doug},
	month = jul,
	year = {2005},
	keywords = {isosurface, {NPR}, silhouettes, suggestive contours, visualization, Volume},
	pages = {512-518},
	file = {volines.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\DH75GP6X\volines.pdf:application/pdf}
}

@inproceedings{kirby_visualizing_1999,
	address = {Los Alamitos, {CA}, {USA}},
	series = {{VIS} '99},
	title = {Visualizing multivalued data from {2D} incompressible flows using concepts from painting},
	isbn = {0-7803-5897-X},
	url = {http://dl.acm.org/citation.cfm?id=319351.319429},
	abstract = {We present a new visualization method for 2d flows which allows us to combine multiple data values in an image for simultaneous viewing. We utilize concepts from oil painting, art, and design as introduced in [1] to examine problems within fluid mechanics. We use a combination of discrete and continuous visual elements arranged in multiple layers to visually represent the data. The representations are inspired by the brush strokes artists apply in layers to create an oil painting. We display commonly visualized quantities such as velocity and vorticity together with three additional mathematically derived quantities: the rate of strain tensor (defined in section 4), and the turbulent charge and turbulent current (defined in section 5). We describe the motivation for simultaneously examining these quantities and use the motivation to guide our choice of visual representation for each particular quantity. We present visualizations of three flow examples and observations concerning some of the physical relationships made apparent by the simultaneous display technique that we employed.},
	urldate = {2013-03-17},
	booktitle = {Proceedings of the conference on Visualization '99: celebrating ten years},
	publisher = {{IEEE} Computer Society Press},
	author = {Kirby, R. M. and Marmanis, H. and Laidlaw, David H.},
	year = {1999},
	pages = {333-340},
	file = {ACM Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\X66VEUQJ\Kirby et al. - 1999 - Visualizing multivalued data from 2D incompressibl.pdf:application/pdf}
}

@article{kalnins_coherent_2003,
	title = {Coherent Stylized Silhouettes},
	volume = {22},
	issn = {0730-0301},
	url = {http://doi.acm.org/10.1145/882262.882355},
	doi = {10.1145/882262.882355},
	abstract = {We describe a way to render stylized silhouettes of animated {3D} models with temporal coherence. Coherence is one of the central challenges for non-photorealistic rendering. It is especially difficult for silhouettes, because they may not have obvious correspondences between frames. We demonstrate various coherence effects for stylized silhouettes with a robust working system. Our method runs in real-time for models of moderate complexity, making it suitable for both interactive applications and offline animation.},
	number = {3},
	urldate = {2013-11-17},
	journal = {{ACM} Trans. Graph.},
	author = {Kalnins, Robert D. and Davidson, Philip L. and Markosian, Lee and Finkelstein, Adam},
	month = jul,
	year = {2003},
	keywords = {animation, non-photorealistic rendering, silhouettes},
	pages = {856-861},
	file = {kalnins2003css.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\RC84VKVV\kalnins2003css.pdf:application/pdf}
}

@incollection{kruger_focus_2010,
	series = {{IFMBE} Proceedings},
	title = {Focus and Context-Visualization without the Complexity},
	copyright = {©2010 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-03894-5, 978-3-642-03895-2},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-03895-2_14},
	abstract = {Attempting to display the entirety of a large volumetric dataset at one time would result in an overwhelming amount of information. Furthermore, visualization tools based on volume rendering present the user with a host of confusing options. We present {ClearView}, which provides a simplified volume visualization tool with a focus on doing what matters most: looking at your data. Users frequently want to direct the viewer’s attention to a particular region of their volumes. With many volume rendering tools, this means setting up complex transfer functions to highlight the region of interest, with the unfortunate side effect of potentially affecting the larger image. {ClearView} allows the user to focus their visualization efforts on the area of their choice, while separating parameters for visualizing of surrounding data. This provides not only a simplified user interface, but finergrained control over the final publication-quality visualization. Through advanced {GPU} rendering techniques, {ClearView} presents all of this to the user at highly interactive frame rates.},
	number = {25/13},
	urldate = {2013-11-17},
	booktitle = {World Congress on Medical Physics and Biomedical Engineering, September 7 - 12, 2009, Munich, Germany},
	publisher = {Springer Berlin Heidelberg},
	author = {Krüger, J. and Fogal, T.},
	editor = {Dössel, Olaf and Schlegel, Wolfgang C.},
	month = jan,
	year = {2010},
	keywords = {Biomedical Engineering, Biophysics and Biological Physics, Context, focus, visualization, Volume},
	pages = {45--48},
	file = {focus-context.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\2NEGIFIV\focus-context.pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\6F9XAX64\10.html:text/html}
}

@inproceedings{xu_stylized_2004,
	address = {New York, {NY}, {USA}},
	series = {{NPAR} '04},
	title = {Stylized Rendering of {3D} Scanned Real World Environments},
	isbn = {1-58113-887-3},
	url = {http://doi.acm.org/10.1145/987657.987662},
	doi = {10.1145/987657.987662},
	abstract = {This paper presents an interactive non-photorealistic rendering ({NPR)} system that stylizes and renders outdoor scenes captured by {3D} laser scanning. In order to deal with the large size, complexity and inherent incompleteness of data obtained from outdoor scans, our system represents outdoor scenes using points instead of traditional polygons. Algorithms are then developed to extract, stylize and render features from this point representation. In addition to conveying various {NPR} styles, our system also promises consistency in animation by maintaining stroke coherence and density. We achieve {NPR} of large data at interactive rates by designing novel data structures and algorithms as well as leveraging new features of commodity graphics hardware.},
	urldate = {2013-11-18},
	booktitle = {Proceedings of the 3rd International Symposium on Non-photorealistic Animation and Rendering},
	publisher = {{ACM}},
	author = {Xu, Hui and Chen, Baoquan},
	year = {2004},
	keywords = {{3D} scanning, interactive {3D} graphics, multi-resolution, non-photorealistic rendering, point-based rendering},
	pages = {25-34},
	file = {2005_26.pdf:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\SUTSANWS\2005_26.pdf:application/pdf}
}

@inproceedings{boye_population_2013,
	title = {Population based modeling of respiratory lung motion and prediction from partial information},
	volume = {8669},
	url = {http://dx.doi.org/10.1117/12.2007076},
	doi = {10.1117/12.2007076},
	abstract = {Treatment of tumor sites affected by respiratory motion requires knowledge of the position and the shape of
the tumor and the surrounding organs during breathing. As not all structures of interest can be observed in
real-time, their position needs to be predicted from partial information (so-called surrogates) like motion of
diaphragm, internal markers or patients surface. Here, we present an approach to model respiratory lung motion
and predict the position and shape of the lungs from surrogates. {4D-MRI} lung data of 10 healthy subjects was
acquired and used to create a model based on Principal Component Analysis ({PCA).} The mean {RMS} motion
ranged from 1.88 mm to 9.66 mm. Prediction was done using a Bayesian approach and an average {RMSE} of
1.44 mm was achieved.},
	urldate = {2013-11-08},
	booktitle = {{SPIE} Medical Imaging},
	author = {Boye, Dirk and Samei, Golnoosh and Schmidt, Johannes and Székely, Gabor and Tanner, Christine},
	year = {2013},
	pages = {86690U--86690U-7},
	file = {Untitled Attachment:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\4PKBINV6\Boye et al. - 2013 - Population based modeling of respiratory lung moti.html:text/html}
}

@article{tsoumpas_fast_2011,
	title = {Fast generation of {4D} {PET-MR} data from real dynamic {MR} acquisitions},
	volume = {56},
	issn = {0031-9155},
	url = {http://iopscience.iop.org/0031-9155/56/20/005},
	doi = {10.1088/0031-9155/56/20/005},
	abstract = {We have implemented and evaluated a framework for simulating simultaneous dynamic {PET-MR} data using the anatomic and dynamic information from real {MR} acquisitions. {PET} radiotracer distribution is simulated by assigning typical {FDG} uptake values to segmented {MR} images with manually inserted additional virtual lesions. {PET} projection data and images are simulated using analytic forward projections (including attenuation and Poisson statistics) implemented within the image reconstruction package {STIR.} {PET} image reconstructions are also performed with {STIR.} The simulation is validated with numerical simulation based on Monte Carlo ({GATE)} which uses more accurate physical modelling, but has 150× slower computation time compared to the analytic method for ten respiratory positions and is 7000× slower when performing multiple realizations. Results are validated in terms of region of interest mean values and coefficients of variation for 65 million coincidences including scattered events. Although some discrepancy is observed, agreement between the two different simulation methods is good given the statistical noise in the data. In particular, the percentage difference of the mean values is 3.1\% for tissue, 17\% for the lungs and 18\% for a small lesion. The utility of the procedure is demonstrated by simulating realistic {PET-MR} datasets from multiple volunteers with different breathing patterns. The usefulness of the toolkit will be shown for performance investigations of the reconstruction, motion correction and attenuation correction algorithms for dynamic {PET-MR} data.},
	language = {en},
	number = {20},
	urldate = {2013-11-14},
	journal = {Physics in Medicine and Biology},
	author = {Tsoumpas, C. and Buerger, C. and King, A. P. and Mollet, P. and Keereman, V. and Vandenberghe, S. and Schulz, V. and Schleyer, P. and Schaeffter, T. and Marsden, P. K.},
	month = oct,
	year = {2011},
	pages = {6597},
	file = {Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\GC8WSKW5\Tsoumpas et al. - 2011 - Fast generation of 4D PET-MR data from real dynami.pdf:application/pdf;Snapshot:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\3r6072id.default\zotero\storage\NB2HMDHI\005.html:text/html}
}

@article{zhou_automatic_2009,
	title = {Automatic Transfer Function Generation Using Contour Tree Controlled Residue Flow Model and Color Harmonics},
	volume = {15},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2009.120},
	abstract = {Transfer functions facilitate the volumetric data visualization by assigning optical properties to various data features and scalar values. Automation of transfer function specifications still remains a challenge in volume rendering. This paper presents an approach for automating transfer function generations by utilizing topological attributes derived from the contour tree of a volume. The contour tree acts as a visual index to volume segments, and captures associated topological attributes involved in volumetric data. A residue flow model based on Darcy's Law is employed to control distributions of opacity between branches of the contour tree. Topological attributes are also used to control color selection in a perceptual color space and create harmonic color transfer functions. The generated transfer functions can depict inclusion relationship between structures and maximize opacity and color differences between them. The proposed approach allows efficient automation of transfer function generations, and exploration on the data to be carried out based on controlling of opacity residue flow rate instead of complex low-level transfer function parameter adjustments. Experiments on various data sets demonstrate the practical use of our approach in transfer function generations.},
	number = {6},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Zhou, Jianlong and Takatsuka, Masahiro},
	year = {2009},
	keywords = {Algorithms, Australia, Automatic control, Automatic generation control, automatic transfer function generation, Automation, Color, color harmonics, color selection, colour graphics, Computer Graphics, contour tree, Darcy's law, data visualisation, data visualization, Foot, harmonic color., Head, Humans, Image motion analysis, Image Processing, Computer-Assisted, Knee, Models, Theoretical, opacity, Optical control, Optical harmonic generation, optical properties, perceptual color space, rendering (computer graphics), residue flow model, residueflow, Topology, transfer function, transfer functions, trees (mathematics), volume rendering, volumetric data visualization},
	pages = {1481--1488},
	file = {IEEE Xplore Abstract Record:C:\Users\JoeShengzhou\AppData\Roaming\Zotero\Zotero\Profiles\0m7eflhb.default\zotero\storage\GQ5J3G5I\abs_all.html:text/html;IEEE Xplore Full Text PDF:C:\Users\JoeShengzhou\AppData\Roaming\Zotero\Zotero\Profiles\0m7eflhb.default\zotero\storage\CC7GP4B7\Zhou and Takatsuka - 2009 - Automatic Transfer Function Generation Using Conto.pdf:application/pdf}
}

@article{ip_hierarchical_2012,
	title = {Hierarchical Exploration of Volumes Using Multilevel Segmentation of the Intensity-Gradient Histograms},
	volume = {18},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2012.231},
	abstract = {Visual exploration of volumetric datasets to discover the embedded features and spatial structures is a challenging and tedious task. In this paper we present a semi-automatic approach to this problem that works by visually segmenting the intensity-gradient {2D} histogram of a volumetric dataset into an exploration hierarchy. Our approach mimics user exploration behavior by analyzing the histogram with the normalized-cut multilevel segmentation technique. Unlike previous work in this area, our technique segments the histogram into a reasonable set of intuitive components that are mutually exclusive and collectively exhaustive. We use information-theoretic measures of the volumetric data segments to guide the exploration. This provides a data-driven coarse-to-fine hierarchy for a user to interactively navigate the volume in a meaningful manner.},
	number = {12},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Ip, Cheuk Yiu and Varshney, A. and Jaja, J.},
	year = {2012},
	keywords = {data visualisation, data-driven coarse-to-fine hierarchy, entropy, exploration hierarchy, gradient methods, hierarchical volume exploration, histogram segmentation, Histograms, Image segmentation, Information Theory, Information-guided exploration, information-theoretic measures, intensity-gradient {2D} histogram, intensity-gradient histogram, normalized cut, normalized-cut multilevel segmentation, shape analysis, transfer functions, user exploration behavior, visual exploration, visual segmentation, visualization, Volume classification, volume exploration, Volume measurement, volumetric data segment, volumetric dataset},
	pages = {2355--2363},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\J4VWTHUG\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\V6CI4GF8\\Ip et al. - 2012 - Hierarchical Exploration of Volumes Using Multilev.pdf:application/pdf}
}

@article{rodriguez_state---art_2014,
	title = {State-of-the-art in Compressed {GPU-Based} Direct Volume Rendering},
	volume = {33},
	url = {http://vic.crs4.it/vic/cgi-bin/bib-page.cgi?id='Balsa:2014:SCG'},
	abstract = {Great advancements in commodity graphics hardware have favored {GPU-based} volume rendering as the main adopted solution for interactive exploration of rectilinear scalar volumes on commodity platforms. Nevertheless, long data transfer times and {GPU} memory size limitations are often the main limiting factors, especially for massive, time-varying or multi-volume visualization, as well as for networked visualization on the emerging mobile devices. To address this issue, a variety of level-of-detail data representations and compression techniques have been introduced. In order to improve capabilities and performance over the entire storage, distribution and rendering pipeline, the encoding/decoding process is typically highly asymmetric, and systems should ideally compress at data production time and decompress on demand at rendering time. Compression and level-of-detail pre-computation does not have to adhere to real-time constraints and can be performed off-line for high quality results. In contrast, adaptive real-time rendering from compressed representations requires fast, transient, and spatially independent decompression. In this report, we review the existing compressed {GPU} volume rendering approaches, covering sampling grid layouts, compact representation models, compression techniques, {GPU} ren- dering architectures and fast decoding techniques.},
	journal = {Computer Graphics Forum},
	author = {Rodriguez, Marcos Balsa and Gobbetti, Enrico and Guiti{\'a}n, Jos{\'e} Antonio Iglesias and Makhinya, Maxim and Marton, Fabio and Pajarola, Renato and Suter, Susanne},
	year = {2014},
	note = {To appear},
	keywords = {compression models, compression-domain direct volume rendering, Computer Graphics [I.3.3]: {Picture/Image} Generation Computer Graphics [I.3.7]: Three-dimensional graphics and realism Coding and Information Theory [E.4]: Data compaction and compression Compression (Coding) [I.4.2]: Approximate methods, decoding strategies, decompression architectures, {GPU}, large volume data visualization, level-of-detail representations, preprocessing and encoding, sampling grid layouts, time-varying volume data visualization},
	file = {cgf2014-star_compressed_gpu_dvr.pdf:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\SJEZC43X\\cgf2014-star_compressed_gpu_dvr.pdf:application/pdf;Snapshot:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\V5KKW7IT\\abstract.html:text/html}
}

@article{mindek_visual_2013,
	title = {Visual Parameter Exploration in {GPU} Shader Space},
	volume = {21},
	issn = {1213-6972},
	url = {http://www.cg.tuwien.ac.at/research/publications/2013/mindek-2013-pel/},
	abstract = {The wide availability of high-performance {GPUs} has made the use of shader programs in visualization ubiquitous. Understanding shaders is a challenging task. Frequently it is dif?cult to mentally reconstruct the nature and types of transformations applied to the underlying data during the visualization process. We propose a method for the visual analysis of {GPU} shaders, which allows the ?exible exploration and investigation of algorithms, parameters, and their effects. We introduce a method for extracting feature vectors composed of several attributes of the shader, as well as a direct manipulation interface for assigning semantics to them. The user interactively classi?es pixels of images which are rendered with the investigated shader. The two resulting classes, a positive class and a negative one, are employed to steer the visualization. Based on this information, we can extract a wide variety of additional attributes and visualize their relation to this classi?cation. Our system allows an interactive exploration of shader space and we demonstrate its utility for several different applications.},
	number = {3},
	journal = {Journal of {WSCG}},
	author = {Mindek, Peter and Bruckner, Stefan and Rautek, Peter and Gr{\"o}ller, Meister Eduard},
	year = {2013},
	keywords = {parameter space exploration, shader augmentation},
	pages = {225–234},
	file = {mindek-2013-pel-Paper.pdf:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\IQD83J77\\mindek-2013-pel-Paper.pdf:application/pdf}
}

@article{maciejewski_abstracting_2013,
	title = {Abstracting Attribute Space for Transfer Function Exploration and Design},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2012.105},
	abstract = {Currently, user centered transfer function design begins with the user interacting with a one or two-dimensional histogram of the volumetric attribute space. The attribute space is visualized as a function of the number of voxels, allowing the user to explore the data in terms of the attribute size/magnitude. However, such visualizations provide the user with no information on the relationship between various attribute spaces (e.g., density, temperature, pressure, x, y, z) within the multivariate data. In this work, we propose a modification to the attribute space visualization in which the user is no longer presented with the magnitude of the attribute; instead, the user is presented with an information metric detailing the relationship between attributes of the multivariate volumetric data. In this way, the user can guide their exploration based on the relationship between the attribute magnitude and user selected attribute information as opposed to being constrained by only visualizing the magnitude of the attribute. We refer to this modification to the traditional histogram widget as an abstract attribute space representation. Our system utilizes common one and two-dimensional histogram widgets where the bins of the abstract attribute space now correspond to an attribute relationship in terms of the mean, standard deviation, entropy, or skewness. In this manner, we exploit the relationships and correlations present in the underlying data with respect to the dimension(s) under examination. These relationships are often times key to insight and allow us to guide attribute discovery as opposed to automatic extraction schemes which try to calculate and extract distinct attributes a priori. In this way, our system aids in the knowledge discovery of the interaction of properties within volumetric data.},
	number = {1},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Maciejewski, R. and Jang, Yun and Woo, Insoo and J{\"a}nicke, H. and Gaither, K.P. and Ebert, D.S.},
	month = jan,
	year = {2013},
	keywords = {abstract attribute space representation, attribute discovery, attribute information, attribute magnitude, attribute space visualization, automatic extraction schemes, data mining, data visualisation, Data visualization, entropy, histogram widget, Histograms, image color analysis, information metric, Information Theory, knowledge discovery, mean, Measurement, multivariate volumetric data, one-dimensional histogram, rendering (computer graphics), skewness, standard deviation, Transfer function design, transfer function exploration, transfer functions, two-dimensional histogram, user centered transfer function design, user centred design, volume rendering, volumetric attribute space abstraction},
	pages = {94--107},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\MUU3MT2E\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\JK69SZNU\\Maciejewski et al. - 2013 - Abstracting Attribute Space for Transfer Function .pdf:application/pdf}
}

@inproceedings{csebfalvi_illumination-driven_2012,
	address = {Magdeburg, Germany},
	title = {Illumination-Driven Opacity Modulation for Expressive Volume Rendering},
	url = {http://www.cg.tuwien.ac.at/research/publications/2012/Csebfalvi-2012-IOM/},
	abstract = {Using classical volume visualization, typically a couple of isosurface layers are rendered semi-transparently to show the internal structures contained in the data. However, the opacity transfer function is often difficult to specify such that all the isosurfaces are of high contrast and sufficiently perceivable. In this paper, we propose a volumerendering technique which ensures that the different layers contribute to fairly different regions of the image space. Since the overlapping between the effected regions is reduced, an outer translucent isosurface does not decrease significantly the contrast of a partially hidden inner isosurface. Therefore, the layers of the data become visually well separated. Traditional transfer functions assign color and opacity values to the voxels depending on the density and the gradient. In contrast, we assign also different illumination directions to different materials, and modulate the opacities view-dependently based on the surface normals and the directions of the light sources, which are fixed to the viewing angle. We will demonstrate that this model allows an expressive visualization of volumetric data.},
	booktitle = {Proceedings of Vision, Modeling \& Visualization 2012},
	author = {Csebfalvi, Bal{\'a}zs and T{\'o}th, Bal{\'a}zs and Bruckner, Stefan and Gr{\"o}ller, Meister Eduard},
	month = nov,
	year = {2012},
	keywords = {illumination, illustrative visualization, volume rendering},
	pages = {103–109},
	file = {Csebfalvi-2012-IOM-Paper.pdf:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\BFCGMEHB\\Csebfalvi-2012-IOM-Paper.pdf:application/pdf}
}

@article{marchesin_per-pixel_2010,
	title = {Per-Pixel Opacity Modulation for Feature Enhancement in Volume Rendering},
	volume = {16},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5406522},
	doi = {10.1109/TVCG.2010.30},
	number = {4},
	urldate = {2012-07-17},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Marchesin, Stéphane and Dischler, Jean-Michel and Mongenet, Catherine},
	month = jul,
	year = {2010},
	keywords = {adaptive rendering, Algorithms, alpha blending, Computer Graphics, Computer Simulation, feature enhancement, feature extraction, image enhancement, Image Interpretation, Computer-Assisted, Imaging, Three-Dimensional, Models, Theoretical, nonphotorealistic rendering., opacity, opacity transfer function, per-pixel opacity modulation, relevance function, rendering (computer graphics), User-Computer Interface, volume rendering, volume rendering equation},
	pages = {560--570},
	file = {05406522.pdf:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\44ZNIMGN\\05406522.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\DRW5R5QB\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\D95IT4H4\\Marchesin et al. - 2010 - Per-Pixel Opacity Modulation for Feature Enhanceme.pdf:application/pdf}
}

@article{bruckner_illustrative_2006,
	title = {Illustrative Context-Preserving Exploration of Volume Data},
	volume = {12},
	issn = {1077-2626},
	url = {http://dx.doi.org/10.1109/TVCG.2006.96},
	doi = {10.1109/TVCG.2006.96},
	abstract = {In volume rendering, it is very difficult to simultaneously visualize interior and exterior structures while preserving clear shape cues. Highly transparent transfer functions produce cluttered images with many overlapping structures, while clipping techniques completely remove possibly important context information. In this paper, we present a new model for volume rendering, inspired by techniques from illustration. It provides a means of interactively inspecting the interior of a volumetric data set in a feature-driven way which retains context information. The context-preserving volume rendering model uses a function of shading intensity, gradient magnitude, distance to the eye point, and previously accumulated opacity to selectively reduce the opacity in less important data regions. It is controlled by two user-specified parameters. This new method represents an alternative to conventional clipping techniques, sharing their easy and intuitive user control, but does not suffer from the drawback of missing context information.},
	number = {6},
	urldate = {2013-05-09},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Bruckner, Stefan and Grimm, Soren and Kanitsar, Armin and Groller, M. Eduard},
	month = nov,
	year = {2006},
	keywords = {focus+context techniques, {Focus+Context} Techniques, illustrative visualization, Illustrative Visualization, volume rendering, volume rendering.},
	pages = {1559–1569},
	file = {01703375.pdf:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\7Z5JTQG5\\01703375.pdf:application/pdf}
}

@inproceedings{kindlmann_curvature-based_2003,
	address = {Washington, {DC}, {USA}},
	series = {{VIS} '03},
	title = {Curvature-Based Transfer Functions for Direct Volume Rendering: Methods and Applications},
	isbn = {0-7695-2030-8},
	shorttitle = {Curvature-Based Transfer Functions for Direct Volume Rendering},
	url = {http://dx.doi.org/10.1109/VISUAL.2003.1250414},
	doi = {10.1109/VISUAL.2003.1250414},
	abstract = {Direct volume rendering of scalar fields uses a transfer function to map locally measured data properties to opacities and colors. The domain of the transfer function is typically the one-dimensional space of scalar data values. This paper advances the use of curvature information in multi-dimensional transfer functions, with a methodology for computing high-quality curvature measurements. The proposed methodology combines an implicit formulation of curvature with convolution-based reconstruction of the field. We give concrete guidelines for implementing the methodology, and illustrate the importance of choosing accurate filters for computing derivatives with convolution. Curvature-based transfer functions are shown to extend the expressivity and utility of volume rendering through contributions in three different application areas: non-photorealistic volume rendering, surface smoothing via anisotropic diffusion, and visualization of isosurface uncertainty.},
	urldate = {2013-03-12},
	booktitle = {Proceedings of the 14th {IEEE} Visualization 2003 ({VIS'03)}},
	publisher = {{IEEE} Computer Society},
	author = {Kindlmann, Gordon and Whitaker, Ross and Tasdizen, Tolga and M{\"o}ller, Torsten},
	year = {2003},
	keywords = {convolution-based differentiation, flowline curvature, implicit surface curvature, non-photorealistic rendering, surface processing, uncertainty visualization, volume rendering},
	pages = {513--520},
	file = {ACM Full Text PDF:C:\Users\Joe\AppData\Roaming\Zotero\Zotero\Profiles\vuyr0ioc.default\zotero\storage\M6ZDWZ3Z\Kindlmann et al. - 2003 - Curvature-Based Transfer Functions for Direct Volu.pdf:application/pdf}
}

@inproceedings{borland_volumetric_2006,
	title = {Volumetric depth peeling for medical image display},
	volume = {6060},
	url = {http://dx.doi.org/10.1117/12.641497},
	doi = {10.1117/12.641497},
	abstract = {Volumetric depth peeling  ({VDP)} is an extension to volume rendering that enables display of otherwise occluded features in volume data sets.  {VDP} decouples occlusion calculation from the volume rendering transfer function, enabling independent optimization of settings for rendering and occlusion.  The algorithm is flexible enough to handle multiple regions occluding the object of interest, as well as object self-occlusion, and requires no pre-segmentation of the data set.  {VDP} was developed as an improvement for virtual arthroscopy for the diagnosis of shoulder-joint trauma, and has been generalized for use in other simple and complex joints, and to enable non-invasive urology studies.  In virtual arthroscopy, the surfaces in the joints often occlude each other, allowing limited viewpoints from which to evaluate these surfaces.  In urology studies, the physician would like to position the virtual camera outside the kidney collecting system and see inside it.  By rendering invisible all voxels between the observer's point of view and objects of interest, {VDP} enables viewing from unconstrained positions.  In essence, {VDP} can be viewed as a technique for automatically defining an optimal data- and task-dependent clipping surface.  Radiologists using {VDP} display have been able to perform evaluations of pathologies more easily and more rapidly than with clinical arthroscopy, standard volume rendering, or standard {MRI/CT} slice viewing.},
	urldate = {2014-06-17},
	booktitle = {Proceedings of {SPIE}},
	author = {Borland, David and Clarke, John P. and Fielding, Julia R. and TaylorII, Russell M.},
	year = {2006},
	pages = {606004--606004-11},
	file = {VDPforMed_VDA2006.pdf:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\MTM39I6E\\VDPforMed_VDA2006.pdf:application/pdf}
}

@INPROCEEDINGS{ma_high_2000, 
author={Kwan-Liu Ma and Camp, D.M.}, 
booktitle={Supercomputing, ACM/IEEE 2000 Conference}, 
title={High Performance Visualization of Time-Varying Volume Data over a Wide-Area Network}, 
year={2000}, 
month={Nov}, 
pages={29-29}, 
keywords={Image Compression;Keywords: High Performance Computing;Parallel Volume Rendering;Pipelining;Remote Visualization;Sci-entific;Time-Varying Data;Visualization;Wide-Area Network;Computer displays;Computer networks;Concurrent computing;Costs;Data visualization;High-speed networks;Image coding;Pipeline processing;Rendering (computer graphics);Testing;Image Compression;Keywords: High Performance Computing;Parallel Volume Rendering;Pipelining;Remote Visualization;Sci-entific;Time-Varying Data;Visualization;Wide-Area Network}, 
doi={10.1109/SC.2000.10000}, 
ISSN={1063-9535},}

@techreport{konig_mastering_2000,
	address = {Favoritenstrasse 9-11/186, A-1040 Vienna, Austria},
	type = {Technical Report},
	title = {Mastering Transfer Function Specification by using {VolumePro} Technology},
	url = {http://www.cg.tuwien.ac.at/research/publications/2000/Koenig-2000-ATFS/},
	abstract = {A new user-interface paradigm for the specification of transfer functions is presented. The specification is usually a difficult task as mapping information for a number of different domains (data range, color, opacity, etc.) has to be defined. In the presented approach, the definition of the mapping information can be realized independently for each property domain. A set of specification tools is provided for each domain, enabling users with different levels of experience or demanding time restrictions to choose an appropriate approach for their needs. Real-time feedback during the manipulation of parameters has been proven to be crucial to the specification. An interactive direct-volume-rendering display is realized by utilizing dedicated hardware acceleration.},
	number = {{TR-186-2-00-07}},
	institution = {Institute of Computer Graphics and Algorithms, Vienna University of Technology},
	author = {K{\"o}nig, Andreas and Gr{\"o}ller, Meister Eduard},
	month = mar,
	year = {2000},
	note = {human contact: technical-report@cg.tuwien.ac.at},
	keywords = {Transfer Function Specification, volume visualization, {VolumePro} ray-casting system},
	file = {TR-186-2-00-07Paper.pdf:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\4ZU5DVVV\\TR-186-2-00-07Paper.pdf:application/pdf}
}

@book{feeman_mathematics_2009,
	title = {The Mathematics of Medical Imaging: A Beginner's Guide},
	isbn = {9780387927114},
	shorttitle = {The Mathematics of Medical Imaging},
	abstract = {In 1979, the Nobel Prize for Medicine and Physiology was awarded jointly to Allan {McLeod} Cormack and Godfrey Newbold Houns eld, the two pioneering scienti- engineers primarily responsible for the development, in the 1960s and early 1970s, of computerized axial tomography, popularly known as the {CAT} or {CT} scan. In his papers [13], Cormack, then a Professor at Tufts University, in Massachusetts, dev- oped certain mathematical algorithms that, he envisioned, could be used to create an image from X-ray data. Working completely independently of Cormack and at about the same time, Houns eld, a research scientist at {EMI} Central Research Laboratories in the United Kingdom, designed the rst operational {CT} scanner as well as the rst commercially available model. (See [22] and [23]. ) Since 1980, the number of {CT} scans performed each year in the United States has risen from about 3 million to over 67 million. What few people who have had {CT} scans probably realize is that the fundamental problem behind this procedure is essentially mathematical: If we know the values of the integral of a two- or three-dimensional fu- tion along all possible cross-sections, then how can we reconstruct the function itself? This particular example of what is known as an inverse problem was studied by Johann Radon, an Austrian mathematician, in the early part of the twentieth century.},
	language = {en},
	publisher = {Springer},
	author = {Feeman, Timothy G.},
	month = dec,
	year = {2009},
	keywords = {Computers / Computer Vision \& Pattern Recognition, Computers / Data Processing, Mathematics / Calculus, Mathematics / Discrete Mathematics, Mathematics / Functional Analysis, Mathematics / Mathematical Analysis, Medical / Allied Health Services / Radiological \& Ultrasound Technology, Medical / Biochemistry, Medical / Radiology \& Nuclear Medicine, Technology \& Engineering / Biomedical, Technology \& Engineering / Engineering (General)},
	file = {Feeman T.G. The mathematics of medical imaging.. A beginners guide (Springer, 2010)(ISBN 0387927115)(O)(150s)_CsIp_.pdf:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\7ZG6NRIH\\Feeman T.G. The mathematics of medical imaging.. A beginners guide (Springer, 2010)(ISBN 0387927115)(O)(150s)_CsIp_.pdf:application/pdf}
}

@inproceedings{fang_visualization_2007,
	address = {New York, {NY}, {USA}},
	series = {{GI} '07},
	title = {Visualization and exploration of time-varying medical image data sets},
	isbn = {978-1-56881-337-0},
	url = {http://doi.acm.org/10.1145/1268517.1268563},
	doi = {10.1145/1268517.1268563},
	abstract = {In this work, we propose and compare several methods for the visualization and exploration of time-varying volumetric medical images based on the temporal characteristics of the data. The principle idea is to consider a time-varying data set as a {3D} array where each voxel contains a time-activity curve ({TAC).} We define and appraise three different {TAC} similarity measures. Based on these measures we introduce three methods to analyze and visualize time-varying data. The first method relates the whole data set to one template {TAC} and creates a {1D} histogram. The second method extends the {1D} histogram into a {2D} histogram by taking the Euclidean distance between voxels into account. The third method does not rely on a template {TAC} but rather creates a {2D} scatter-plot of all {TAC} data points via multi-dimensional scaling. These methods allow the user to specify transfer functions on the {1D} and {2D} histograms and on the scatter plot, respectively. We validate these methods on synthetic dynamic {SPECT} and {PET} data sets and a dynamic planar Gamma camera image of a patient. These techniques are designed to offer researchers and health care professionals a new tool to study the time-varying medical imaging data sets.},
	urldate = {2012-11-05},
	booktitle = {Proceedings of Graphics Interface 2007},
	publisher = {{ACM}},
	author = {Fang, Zhe and M{\"o}ller, Torsten and Hamarneh, Ghassan and Celler, Anna},
	year = {2007},
	keywords = {medical imaging, multi-dimensional scaling, time-varying data, transfer function, volume rendering},
	pages = {281–288},
	file = {ACM Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\SP3RP6UG\\Fang et al. - 2007 - Visualization and exploration of time-varying medi.pdf:application/pdf}
}

@article{janicke_multifield_2007,
	title = {Multifield Visualization Using Local Statistical Complexity},
	volume = {13},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2007.70615},
	abstract = {Modern unsteady (multi-)field visualizations require an effective reduction of the data to be displayed. From a huge amount of information the most informative parts have to be extracted. Instead of the fuzzy application dependent notion of feature, a new approach based on information theoretic concepts is introduced in this paper to detect important regions. This is accomplished by extending the concept of local statistical complexity from finite state cellular automata to discretized (multi-)fields. Thus, informative parts of the data can be highlighted in an application-independent, purely mathematical sense. The new measure can be applied to unsteady multifields on regular grids in any application domain. The ability to detect and visualize important parts is demonstrated using diffusion, flow, and weather simulations.},
	number = {6},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {J{\"a}nicke, Heike and Wiebel, Alexander and Scheuermann, Gerik and Kollmann, Wolfgang},
	year = {2007},
	keywords = {coherent structures, feature detection, flow visualization., information theory, local statistical complexity, multifield visualization, time-dependent},
	pages = {1384--1391},
	file = {IEEE Computer Snapshot:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\XQFMXA83\\Jänicke et al. - 2007 - Multifield Visualization Using Local Statistical C.html:text/html;jaenicke_vis07.pdf:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\RVZ3BS2R\\jaenicke_vis07.pdf:application/pdf}
}

@article{xu_information-theoretic_2010,
	title = {An Information-Theoretic Framework for Flow Visualization},
	volume = {16},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2010.131},
	abstract = {The process of visualization can be seen as a visual communication channel where the input to the channel is the raw data, and the output is the result of a visualization algorithm. From this point of view, we can evaluate the effectiveness of visualization by measuring how much information in the original data is being communicated through the visual communication channel. In this paper, we present an information-theoretic framework for flow visualization with a special focus on streamline generation. In our framework, a vector field is modeled as a distribution of directions from which Shannon's entropy is used to measure the information content in the field. The effectiveness of the streamlines displayed in visualization can be measured by first constructing a new distribution of vectors derived from the existing streamlines, and then comparing this distribution with that of the original data set using the conditional entropy. The conditional entropy between these two distributions indicates how much information in the original data remains hidden after the selected streamlines are displayed. The quality of the visualization can be improved by progressively introducing new streamlines until the conditional entropy converges to a small value. We describe the key components of our framework with detailed analysis, and show that the framework can effectively visualize {2D} and {3D} flow data.},
	number = {6},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Xu, Lijie and Lee, Teng-Yok and Shen, Han-Wei},
	month = dec,
	year = {2010},
	keywords = {{2D} flow data visualization, {3D} flow data.visualization, computational fluid dynamics, conditional entropy, data visualisation, Data visualization, entropy, Flow field visualization, flow visualisation, Histograms, information theory, Information theory, information-theoretic framework, Shannon's entropy, Streaming media, streamline generation, streamline generation., three dimensional displays, vector field, visual communication channel, visualization},
	pages = {1216 --1224},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\364R8RPS\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\WIW8RANM\\Xu et al. - 2010 - An Information-Theoretic Framework for Flow Visual.pdf:application/pdf}
}

@article{bramon_information-theoretic_2013,
	title = {An Information-Theoretic Observation Channel for Volume Visualization},
	volume = {32},
	copyright = {© 2013 The Author(s) Computer Graphics Forum © 2013 The Eurographics Association and Blackwell Publishing Ltd.},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/cgf.12128/abstract},
	doi = {10.1111/cgf.12128},
	abstract = {Different quality metrics have been proposed in the literature to evaluate how well a visualization represents the underlying data. In this paper, we present a new information-theoretic framework that quantifies the information transfer between the source data set and the rendered image. This approach is based on the definition of an observation channel whose input and output are given by the intensity values of the volumetric data set and the pixel colors, respectively. From this channel, the mutual information, a measure of information transfer or correlation between the input and the output, is used as a metric to evaluate the visualization quality. The usefulness of the proposed observation channel is illustrated with three fundamental visualization applications: selection of informative viewpoints, transfer function design, and light positioning.},
	language = {en},
	number = {3pt4},
	urldate = {2013-08-06},
	journal = {Computer Graphics Forum},
	author = {Bramon, R. and Ruiz, M. and Bardera, A. and Boada, I. and Feixas, M. and Sbert, M.},
	year = {2013},
	keywords = {[Computer, Algorithms, {Generation—Viewing}, Graphics]:, I.3.3, I.3.3 [Computer Graphics]: {Picture/Image} {Generation—Viewing} algorithms, {Picture/Image}},
	pages = {411-420},
	file = {Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\IGX55EHN\\Bramon et al. - 2013 - An Information-Theoretic Observation Channel for V.pdf:application/pdf;Snapshot:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\N9TMS7KU\\abstract.html:text/html}
}

@article{chan_perception-based_2009,
	title = {Perception-Based Transparency Optimization for Direct Volume Rendering},
	volume = {15},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2009.172},
	abstract = {The semi-transparent nature of direct volume rendered images is useful to depict layered structures in a volume. However, obtaining a semi-transparent result with the layers clearly revealed is difficult and may involve tedious adjustment on opacity and other rendering parameters. Furthermore, the visual quality of layers also depends on various perceptual factors. In this paper, we propose an auto-correction method for enhancing the perceived quality of the semi-transparent layers in direct volume rendered images. We introduce a suite of new measures based on psychological principles to evaluate the perceptual quality of transparent structures in the rendered images. By optimizing rendering parameters within an adaptive and intuitive user interaction process, the quality of the images is enhanced such that specific user requirements can be met. Experimental results on various datasets demonstrate the effectiveness and robustness of our method.},
	number = {6},
	journal = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Chan, Ming-Yuen and Wu, Yingcai and Mak, Wai-Ho and Chen, Wei and Qu, Huamin},
	month = dec,
	year = {2009},
	keywords = {auto-correction method, Computer Graphics, Diagnostic Imaging, direct volume rendered images, Direct volume rendering, image enhancement, Image enhancement, Image Processing, Computer-Assisted, Image quality, Image resolution, intuitive user interaction process, layer perception., perception-based transparency optimization, psychological principles, Psychology, rendering (computer graphics), Rendering (computer graphics), Robustness, Shape measurement, Transfer functions, user interfaces, User-Computer Interface, Visual perception, visual quality, Visualization},
	pages = {1283 --1290},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\P39H2TC9\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\MBKFMXJ3\\Chan et al. - 2009 - Perception-Based Transparency Optimization for Dir.pdf:application/pdf}
}

@inproceedings{luo_information-guided_2014,
	title = {Information-Guided Transfer Function Refinement},
	doi = {10.2312/egsh.20141015},
	booktitle = {Eurographics 2014 - Short Papers},
	author = {Luo, Shengzhou and Dingliana, John},
	month = apr,
	year = {2014},
	pages = {61--64},
	URL = {http://diglib.eg.org/EG/DL/conf/EG2014/short/061-064.pdf},
	DOI = {10.2312/egsh.20141015},
	editor = {Eric Galin and Michael Wand},
	issn = {1017-4656},
	address = {Strasbourg, France},
	publisher = {Eurographics Association}
}

@inproceedings{rezk-salama_automatic_2000,
	title = {Automatic Adjustment of Transfer Functions for 3D Volume Visualization},
	abstract = {In most volume rendering scenarios implicit classification is performed manually by specification data values to visual attributes. An appropriate classification requires both specialized knowledge of the interesting structures within the data set as well as the technical knowhow of the computer scientist. Recent automatic data-driven techniques are verywell capable of separating different regions in the data set. However, their applicability in practice is limited, since they do not contain any information about the critical structures which are of interest. In this scenario we propose an efficient and reproducible way to automatically assign transfer function templates, which include individual knowledge as well as personal taste. The presented approach is based on dynamic programming and was successfully applied in medical environment. 1},
	booktitle = {In Proc. Workshop Vision, Modeling, and Visualization ({VMV}},
	publisher = {a},
	author = {Rezk-Salama, Christof and Hastreiter, Peter and Scherer, J{\"o}rg and Greiner, G{\"u}nther},
	year = {2000},
	pages = {357–364},
	file = {Citeseer - Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\75RSXPZF\\Rezk-salama et al. - 2000 - Automatic Adjustment of Transfer Functions for 3D .pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\4GGRJUPG\\summary.html:text/html}
}

@article{kindlmann_transfer_2002,
	title = {Transfer Functions in Direct Volume Rendering: Design Interface Interaction},
	shorttitle = {Transfer Functions in Direct Volume Rendering},
	journal = {{SIGGRAPH} Course Notes},
	author = {Kindlmann, Gordon},
	year = {2002},
	keywords = {Direct volume rendering, transfer function},
	file = {PDF from www.cs.utah.edu:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\t929e2iy.default\\zotero\\storage\\FHBM7FGV\\Kindlmann - Transfer Functions in Direct Volume Rendering Des.pdf:application/pdf}
}

@inproceedings{akiba_simultaneous_2006,
	address = {Aire-la-Ville, Switzerland, Switzerland},
	series = {{EUROVIS}'06},
	title = {Simultaneous classification of time-varying volume data based on the time histogram},
	isbn = {3-905673-31-2},
	url = {http://dx.doi.org/10.2312/VisSym/EuroVis06/171-178},
	doi = {10.2312/VisSym/EuroVis06/171-178},
	abstract = {An important challenge in the application of direct volume rendering to time-varying data is the specification of transfer functions for all time steps. Very little research has been devoted to this problem, however. To address this issue we propose an approach which allows simultaneous classification of the entire time series. We explore options for transfer function specification that are based, either directly or indirectly, on the time histogram. Furthermore, we consider how to effectively provide feedback for interactive classification by exploring options for simultaneous rendering of the time series, again based on the time histogram. Finally, we apply this approach to several large time-varying data sets where we show that the important features at all times are captured with about the same effort it takes to classify one time step using conventional classification.},
	urldate = {2012-11-05},
	booktitle = {Proceedings of the {Eighth} {Joint} {Eurographics} / {IEEE} {VGTC} conference on {Visualization}},
	publisher = {Eurographics Association},
	author = {Akiba, Hiroshi and Fout, Nathaniel and Ma, Kwan-Liu},
	year = {2006},
	pages = {171--178},
	file = {submitted_akiba.pdf:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\NTJFEVTX\\submitted_akiba.pdf:application/pdf}
}

@article{woodring_multi-variate_2006,
	title = {Multi-variate, {Time} {Varying}, and {Comparative} {Visualization} with {Contextual} {Cues}},
	volume = {12},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2006.164},
	abstract = {Time-varying, multi-variate, and comparative data sets are not easily visualized due to the amount of data that is presented to the user at once. By combining several volumes together with different operators into one visualized volume, the user is able to compare values from different data sets in space over time, run, or field without having to mentally switch between different renderings of individual data sets. In this paper, we propose using a volume shader where the user is given the ability to easily select and operate on many data volumes to create comparison relationships. The user specifies an expression with set and numerical operations and her data to see relationships between data fields. Furthermore, we render the contextual information of the volume shader by converting it to a volume tree. We visualize the different levels and nodes of the volume tree so that the user can see the results of suboperations. This gives the user a deeper understanding of the final visualization, by seeing how the parts of the whole are operationally constructed},
	number = {5},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Woodring, J. and Shen, Han-Wei},
	year = {2006},
	keywords = {Animation, comparative, Computer science, contextual information, data visualisation, Data visualization, Filling, focus + context, Humans, multi-variate, multivariate time-varying comparative visualization, numerical operation, rendering (computer graphics), Rendering (computer graphics), rendering technique, Switches, time-varying, Transfer functions, transfer functions, volume shader, volume tree},
	pages = {909--916},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\5TRRDTBF\\abs_all.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\XNK9Q3AE\\Woodring and Shen - 2006 - Multi-variate, Time Varying, and Comparative Visua.pdf:application/pdf}
}

@article{guo_scalable_2012,
	title = {Scalable {Multivariate} {Volume} {Visualization} and {Analysis} {Based} on {Dimension} {Projection} and {Parallel} {Coordinates}},
	volume = {18},
	issn = {1077-2626},
	url = {http://dx.doi.org/10.1109/TVCG.2012.80},
	doi = {10.1109/TVCG.2012.80},
	abstract = {In this paper, we present an effective and scalable system for multivariate volume data visualization and analysis with a novel transfer function interface design that tightly couples parallel coordinates plots (PCP) and MDS-based dimension projection plots. In our system, the PCP visualizes the data distribution of each variate (dimension) and the MDS plots project features. They are integrated seamlessly to provide flexible feature classification without context switching between different data presentations during the user interaction. The proposed interface enables users to identify relevant correlation clusters and assign optical properties with lassos, magic wand, and other tools. Furthermore, direct sketching on the volume rendered images has been implemented to probe and edit features. With our system, users can interactively analyze multivariate volumetric data sets by navigating and exploring feature spaces in unified PCP and MDS plots. To further support large-scale multivariate volume data visualization and analysis, Scalable Pivot MDS (SPMDS), parallel adaptive continuous PCP rendering, as well as parallel rendering techniques are developed and integrated into our visualization system. Our experiments show that the system is effective in multivariate volume data visualization and its performance is highly scalable for data sets with different sizes and number of variates.},
	number = {9},
	urldate = {2013-05-01},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Guo, Hanqi and Xiao, He and Yuan, Xiaoru},
	month = sep,
	year = {2012},
	keywords = {Algorithm design and analysis, context switching, Correlation, data presentations, data visualisation, Data visualization, dimension projection, direct sketching, flexible feature classification, lassos, magic wand, MDS-based dimension projection plots, MDS plots, multivariate volume, multivariate volume data visualization, multivariate volumetric data sets, optical properties, parallel adaptive continuous PCP rendering, Parallel coordinates, parallel coordinates plots, parallel visualization., pattern classification, PCP plots, rendering (computer graphics), Rendering (computer graphics), scalable multivariate volume visualization, scalable pivot MDS, Transfer Function, transfer function interface design, Transfer functions, transfer functions, user interaction, user-interface design, Vegetation, volume rendered images},
	pages = {1397--1410},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\GA6ZPI8E\\articleDetails.html:text/html;IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\8NPAVS9B\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\CDSS99AI\\Guo et al. - 2012 - Scalable Multivariate Volume Visualization and Ana.pdf:application/pdf;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\QITCES5E\\Guo et al. - 2012 - Scalable Multivariate Volume Visualization and Ana.pdf:application/pdf}
}

@inproceedings{liu_multivariate_2014,
	title = {Multivariate volume visualization through dynamic projections},
	doi = {10.1109/LDAV.2014.7013202},
	abstract = {We propose a multivariate volume visualization framework that tightly couples dynamic projections with a high-dimensional transfer function design for interactive volume visualization. We assume that the complex, high-dimensional data in the attribute space can be well-represented through a collection of low-dimensional linear subspaces, and embed the data points in a variety of 2D views created as projections onto these subspaces. Through dynamic projections, we present animated transitions between different views to help the user navigate and explore the attribute space for effective transfer function design. Our framework not only provides a more intuitive understanding of the attribute space but also allows the design of the transfer function under multiple dynamic views, which is more flexible than being restricted to a single static view of the data. For large volumetric datasets, we maintain interactivity during the transfer function design via intelligent sampling and scalable clustering. Using examples in combustion and climate simulations, we demonstrate how our framework can be used to visualize interesting structures in the volumetric space.},
	booktitle = {2014 {IEEE} 4th {Symposium} on {Large} {Data} {Analysis} and {Visualization} ({LDAV})},
	author = {Liu, Shusen and Wang, Bei and Thiagarajan, J.J. and Bremer, P.-T. and Pascucci, V.},
	month = nov,
	year = {2014},
	keywords = {2D view, animated transitions, attribute space, computer animation, data visualisation, Data visualization, dynamic projections, high-dimensional data, high-dimensional transfer function design, Hurricanes, hurricanes, Image color analysis, intelligent sampling, interactive systems, interactive volume visualization, low-dimensional linear subspaces, multiple dynamic view, multivariate volume visualization, Navigation, pattern clustering, principal component analysis, scalable clustering, Space exploration, Transfer functions},
	pages = {35--42},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\VIKJNJHJ\\articleDetails.html:text/html;IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\4AHC5CTZ\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\WP54JTEJ\\Liu et al. - 2014 - Multivariate volume visualization through dynamic .pdf:application/pdf;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\AG3NHCDS\\Liu et al. - 2014 - Multivariate volume visualization through dynamic .pdf:application/pdf}
}

@article{akiba_visualizing_2007,
	title = {Visualizing {Multivariate} {Volume} {Data} from {Turbulent} {Combustion} {Simulations}},
	volume = {9},
	issn = {1521-9615},
	doi = {10.1109/MCSE.2007.42},
	abstract = {To understand dynamic mechanisms, scientists need intuitive and convenient ways to validate known relationships and reveal hidden ones among multiple variables},
	number = {2},
	journal = {Computing in Science Engineering},
	author = {Akiba, Hiroshi and Ma, Kwan-Liu and Chen, Jacqueline H. and Hawkes, Evatt R.},
	month = apr,
	year = {2007},
	keywords = {Biomedical Engineering, Biomedical imaging, chemistry computing, combustion, Computational modeling, data rendering, data visualisation, Data visualization, dynamic mechanisms, dynamics, Fires, heat of combustion, Magnetic resonance imaging, multivariate, multivariate volume data visualization, rendering (computer graphics), Rendering (computer graphics), turbulence, turbulent, turbulent combustion simulations, Ultrasonic imaging, visualization, X-ray imaging},
	pages = {76 --83},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\W7SGPANQ\\abstractAuthors.html:text/html;IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\7HW2URBD\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\K2D2J3SU\\Akiba et al. - 2007 - Visualizing Multivariate Volume Data from Turbulen.pdf:application/pdf;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\8SABM3EX\\Akiba et al. - 2007 - Visualizing Multivariate Volume Data from Turbulen.pdf:application/pdf}
}

@inproceedings{kniss_volume_2002,
 author = {Kniss, Joe and Hansen, Charles and Grenier, Michel and Robinson, Tom},
 title = {Volume Rendering Multivariate Data to Visualize Meteorological Simulations: A Case Study},
 booktitle = {Proceedings of the Symposium on Data Visualisation 2002},
 series = {VISSYM '02},
 year = {2002},
 isbn = {1-58113-536-X},
 location = {Barcelona, Spain},
 pages = {189--ff},
 url = {http://dl.acm.org/citation.cfm?id=509740.509770},
 acmid = {509770},
 publisher = {Eurographics Association},
 address = {Aire-la-Ville, Switzerland, Switzerland},
}

@inproceedings{tominski_task-driven_2008,
	title = {Task-{Driven} {Color} {Coding}},
	doi = {10.1109/IV.2008.24},
	abstract = {Color coding is a widely used visualization method for scalar data. To generate expressive and effective visual representations, it is extremely important to carefully design the mapping from data to color. In this paper, we describe a color coding approach that accounts for the different tasks users might pursue when analyzing data. Our task description is based on the task model of Andrienko \& Andrienko. We apply different color scales and introduce strategies to adapt the color mapping function to support tasks like comparison, localization, or identification of data values.},
	booktitle = {Information {Visualisation}, 2008. {IV} '08. 12th {International} {Conference}},
	author = {Tominski, C. and Fuchs, G. and Schumann, H.},
	month = jul,
	year = {2008},
	keywords = {Cathode ray tubes, Color, color mapping function, color scales, Computer science, data analysis, data visualisation, data visualization, Frequency, Guidelines, Humans, image colour analysis, Liquid crystal displays, Task, task-driven color coding, Thin film transistors, visualization, visualization method},
	pages = {373--380},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\ZTCXP7J3\\abs_all.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\VTEFDK5V\\Tominski et al. - 2008 - Task-Driven Color Coding.pdf:application/pdf}
}

@article{harrower_colorbrewer.org:_2003,
	title = {{ColorBrewer}.org: {An} {Online} {Tool} for {Selecting} {Colour} {Schemes} for {Maps}},
	volume = {40},
	issn = {0008-7041},
	shorttitle = {{ColorBrewer}.org},
	url = {http://www.maneyonline.com/doi/abs/10.1179/000870403235002042},
	doi = {10.1179/000870403235002042},
	number = {1},
	urldate = {2015-03-30},
	journal = {The Cartographic Journal},
	author = {Harrower, Mark and Brewer, Cynthia A.},
	month = jun,
	year = {2003},
	pages = {27--37},
	file = {harrower2003.pdf:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\B4HDJ8FA\\harrower2003.pdf:application/pdf;Snapshot:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\IMB4UDAZ\\000870403235002042.html:text/html}
}

@inproceedings{hastreiter_integrated_1998,
	title = {Integrated registration and visualization of medical image data},
	doi = {10.1109/CGI.1998.694253},
	abstract = {Different imaging modalities give insight to vascular, anatomical and functional information which assist diagnosis and therapy planning in medicine. Registration and consecutive visualization allow to combine the image data and thereby convey more meaningful images to the clinician. Applying a voxel based approach based on mutual information, accurate and retrospective registration is provided. However, optimization and consecutive visualization procedures require a huge amount of trilinear interpolation operations to re-sample the data. Ensuring fast performance which is fundamental for medical routine, we suggest an integrated approach which takes advantage of the imaging and texture mapping subsystem of graphics computers. All trilinear interpolation is completely performed with hardware assisted 3D texture mapping. The 1D and 2D histograms of the datasets which are necessary for the calculation of mutual information are obtained with different hardware accelerated imaging operations. For the simultaneous and interactive visualization of the registered datasets a new approach was developed which allows for versatile fusion operations. Using similar procedures supported by hardware, contributes considerably to accelerate registration and visualization. Implementing our approach within a previously presented framework (Hastreiter et al., 1996) (Sommer et al., 1998) based on OpenInventor and OpenGL provides intuitive manipulation. Clinical examples show the value of our approach in practice},
	booktitle = {Computer {Graphics} {International}, 1998. {Proceedings}},
	author = {Hastreiter, P. and Ertl, T.},
	month = jun,
	year = {1998},
	keywords = {1D histograms, 2D histograms, 3D texture mapping, Acceleration, anatomical information, Biomedical imaging, Computer Graphics, data visualisation, data visualization, functional information, graphics computers, Hardware, hardware accelerated imaging, Histograms, image registration, image texture, interpolation, medical diagnosis, medical diagnostic imaging, medical image data visualization, medical image processing, medical image registration, medical treatment, mutual information, OpenGL, OpenInventor, optimisation, Optimization, performance, therapy planning, three dimensional texture mapping, trilinear interpolation operations, vascular information, voxel based approach},
	pages = {78--85},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\GWTXDQ7G\\abs_all.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\R9TBCQ9S\\Hastreiter and Ertl - 1998 - Integrated registration and visualization of medic.pdf:application/pdf}
}

@inproceedings{fedkiw_visual_2001,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '01},
	title = {Visual {Simulation} of {Smoke}},
	isbn = {1-58113-374-X},
	url = {http://doi.acm.org/10.1145/383259.383260},
	doi = {10.1145/383259.383260},
	abstract = {In this paper, we propose a new approach to numerical smoke simulation for computer graphics applications. The method proposed here exploits physics unique to smoke in order to design a numerical method that is both fast and efficient on the relatively coarse grids traditionally used in computer graphics applications (as compared to the much finer grids used in the computational fluid dynamics literature). We use the inviscid Euler equations in our model, since they are usually more appropriate for gas modeling and less computationally intensive than the viscous Navier-Stokes equations used by others. In addition, we introduce a physically consistent vorticity confinement term to model the small scale rolling features characteristic of smoke that are absent on most coarse grid simulations. Our model also correctly handles the inter-action of smoke with moving objects.},
	urldate = {2015-02-25},
	booktitle = {Proceedings of the 28th {Annual} {Conference} on {Computer} {Graphics} and {Interactive} {Techniques}},
	publisher = {ACM},
	author = {Fedkiw, Ronald and Stam, Jos and Jensen, Henrik Wann},
	year = {2001},
	keywords = {computational fluid dynamics, Euler equations, Navier-Stokes equations, participating media, semi-Lagrangian methods, smoke, stable fluids, vorticity confinement},
	pages = {15--22},
	file = {ACM Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\CSXGMVWE\\Fedkiw et al. - 2001 - Visual Simulation of Smoke.pdf:application/pdf}
}

@article{cui_measuring_2006,
	title = {Measuring {Data} {Abstraction} {Quality} in {Multiresolution} {Visualizations}},
	volume = {12},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2006.161},
	abstract = {Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks},
	number = {5},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Cui, Q. and Ward, M.O. and Rundensteiner, E.A. and Yang, J.},
	month = sep,
	year = {2006},
	keywords = {Bioinformatics, Clustering, Coordinate measuring machines, data abstraction quality measures, data analysis, data clustering, Data structures, data structures, data visualisation, Data visualization, Delay, Density measurement, Displays, histogram difference measure, Histograms, Metrics, Multiresolution Visualization Authors 1:, multivariate data analysis, nearest neighbor measure, Nearest neighbor searches, pattern clustering, public-domain multiresolution visualization system, sampling, sampling methods, very large databases, XmdvTool},
	pages = {709--716},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\EX32V6F4\\abs_all.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\CJQKXCQU\\Cui et al. - 2006 - Measuring Data Abstraction Quality in Multiresolut.pdf:application/pdf}
}

@inproceedings{rundensteiner_xmdvtoolq::_2007,
	address = {New York, NY, USA},
	series = {{SIGMOD} '07},
	title = {{XmdvtoolQ}:: {Quality}-aware {Interactive} {Data} {Exploration}},
	isbn = {978-1-59593-686-8},
	shorttitle = {{XmdvtoolQ}},
	url = {http://doi.acm.org/10.1145/1247480.1247623},
	doi = {10.1145/1247480.1247623},
	abstract = {In this work, we describe our approach for making the interactive data exploration system, called XmdvTool, quality-aware to assure informed decision-making. XmdvToolQ, makes quality or lack thereof explicit for all stages of the data exploration process from raw data, to abstracted data, to the final visual displays, allowing users to query and navigate through data-, structure- and quality-spaces.},
	urldate = {2015-06-09},
	booktitle = {Proceedings of the 2007 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Rundensteiner, Elke A. and Ward, Matthew O. and Xie, Zaixian and Cui, Qingguang and Wad, Charudatta V. and Yang, Di and Huang, Shiping},
	year = {2007},
	keywords = {abstraction quality, data quality, display quality},
	pages = {1109--1112},
	file = {ACM Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\NEDQNCNU\\Rundensteiner et al. - 2007 - XmdvtoolQ Quality-aware Interactive Data Explora.pdf:application/pdf}
}

@inproceedings{chen_measuring_2005,
	title = {Measuring the quality of network visualization},
	doi = {10.1145/1065385.1065509},
	abstract = {A quantitative method is developed for measuring the quality of network visualizations in terms of log-likelihood metrics resulted from expectation maximization (EM) clustering intrinsic and extrinsic attributes of network nodes},
	booktitle = {Proceedings of the 5th {ACM}/{IEEE}-{CS} {Joint} {Conference} on {Digital} {Libraries}, 2005. {JCDL} '05},
	author = {Chen, C.},
	month = jun,
	year = {2005},
	keywords = {Chaos, Clustering algorithms, data visualisation, Data visualization, Educational institutions, EM clustering, expectation maximization clustering, graphical user interfaces, Information science, Information systems, learning (artificial intelligence), log-likelihood metrics, Machine Learning, Machine learning algorithms, network nodes, network visualization, network visualizations, pattern clustering, quality measurement, quality metrics of quality, User interfaces},
	pages = {405--405},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\TF4CDTIX\\abs_all.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\ZGI3757B\\Chen - 2005 - Measuring the quality of network visualization.pdf:application/pdf}
}

@inproceedings{van_wijk_value_2005,
	title = {The value of visualization},
	doi = {10.1109/VISUAL.2005.1532781},
	abstract = {The field of visualization is getting mature. Many problems have been solved, and new directions are sought for. In order to make good choices, an understanding of the purpose and meaning of visualization is needed. Especially, it would be nice if we could assess what a good visualization is. In this paper an attempt is made to determine the value of visualization. A technological viewpoint is adopted, where the value of visualization is measured based on effectiveness and efficiency. An economic model of visualization is presented, and benefits and costs are established. Next, consequences (brand limitations of visualization are discussed (including the use of alternative methods, high initial costs, subjective/less, and the role of interaction), as well as examples of the use of the model for the judgement of existing classes of methods and understanding why they are or are not used in practice. Furthermore, two alternative views on visualization are presented and discussed: viewing visualization as an art or as a scientific discipline. Implications and future directions are identified.},
	booktitle = {{IEEE} {Visualization}, 2005. {VIS} 05},
	author = {van Wijk, J.J.},
	month = oct,
	year = {2005},
	keywords = {Application software, Art, Chromium, computer graphics, Computer science, Costs, data visualisation, Data visualization, Explosions, Mathematics, User interfaces, visualization economic model, visualization value},
	pages = {79--86},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\5WEK9XMC\\abs_all.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\5XG8VDCA\\van Wijk - 2005 - The value of visualization.pdf:application/pdf}
}

@inproceedings{filonik_measuring_2009,
	title = {Measuring {Aesthetics} for {Information} {Visualization}},
	doi = {10.1109/IV.2009.94},
	abstract = {Aesthetics is an unsolved problem of information visualization, because there is no satisfactory understanding of what constitutes aesthetic effect. This survey paper gives an overview of approaches to model aesthetics, starting with Birkhoffpsilas aesthetic measure and continuing to recent ones based on mathematical and information theoretical concepts. Common concepts in the different models are highlighted, such as the effects of order and complexity. Further, practical techniques for generating aesthetic visualizations are shown together with examples of recent work in this field. Finally, the paper discusses some of the key issues regarding aesthetics and the human factor in the visualization process. Empirical studies have shown a correlation between perceived aesthetics and usability, meaning that a better understanding of aesthetics could improve the usability of visualizations.},
	booktitle = {Information {Visualisation}, 2009 13th {International} {Conference}},
	author = {Filonik, D. and Baur, D.},
	month = jul,
	year = {2009},
	keywords = {aesthetics, Art, art-beauty philosophy, Birkhoff aesthetics measurement, Chaos, data visualisation, human factor, Human factors, Image generation, Informatics, information visualization, Mathematical model, Measures, philosophical aspects, Pressing, Robustness, Usability, Visualization},
	pages = {579--584},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\QF4JEBU4\\abs_all.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\N8H7FJCC\\Filonik and Baur - 2009 - Measuring Aesthetics for Information Visualization.pdf:application/pdf}
}

@article{janicke_salience-based_2010,
	title = {A {Salience}-based {Quality} {Metric} for {Visualization}},
	volume = {29},
	copyright = {© 2010 The Author(s) Journal compilation © 2010 The Eurographics Association and Blackwell Publishing Ltd.},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2009.01667.x/abstract},
	doi = {10.1111/j.1467-8659.2009.01667.x},
	abstract = {Salience detection is a principle mechanism to facilitate visual attention. A good visualization guides the observer's attention to the relevant aspects of the representation. Hence, the distribution of salience over a visualization image is an essential measure of the quality of the visualization. We describe a method for computing such a metric for a visualization image in the context of a given dataset. We show how this technique can be used to analyze a visualization's salience, improve an existing visualization, and choose the best representation from a set of alternatives. The usefulness of this proposed metric is illustrated using examples from information visualization, volume visualization and flow visualization.},
	language = {en},
	number = {3},
	urldate = {2014-09-09},
	journal = {Computer Graphics Forum},
	author = {Jänicke, H. and Chen, M.},
	month = jun,
	year = {2010},
	keywords = {I.3.3 [Computer Graphics]: Picture/Image Generation—Line and curve generation},
	pages = {1183--1192},
	file = {Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\XN5QGKWW\\Jänicke and Chen - 2010 - A Salience-based Quality Metric for Visualization.pdf:application/pdf;Snapshot:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\JRXVEKC4\\abstract\;jsessionid=01367D9A534BDF6C48AE88AACB058E16.html:text/html}
}

@inproceedings{wu_quantitative_2010,
	title = {Quantitative effectiveness measures for direct volume rendered images},
	doi = {10.1109/PACIFICVIS.2010.5429623},
	abstract = {With the rapid development in graphics hardware and volume rendering techniques, many volumetric datasets can now be rendered in real time on a standard PC equipped with a commodity graphics board. However, the effectiveness of the results, especially direct volume rendered images, is difficult to validate and users may not be aware of ambiguous or even misleading information in the results. This limits the applications of volume visualization. In this paper, we introduce four quantitative effectiveness measures: distinguishability, contour clarity, edge consistency, and depth coherence measures, which target different effectiveness issues for direct volume rendered images. Based on the measures, we develop a visualization system with automatic effectiveness assessment, providing users with instant feedback on the effectiveness of the results. The case study and user evaluation have demonstrated the high potential of our system.},
	booktitle = {2010 {IEEE} {Pacific} {Visualization} {Symposium} ({PacificVis})},
	author = {Wu, Yingcai and Qu, Huamin and Chung, Ka-Kei and Chan, Ming-Yuen and Zhou, Hong},
	year = {2010},
	keywords = {automatic effectiveness assessment, commodity graphics board, computer graphics, contour clarity measure, data analysis, data visualisation, Data visualization, depth coherence measure, direct volume rendered images, distinguishability measure, edge consistency measure, Feedback, graphics hardware, Hardware, Image generation, Measurement standards, PC, quantitative effectiveness measure, rendering (computer graphics), Rendering (computer graphics), Standards development, volume measurement, volume rendering technique, volumetric datasets, volume visualization},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\3VGTT3K5\\abstractCitations.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\7MQ7WDAS\\Wu et al. - 2010 - Quantitative effectiveness measures for direct vol.pdf:application/pdf}
}

@article{cai_automatic_2013,
	title = {Automatic transfer function design for medical visualization using visibility distributions and projective color mapping},
	volume = {37},
	issn = {0895-6111},
	url = {http://www.medicalimagingandgraphics.com/article/S0895-6111(13)00141-9/abstract},
	doi = {10.1016/j.compmedimag.2013.08.008},
	abstract = {Transfer functions play a key role in volume rendering of medical data, but transfer function manipulation is unintuitive and can be time-consuming; achieving an optimal visualization of patient anatomy or pathology is difficult. To overcome this problem, we present a system for automatic transfer function design based on visibility distribution and projective color mapping. Instead of assigning opacity directly based on voxel intensity and gradient magnitude, the opacity transfer function is automatically derived by matching the observed visibility distribution to a target visibility distribution. An automatic color assignment scheme based on projective mapping is proposed to assign colors that allow for the visual discrimination of different structures, while also reflecting the degree of similarity between them. When our method was tested on several medical volumetric datasets, the key structures within the volume were clearly visualized with minimal user intervention.},
	number = {7},
	urldate = {2014-07-18},
	journal = {Computerized Medical Imaging and Graphics},
	author = {Cai, Lile and Tay, Wei-Liang and Nguyen, Binh P. and Chui, Chee-Kong and Ong, Sim-Heng},
	month = oct,
	year = {2013},
	keywords = {Color mapping, Transfer function design, Visibility distribution, volume visualization, Volume visualization},
	pages = {450--458},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\P387H37N\\Cai et al. - 2013 - Automatic transfer function design for medical vis.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\K6HGS37E\\S0895611113001419.html:text/html}
}

@article{qin_voxel_2015,
	title = {The voxel visibility model: {An} efficient framework for transfer function design},
	volume = {40},
	issn = {0895-6111},
	shorttitle = {The voxel visibility model},
	url = {http://www.sciencedirect.com/science/article/pii/S089561111400189X},
	doi = {10.1016/j.compmedimag.2014.11.014},
	abstract = {Volume visualization is a very important work in medical imaging and surgery plan. However, determining an ideal transfer function is still a challenging task because of the lack of measurable metrics for quality of volume visualization. In the paper, we presented the voxel vibility model as a quality metric to design the desired visibility for voxels instead of designing transfer functions directly. Transfer functions are obtained by minimizing the distance between the desired visibility distribution and the actual visibility distribution. The voxel model is a mapping function from the feature attributes of voxels to the visibility of voxels. To consider between-class information and with-class information simultaneously, the voxel visibility model is described as a Gaussian mixture model. To highlight the important features, the matched result can be obtained by changing the parameters in the voxel visibility model through a simple and effective interface. Simultaneously, we also proposed an algorithm for transfer functions optimization. The effectiveness of this method is demonstrated through experimental results on several volumetric data sets.},
	urldate = {2015-05-23},
	journal = {Computerized Medical Imaging and Graphics},
	author = {Qin, Hongxing and Ye, Bin and He, Rui},
	month = mar,
	year = {2015},
	keywords = {Gaussian Mixture Model, GPU, Transfer function design, visibility, volume visualization},
	pages = {138--146},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\DHTU4HSG\\Qin et al. - 2015 - The voxel visibility model An efficient framework.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\NS5B3W2M\\S089561111400189X.html:text/html}
}

@article{giesen_conjoint_2007,
	title = {Conjoint {Analysis} to {Measure} the {Perceived} {Quality} in {Volume} {Rendering}},
	volume = {13},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2007.70542},
	abstract = {Visualization algorithms can have a large number of parameters, making the space of possible rendering results rather high-dimensional. Only a systematic analysis of the perceived quality can truly reveal the optimal setting for each such parameter. However, an exhaustive search in which all possible parameter permutations are presented to each user within a study group would be infeasible to conduct. Additional complications may result from possible parameter co-dependencies. Here, we will introduce an efficient user study design and analysis strategy that is geared to cope with this problem. The user feedback is fast and easy to obtain and does not require exhaustive parameter testing. To enable such a framework we have modified a preference measuring methodology, conjoint analysis, that originated in psychology and is now also widely used in market research. We demonstrate our framework by a study that measures the perceived quality in volume rendering within the context of large parameter spaces.},
	number = {6},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Giesen, J. and Mueller, K. and Schuberth, E. and Wang, Lujin and Zolliker, P.},
	month = nov,
	year = {2007},
	keywords = {Algorithms, computer graphics, Conjoint Analysis, data visualisation, Data visualization, Design engineering, Feedback, Focusing, Humans, image enhancement, Image Interpretation, Computer-Assisted, Imaging, Three-Dimensional, market research, Parameterized Algorithms, perceived quality, psychology, Quality Control, rendering (computer graphics), Reproducibility of Results, Sensitivity and Specificity, Testing, user feedback, visualization algorithms, Visual Perception, volume measurement, Volume rendering, volume visualization},
	pages = {1664--1671},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\CTUTPXRG\\abs_all.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\TPG3J7XJ\\Giesen et al. - 2007 - Conjoint Analysis to Measure the Perceived Quality.pdf:application/pdf}
}

@article{itti_model_1998,
	title = {A model of saliency-based visual attention for rapid scene analysis},
	volume = {20},
	issn = {0162-8828},
	doi = {10.1109/34.730558},
	abstract = {A visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented. Multiscale image features are combined into a single topographical saliency map. A dynamical neural network then selects attended locations in order of decreasing saliency. The system breaks down the complex problem of scene understanding by rapidly selecting, in a computationally efficient manner, conspicuous locations to be analyzed in detail},
	number = {11},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Itti, L. and Koch, C. and Niebur, E.},
	month = nov,
	year = {1998},
	keywords = {Biological system modeling, Brain modeling, Computer architecture, Computer vision, dynamical neural network, feature extraction, Feature extraction, Hardware, Image analysis, image recognition, Layout, neural nets, neural networks, object detection, rapid scene analysis, Saliency, scene understanding, target detection, target tracking, topographical saliency map, Visual attention, visual search, Visual System},
	pages = {1254--1259},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\3X2XCTW7\\abs_all.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\ESCDGV9G\\Itti et al. - 1998 - A model of saliency-based visual attention for rap.pdf:application/pdf}
}

@article{kim_saliency-guided_2006,
	title = {Saliency-guided {Enhancement} for {Volume} {Visualization}},
	volume = {12},
	issn = {1077-2626},
	url = {http://dx.doi.org/10.1109/TVCG.2006.174},
	doi = {10.1109/TVCG.2006.174},
	abstract = {Recent research in visual saliency has established a computational measure of perceptual importance. In this paper we present a visual-saliency-based operator to enhance selected regions of a volume. We show how we use such an operator on a user-specified saliency field to compute an emphasis field. We further discuss how the emphasis field can be integrated into the visualization pipeline through its modifications of regional luminance and chrominance. Finally, we validate our work using an eye-tracking-based user study and show that our new saliency enhancement operator is more effective at eliciting viewer attention than the traditional Gaussian enhancement operator.},
	number = {5},
	urldate = {2013-03-07},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kim, Youngmin and Varshney, Amitabh},
	month = sep,
	year = {2006},
	keywords = {Algorithms, Art, Attention, Biomedical imaging, computer graphics, data visualisation, Data visualization, Eye Movements, Fixation, Ocular, Geometry, Humans, image enhancement, Image Interpretation, Computer-Assisted, Imaging, Three-Dimensional, Large-scale systems, Mouth, non-photorealistic rendering, Optical attenuators, perceptual enhancement, Pipelines, rendering (computer graphics), Rendering (computer graphics), Saliency, saliency-guided enhancement, Transfer functions, transfer functions, User-Computer Interface, Visual attention, visual-saliency-based operator, Volume rendering, volume rendering, volume visualization},
	pages = {925--932},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\7S3EG4U5\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\GQZFMBRX\\Kim and Varshney - 2006 - Saliency-guided Enhancement for Volume Visualizati.pdf:application/pdf;saliency_guided_enhancement.ppt:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\2XCJEI6T\\saliency_guided_enhancement.ppt:application/msword}
}

@book{palmer_vision_1999,
	title = {Vision {Science}: {Photons} to {Phenomenology}},
	isbn = {9780262161831},
	shorttitle = {Vision {Science}},
	abstract = {This book revolutionizes how vision can be taught to undergraduate and graduate students in cognitive science, psychology, and optometry. It is the first comprehensive textbook on vision to reflect the integrated computational approach of modern research scientists. This new interdisciplinary approach, called "vision science," integrates psychological, computational, and neuroscientific perspectives.The book covers all major topics related to vision, from early neural processing of image structure in the retina to high-level visual attention, memory, imagery, and awareness. The presentation throughout is theoretically sophisticated yet requires minimal knowledge of mathematics. There is also an extensive glossary, as well as appendices on psychophysical methods, connectionist modeling, and color technology. The book will serve not only as a comprehensive textbook on vision, but also as a valuable reference for researchers in cognitive science, psychology, neuroscience, computer science, optometry, and philosophy.},
	language = {en},
	publisher = {BRADFORD BOOK},
	author = {Palmer, Stephen E.},
	year = {1999},
	keywords = {Medical / Neuroscience, Psychology / Cognitive Psychology, Psychology / Cognitive Psychology \& Cognition, Science / General, Science / Life Sciences / Anatomy \& Physiology}
}

@article{koch_predicting_1999,
	title = {Predicting the visual world: silence is golden},
	volume = {2},
	copyright = {© 1999 Nature Publishing Group},
	issn = {1097-6256},
	shorttitle = {Predicting the visual world},
	url = {http://www.nature.com/neuro/journal/v2/n1/abs/nn0199_9.html},
	doi = {10.1038/4511},
	abstract = {In predictive coding, only unexpected input features are signaled to the next stage of processing. Rao and Ballard use this approach to model extra−classical receptive field effects.},
	language = {en},
	number = {1},
	urldate = {2015-06-10},
	journal = {Nature Neuroscience},
	author = {Koch, Christof and Poggio, Tomaso},
	month = jan,
	year = {1999},
	pages = {9--10},
	file = {Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\BHH8T47W\\Koch and Poggio - 1999 - Predicting the visual world silence is golden.pdf:application/pdf;Snapshot:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\85JTEKFR\\nn0199_9.html:text/html}
}

@inproceedings{viola_importance-driven_2004,
	address = {Washington, DC, USA},
	series = {{VIS} '04},
	title = {Importance-{Driven} {Volume} {Rendering}},
	isbn = {0-7803-8788-0},
	url = {http://dx.doi.org/10.1109/VISUAL.2004.48},
	doi = {10.1109/VISUAL.2004.48},
	abstract = {This paper introduces importance-driven volume rendering as a novel technique for automatic focus and context display of volumetric data. Our technique is a generalization of cut-away views, which ¿ depending on the viewpoint ¿ remove or suppress less important parts of a scene to reveal more important underlying information. We automatize and apply this idea to volumetric data. Each part of the volumetric data is assigned an object importance which encodes visibility priority. This property determines which structures should be readily discernible and which structures are less important. In those image regions, where an object occludes more important structures it is displayed more sparsely than in those areas where no occlusion occurs. Thus the objects of interest are clearly visible. For each object several representations, i.e., levels of sparseness, are specified. The display of an individual object may incorporate different levels of sparseness. The goal is to emphasize important structures and to maximize the information content in the final image. This paper also discusses several possible schemes for level of sparseness specification and different ways how object importance can be composited to determine the final appearance of a particular object.},
	urldate = {2013-07-27},
	booktitle = {Proceedings of the conference on {Visualization} '04},
	publisher = {IEEE Computer Society},
	author = {Viola, Ivan and Kanitsar, Armin and Groller, Meister Eduard},
	year = {2004},
	keywords = {Biomedical equipment, computer graphics, data visualisation, Data visualization, Focusing, Image generation, image representation, importance-driven volume rendering, Lesions, level-of-details, levels of sparseness, Liver neoplasms, medical diagnostic computing, Medical services, nonphotorealistic techniques, object importance, occlusion, rendering (computer graphics), Shape, view-dependent visualization},
	pages = {139--146},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\ESH65NZJ\\abs_all.html:text/html;IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\FEQVS9MJ\\abs_all.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\FNGBEAWG\\Viola et al. - 2004 - Importance-driven volume rendering.pdf:application/pdf;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\TCPZ5ED3\\Viola et al. - 2004 - Importance-driven volume rendering.pdf:application/pdf}
}

@article{shen_spatiotemporal_2015,
	title = {Spatiotemporal volume saliency},
	issn = {1343-8875, 1875-8975},
	url = {http://link.springer.com/article/10.1007/s12650-015-0293-y},
	doi = {10.1007/s12650-015-0293-y},
	abstract = {Abstract This paper proposes spatiotemporal volume saliency to detect and explore salient regions in time-varying volume data. Based on the center-surround hypothesis that the salient region stands out from its surroundings, we extend the spatial saliency to time domain and introduce temporal volume saliency. It is defined as a center-surround operator on Gaussian-weighted mean attribute gradient between steps in a scale-independent manner. By combing spatial saliency and temporal saliency together, our spatiotemporal volume saliency is effective in detecting changes of salient regions. We demonstrate its utility in this regard by automating transfer function design and selecting key frames for time-varying volume data. Graphical abstract},
	language = {en},
	urldate = {2015-05-24},
	journal = {Journal of Visualization},
	author = {Shen, Enya and Wang, Yunhai and Li, Sikun},
	month = apr,
	year = {2015},
	keywords = {Classical Continuum Physics, Computer Imaging, Vision, Pattern Recognition and Graphics, Engineering Fluid Dynamics, Engineering Thermodynamics, Heat and Mass Transfer, Human perception, Spatiotemporal volume saliency, Time-varying data, Volume exploration},
	pages = {1--12},
	file = {Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\S6PQXBFW\\Shen et al. - 2015 - Spatiotemporal volume saliency.pdf:application/pdf;Snapshot:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\ADICUBI6\\10.html:text/html}
}

@inproceedings{harel_graph-based_2006,
	title = {Graph-{Based} {Visual} {Saliency}},
	abstract = {A new bottom-up visual saliency model, Graph-Based Visual Saliency (GBVS), is proposed. It consists of two steps: �rst forming activation maps on certain feature channels, and then normalizing them in a way which highlights conspicuity and admits combination with other maps. The model is simple, and biologically plau- sible insofar as it is naturally parallelized. This model powerfully predicts human �xations on 749 variations of 108 natural images, achieving 98\% of the ROC area of a human-based control, whereas the classical algorithms of Itti \& Koch ((2), (3), (4)) achieve only 84\%.Read \& annotate PDFRead, annotate and save this article using the colwiz Interactive PDF Reader Add to colwizSave this article to your colwiz library to read and reference anywhere},
	booktitle = {Proceedings of {Neural} {Information} {Processing} {Systems} ({NIPS})},
	author = {Harel, Jonathan and Koch, Christof and Perona, Pietro},
	year = {2006},
	keywords = {Bottom Up, natural images},
	pages = {545--552},
	file = {Citeseer - Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\EGRFHAN3\\Harel et al. - 2007 - Graph-based visual saliency.pdf:application/pdf}
}

@inproceedings{lee_mesh_2005,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '05},
	title = {Mesh {Saliency}},
	url = {http://doi.acm.org/10.1145/1186822.1073244},
	doi = {10.1145/1186822.1073244},
	abstract = {Research over the last decade has built a solid mathematical foundation for representation and analysis of 3D meshes in graphics and geometric modeling. Much of this work however does not explicitly incorporate models of low-level human visual attention. In this paper we introduce the idea of mesh saliency as a measure of regional importance for graphics meshes. Our notion of saliency is inspired by low-level human visual system cues. We define mesh saliency in a scale-dependent manner using a center-surround operator on Gaussian-weighted mean curvatures. We observe that such a definition of mesh saliency is able to capture what most would classify as visually interesting regions on a mesh. The human-perception-inspired importance measure computed by our mesh saliency operator results in more visually pleasing results in processing and viewing of 3D meshes. compared to using a purely geometric measure of shape. such as curvature. We discuss how mesh saliency can be incorporated in graphics applications such as mesh simplification and viewpoint selection and present examples that show visually appealing results from using mesh saliency.},
	urldate = {2014-10-08},
	booktitle = {{ACM} {SIGGRAPH} 2005 {Papers}},
	publisher = {ACM},
	author = {Lee, Chang Ha and Varshney, Amitabh and Jacobs, David W.},
	year = {2005},
	keywords = {perception, Saliency, simplification, Viewpoint selection, visual attention},
	pages = {659--666},
	file = {ACM Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\DHAVHDHN\\Lee et al. - 2005 - Mesh Saliency.pdf:application/pdf}
}

@book{fairchild_color_2013,
	title = {Color {Appearance} {Models}},
	isbn = {1118653106},
	abstract = {The essential resource for readers needing to understand visual perception and for those trying to produce, reproduce and measure color appearance in various applications such as imaging, entertainment, materials, design, architecture and lighting. This book builds upon the success of previous editions, and will continue to serve the needs of those professionals working in the field to solve practical problems or looking for background for on-going research projects. It would also act as a good course text for senior undergraduates and postgraduates studying color science. The 3rd Edition of Color Appearance Models contains numerous new and expanded sections providing an updated review of color appearance and includes many of the most widely used models to date, ensuring its continued success as the comprehensive resource on color appearance models. Key features:  Presents the fundamental concepts and phenomena of color appearance (what objects look like in typical viewing situations) and practical techniques to measure, model and predict those appearances. Includes the clear explanation of fundamental concepts that makes the implementation of mathematical models very easy to understand. Explains many different types of models, and offers a clear context for the models, their use, and future directions in the field.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Fairchild, Mark D.},
	month = jun,
	year = {2013},
	keywords = {Technology \& Engineering / Electrical, Technology \& Engineering / Imaging Systems}
}

@phdthesis{emsenhuber_visibility_2008,
	address = {Favoritenstrasse 9-11/186, A-1040 Vienna, Austria},
	type = {Master's {Thesis}},
	title = {Visibility {Histograms} in {Direct} {Volume} {Rendering}},
	url = {http://www.cg.tuwien.ac.at/research/publications/2008/emsenhuber-2008-vhd/},
	abstract = {This thesis introduces visibility histograms as a method for analyzing volumetric datasets. These histograms show how much the data points within a 3D dataset that have the same scalar value influence the image which is created by rendering the dataset with a particular transfer function and from a particular viewing direction. These histograms can be used to gain insights into the internal structure of volumetric datasets, in particular information about occlusions. Furthermore, the possibility of automatically calculating transfer functions which generate a particular visibility histogram when applied to a dataset from a particular viewing direction is explored. Two methods which can be used to calculate a matching transfer function for a visibility histogram are explained, one of which is based on a genetic algorithm approach, while the other is an heuristic.},
	school = {Institute of Computer Graphics and Algorithms, Vienna University of Technology},
	author = {Emsenhuber, Gerlinde},
	month = nov,
	year = {2008},
	file = {emsenhuber-2008-vhd-paper.pdf:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\89MVZ5WT\\emsenhuber-2008-vhd-paper.pdf:application/pdf}
}

@article{laramee_using_2010,
	title = {Using {Visualization} to {Debug} {Visualization} {Software}},
	volume = {30},
	issn = {0272-1716},
	doi = {10.1109/MCG.2009.154},
	abstract = {This article provides useful strategies for debugging visualization software.The key to debugging visualization software is to exploit the strengths of computer graphics and visualization.},
	number = {6},
	journal = {IEEE Computer Graphics and Applications},
	author = {Laramee, R.S.},
	month = nov,
	year = {2010},
	keywords = {Application software, Computer bugs, computer graphics, Computer graphics, computer graphics applications, Computer science, computer visualization, computing methodologies, Data structures, data visualisation, Data visualization, graphics and multimedia, Guidelines, methodology and techniques, program debugging, Programming profession, program visualisation, Software algorithms, software debugging, Software debugging, visualization software},
	pages = {67--73},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\JAJ7KX6J\\Laramee - 2010 - Using Visualization to Debug Visualization Softwar.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\V2D83J3M\\Laramee - 2010 - Using Visualization to Debug Visualization Softwar.pdf:application/pdf;laramee09debuggingSlides.pdf:C\:\\Users\\JoeShengzhou\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\0m7eflhb.default\\zotero\\storage\\2W375RI7\\laramee09debuggingSlides.pdf:application/pdf}
}

@book{hadwiger_real-time_2006,
	author = {Hadwiger, Markus and Kniss, Joe M. and Rezk-salama, Christof and Weiskopf, Daniel and Engel, Klaus},
	title = {Real-time Volume Graphics},
	year = {2006},
	isbn = {1568812663},
	publisher = {A. K. Peters, Ltd.},
	address = {Natick, MA, USA}
} 

@article{duan_visual_2011,
	author={Lijuan Duan and Chunpeng Wu and Jun Miao and Bovik, A.C.}, 
	journal={Signal Processing Letters, IEEE}, 
	title={Visual Conspicuity Index: Spatial Dissimilarity, Distance, and Central Bias}, 
	year={2011}, 
	month={Nov}, 
	volume={18}, 
	number={11}, 
	pages={690-693}, 
	keywords={image processing;principal component analysis;Kullback-Leibler distance metric;central bias;color image datasets;image conspicuity index;image patches;image processing;receiver operator characteristics analysis;reduced dimensional principal component space;spatial dissimilarity;spatial distance;visual conspicuity index;Analytical models;Bars;Color;Computational modeling;Humans;Indexes;Visualization;central bias;conspicuity;dissimilarity;spatial distance;visual saliency}, 
	doi={10.1109/LSP.2011.2167752}, 
	ISSN={1070-9908}
}

@book{chong_introduction_2013,
	location = {Hoboken, New Jersey},
	edition = {4th},
	title = {An introduction to optimization},
	isbn = {978-1-118-27901-4},
	series = {Wiley series in discrete mathematics and optimization},
	pagetotal = {622},
	publisher = {Wiley},
	author = {Chong, Edwin Kah Pin and Zak, Stanislaw H.},
	date = {2013},
	keywords = {Mathematical optimization},
	file = {An Introduction to Optimization-Wiley (2013).pdf:C\:\\Users\\dell\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\727v3yux.default\\zotero\\storage\\SEJED5PU\\An Introduction to Optimization-Wiley (2013).pdf:application/pdf},
	year={2013}
}

@article{yuan_step-sizes_2008,
	title = {Step-sizes for the gradient method},
	volume = {42},
	url = {ftp://159.226.92.9/pub/yyx/papers/p0504.pdf},
	pages = {785},
	number = {2},
	journaltitle = {{AMS} {IP} Studies in Advanced Mathematics},
	author = {Yuan, Ya-xiang},
	urldate = {2015-10-10},
	date = {2008},
	file = {Step-Sizes for the Gradient Method.pdf:C\:\\Users\\dell\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\727v3yux.default\\zotero\\storage\\59P9T9ZA\\Step-Sizes for the Gradient Method.pdf:application/pdf}
}

@article{zhou_gradient_2006,
	title = {Gradient Methods with Adaptive Step-Sizes},
	volume = {35},
	issn = {0926-6003, 1573-2894},
	url = {http://link.springer.com/article/10.1007/s10589-006-6446-0},
	doi = {10.1007/s10589-006-6446-0},
	pages = {69--86},
	number = {1},
	journaltitle = {Computational Optimization and Applications},
	shortjournal = {Comput Optim Applic},
	author = {Zhou, Bin and Gao, Li and Dai, Yu-Hong},
	urldate = {2015-10-10},
	date = {2006-03-31},
	langid = {english},
	keywords = {adaptive step-size, Barzilai-Borwein method, Convex and Discrete Geometry, Gradient method, linear system, Operations Research/Decision Theory, Operations Research, Mathematical Programming, Optimization, Statistics, general, superlinear behavior, trust-region approach},
	file = {Full Text PDF:C\:\\Users\\dell\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\727v3yux.default\\zotero\\storage\\AIRXQ833\\Zhou et al. - 2006 - Gradient Methods with Adaptive Step-Sizes.pdf:application/pdf;Snapshot:C\:\\Users\\dell\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\727v3yux.default\\zotero\\storage\\KNGKX8Q8\\10.html:text/html}
}

@article{vrahatis_class_2000,
	title = {A class of gradient unconstrained minimization algorithms with adaptive stepsize},
	volume = {114},
	issn = {0377-0427},
	url = {http://www.sciencedirect.com/science/article/pii/S0377042799002769},
	doi = {10.1016/S0377-0427(99)00276-9},
	abstract = {In this paper the development, convergence theory and numerical testing of a class of gradient unconstrained minimization algorithms with adaptive stepsize are presented. The proposed class comprises four algorithms: the first two incorporate techniques for the adaptation of a common stepsize for all coordinate directions and the other two allow an individual adaptive stepsize along each coordinate direction. All the algorithms are computationally efficient and possess interesting convergence properties utilizing estimates of the Lipschitz constant that are obtained without additional function or gradient evaluations. The algorithms have been implemented and tested on some well-known test cases as well as on real-life artificial neural network applications and the results have been very satisfactory.},
	pages = {367--386},
	number = {2},
	journaltitle = {Journal of Computational and Applied Mathematics},
	shortjournal = {Journal of Computational and Applied Mathematics},
	author = {Vrahatis, M. N. and Androulakis, G. S. and Lambrinos, J. N. and Magoulas, G. D.},
	urldate = {2015-10-10},
	date = {2000-02-01},
	keywords = {Armijo's method, Artificial neural network, Globally convergent method, Gradient method, Line search strategies, Lipschitz constant, Steepest descent, Training algorithm, Unconstrained optimization},
	file = {1-s2.0-S0377042799002769-main.pdf:C\:\\Users\\dell\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\727v3yux.default\\zotero\\storage\\VU8UUQW5\\1-s2.0-S0377042799002769-main.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\dell\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\727v3yux.default\\zotero\\storage\\DJ8IK2VN\\S0377042799002769.html:text/html}
}

@article{armijo_minimization_1966,
	title = {Minimization of functions having Lipschitz continuous first partial derivatives.},
	volume = {16},
	issn = {0030-8730},
	url = {http://projecteuclid.org/euclid.pjm/1102995080},
	abstract = {Project Euclid - mathematics and statistics online},
	pages = {1--3},
	number = {1},
	journaltitle = {Pacific Journal of Mathematics},
	shortjournal = {Pacific J. Math.},
	author = {Armijo, Larry},
	urldate = {2015-10-10},
	date = {1966},
	mrnumber = {MR0191071},
	zmnumber = {0202.46105},
	file = {pjm-v16-n1-p01-p.pdf:C\:\\Users\\dell\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\727v3yux.default\\zotero\\storage\\ZPZKZX8G\\pjm-v16-n1-p01-p.pdf:application/pdf;Snapshot:C\:\\Users\\dell\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\727v3yux.default\\zotero\\storage\\PFPJGPH3\\1102995080.html:text/html}
}

@techreport{shewchuk_introduction_1994,
	address = {Pittsburgh, PA, USA},
	title = {An {Introduction} to the {Conjugate} {Gradient} {Method} {Without} the {Agonizing} {Pain}},
	abstract = {The Conjugate Gradient Method is the most prominent iterative method for solving sparse systems of linear equations. Unfortunately, many textbook treatments of the topic are written so that even their own authors would be mystified, if they bothered to read their own writing. For this reason, an understanding of the method has been reserved for the elite brilliant few who have painstakingly decoded the mumblings of their forebears. Nevertheless, the Conjugate Gradient Method is a composite of simple, elegant ideas that almost anyone can understand. Of course, a reader as intelligent as yourself will learn them almost effortlessly. The idea of quadratic forms is introduced and used to derive the methods of Steepest Descent, Conjugate Directions, and Conjugate Gradients. Eigenvectors are explained and used to examine the convergence of the Jacobi Method, Steepest Descent, and Conjugate Gradients. Other topics include preconditioning and the nonlinear Conjugate Gradient Method. I have taken pains to make this article easy to read. Sixty-two illustrations are provided. Dense prose is avoided. Concepts are explained in several different ways. Most equations are coupled with an intuitive interpretation.},
	institution = {Carnegie Mellon University},
	author = {Shewchuk, Jonathan R},
	year = {1994},
	file = {painless-conjugate-gradient.pdf:C\:\\Users\\joe\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\z4ailp3m.default\\zotero\\storage\\4RN9S5ID\\painless-conjugate-gradient.pdf:application/pdf}
}


